commit e1b9ccb1d729ada16192d982e771580421e4d07d
Author: Anthony Romano <anthony.romano@coreos.com>
Date:   Thu Jun 23 17:25:38 2016 -0700

    doc: eschew "you" for current docs

diff --git a/Documentation/branch_management.md b/Documentation/branch_management.md
index dcea5a3..073a344 100644
--- a/Documentation/branch_management.md
+++ b/Documentation/branch_management.md
@@ -13,7 +13,7 @@ The etcd team has adopted a *rolling release model* and supports one stable vers
 
 The `master` branch is our development branch. All new features land here first.
 
-If you want to try new features, pull `master` and play with it. Note that `master` may not be stable because new features may introduce bugs.
+To try new and experimental features, pull `master` and play with it. Note that `master` may not be stable because new features may introduce bugs.
 
 Before the release of the next stable version, feature PRs will be frozen. We will focus on the testing, bug-fix and documentation for one to two weeks.
 
diff --git a/Documentation/dev-internal/discovery_protocol.md b/Documentation/dev-internal/discovery_protocol.md
index 3971431..d38ec2d 100644
--- a/Documentation/dev-internal/discovery_protocol.md
+++ b/Documentation/dev-internal/discovery_protocol.md
@@ -26,7 +26,7 @@ UUID=$(uuidgen)
 
 ### Specifying the Expected Cluster Size
 
-You need to specify the expected cluster size for this discovery token. The size is used by the discovery service to know when it has found all members that will initially form the cluster.
+The discovery token expects a cluster size that must be specified. The size is used by the discovery service to know when it has found all members that will initially form the cluster.
 
 ```
 curl -X PUT http://example.com/v2/keys/_etcd/registry/${UUID}/_config/size -d value=${cluster_size}
@@ -36,7 +36,7 @@ Usually the cluster size is 3, 5 or 7. Check [optimal cluster size][cluster-size
 
 ### Bringing up etcd Processes
 
-Now that you have your discovery URL, you can use it as `-discovery` flag and bring up etcd processes. Every etcd process will follow this next few steps internally if given a `-discovery` flag.
+Given the discovery URL, use it as `-discovery` flag and bring up etcd processes. Every etcd process will follow this next few steps internally if given a `-discovery` flag.
 
 ### Registering itself
 
@@ -102,11 +102,11 @@ The generation process in the service follows the steps from [Creating a New Dis
 GET /${UUID}
 ```
 
-You can check the status for this discovery token, including the machines that have been registered, by requesting the value of the UUID.
+The status for this discovery token, including the machines that have been registered, can be checked by requesting the value of the UUID.
 
 ### Open-source repository
 
-The repository is located at https://github.com/coreos/discovery.etcd.io. You could use it to build your own public discovery service.
+The repository is located at https://github.com/coreos/discovery.etcd.io. It could be used to build a custom discovery service.
 
 [api]: ../v2/api.md#waiting-for-a-change
 [cluster-size]: ../v2/admin_guide.md#optimal-cluster-size
diff --git a/Documentation/dev-internal/release.md b/Documentation/dev-internal/release.md
index b439b84..59e06bc 100644
--- a/Documentation/dev-internal/release.md
+++ b/Documentation/dev-internal/release.md
@@ -2,7 +2,7 @@
 
 The guide talks about how to release a new version of etcd.
 
-The procedure includes some manual steps for sanity checking but it can probably be further scripted. Please keep this document up-to-date if you want to make changes to the release process. 
+The procedure includes some manual steps for sanity checking but it can probably be further scripted. Please keep this document up-to-date if making changes to the release process. 
 
 ## Prepare Release
 
diff --git a/Documentation/dl_build.md b/Documentation/dl_build.md
index 4f9d4b1..431021e 100644
--- a/Documentation/dl_build.md
+++ b/Documentation/dl_build.md
@@ -10,7 +10,7 @@ The easiest way to get etcd is to use one of the pre-built release binaries whic
 
 ## Build the Latest Version
 
-For those wanting to try the very latest version, you can build the latest version of etcd from the `master` branch.
+For those wanting to try the very latest version, build etcd from the `master` branch.
 [Go](https://golang.org/) version 1.5+ is required to build the latest version of etcd.
 
 Here are the commands to build an etcd binary from the `master` branch:
@@ -33,7 +33,7 @@ $ ./bin/etcd
 ...
 ```
 
-## Test your Installation
+## Test the installation
 
 Check the etcd binary is built correctly by starting etcd and setting a key.
 
@@ -53,4 +53,4 @@ OK
 If OK is printed, then etcd is working!
 
 [github-release]: https://github.com/coreos/etcd/releases/
-[go]: https://golang.org/doc/install
\ No newline at end of file
+[go]: https://golang.org/doc/install
diff --git a/Documentation/docs.md b/Documentation/docs.md
index 7f6d39f..c7d47fa 100644
--- a/Documentation/docs.md
+++ b/Documentation/docs.md
@@ -4,11 +4,11 @@ etcd is a distributed key-value store designed to reliably and quickly preserve
 
 ## Getting started
 
-New etcd users and developers should get started by [downloading and building][download_build] etcd. Once you have etcd, follow this [quick demo][demo] to see the basics of creating and working with an etcd cluster.
+New etcd users and developers should get started by [downloading and building][download_build] etcd. After getting etcd, follow this [quick demo][demo] to see the basics of creating and working with an etcd cluster.
 
 ## Developing with etcd
 
-The easiest way to get started using etcd as a distributed key-value store for your applications is to [set up a local cluster][local_cluster].
+The easiest way to get started using etcd as a distributed key-value store is to [set up a local cluster][local_cluster].
 
  - [Setting up local clusters][local_cluster]
  - [Interacting with etcd][interacting]
diff --git a/Documentation/op-guide/clustering.md b/Documentation/op-guide/clustering.md
index 22ebc5c..3a7fbdb 100644
--- a/Documentation/op-guide/clustering.md
+++ b/Documentation/op-guide/clustering.md
@@ -2,9 +2,9 @@
 
 ## Overview
 
-Starting an etcd cluster statically requires that each member knows another in the cluster. In a number of cases, you might not know the IPs of your cluster members ahead of time. In these cases, you can bootstrap an etcd cluster with the help of a discovery service.
+Starting an etcd cluster statically requires that each member knows another in the cluster. In a number of cases, the IPs of the cluster members may be unknown ahead of time. In these cases, the etcd cluster can be bootstrapped with the help of a discovery service.
 
-Once an etcd cluster is up and running, adding or removing members is done via [runtime reconfiguration][runtime-conf]. To better understand the design behind runtime reconfiguration, we suggest you read [the runtime configuration design document][runtime-reconf-design].
+Once an etcd cluster is up and running, adding or removing members is done via [runtime reconfiguration][runtime-conf]. To better understand the design behind runtime reconfiguration, we suggest reading [the runtime configuration design document][runtime-reconf-design].
 
 This guide will cover the following mechanisms for bootstrapping an etcd cluster:
 
@@ -36,11 +36,11 @@ ETCD_INITIAL_CLUSTER_STATE=new
 
 Note that the URLs specified in `initial-cluster` are the _advertised peer URLs_, i.e. they should match the value of `initial-advertise-peer-urls` on the respective nodes.
 
-If you are spinning up multiple clusters (or creating and destroying a single cluster) with same configuration for testing purpose, it is highly recommended that you specify a unique `initial-cluster-token` for the different clusters. By doing this, etcd can generate unique cluster IDs and member IDs for the clusters even if they otherwise have the exact same configuration. This can protect you from cross-cluster-interaction, which might corrupt your clusters.
+If spinning up multiple clusters (or creating and destroying a single cluster) with same configuration for testing purpose, it is highly recommended that each cluster is given a unique `initial-cluster-token`. By doing this, etcd can generate unique cluster IDs and member IDs for the clusters even if they otherwise have the exact same configuration. This can protect etcd from cross-cluster-interaction, which might corrupt the clusters.
 
-etcd listens on [`listen-client-urls`][conf-listen-client] to accept client traffic. etcd member advertises the URLs specified in [`advertise-client-urls`][conf-adv-client] to other members, proxies, clients. Please make sure the `advertise-client-urls` are reachable from intended clients. A common mistake is setting `advertise-client-urls` to localhost or leave it as default when you want the remote clients to reach etcd.
+etcd listens on [`listen-client-urls`][conf-listen-client] to accept client traffic. etcd member advertises the URLs specified in [`advertise-client-urls`][conf-adv-client] to other members, proxies, clients. Please make sure the `advertise-client-urls` are reachable from intended clients. A common mistake is setting `advertise-client-urls` to localhost or leave it as default if the remote clients should reach etcd.
 
-On each machine you would start etcd with these flags:
+On each machine, start etcd with these flags:
 
 ```
 $ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \
@@ -70,7 +70,7 @@ $ etcd --name infra2 --initial-advertise-peer-urls http://10.0.1.12:2380 \
   --initial-cluster-state new
 ```
 
-The command line parameters starting with `--initial-cluster` will be ignored on subsequent runs of etcd. You are free to remove the environment variables or command line flags after the initial bootstrap process. If you need to make changes to the configuration later (for example, adding or removing members to/from the cluster), see the [runtime configuration][runtime-conf] guide.
+The command line parameters starting with `--initial-cluster` will be ignored on subsequent runs of etcd. Feel free to remove the environment variables or command line flags after the initial bootstrap process. If the configuration needs changes later (for example, adding or removing members to/from the cluster), see the [runtime configuration][runtime-conf] guide.
 
 ### TLS
 
@@ -190,7 +190,7 @@ etcd: error setting up initial cluster: infra0 has different advertised URLs in
 exit 1
 ```
 
-If you configure a peer with a different set of configuration and attempt to join this cluster you will get a cluster ID mismatch and etcd will exit.
+If a peer is configured with a different set of configuration arguments and attempts to join this cluster, etcd will report a cluster ID mismatch will exit.
 
 ```
 $ etcd --name infra3 --initial-advertise-peer-urls http://10.0.1.13:2380 \
@@ -205,7 +205,7 @@ exit 1
 
 ## Discovery
 
-In a number of cases, you might not know the IPs of your cluster peers ahead of time. This is common when utilizing cloud providers or when your network uses DHCP. In these cases, rather than specifying a static configuration, you can use an existing etcd cluster to bootstrap a new one. We call this process "discovery".
+In a number of cases, the IPs of the cluster peers may not be known ahead of time. This is common when utilizing cloud providers or when the network uses DHCP. In these cases, rather than specifying a static configuration, use an existing etcd cluster to bootstrap a new one. We call this process "discovery".
 
 There two methods that can be used for discovery:
 
@@ -214,25 +214,25 @@ There two methods that can be used for discovery:
 
 ### etcd Discovery
 
-To better understand the design about discovery service protocol, we suggest you read [this][discovery-proto].
+To better understand the design about discovery service protocol, we suggest reading the discovery service protocol [documentation][discovery-proto].
 
 #### Lifetime of a Discovery URL
 
-A discovery URL identifies a unique etcd cluster. Instead of reusing a discovery URL, you should always create discovery URLs for new clusters.
+A discovery URL identifies a unique etcd cluster. Instead of reusing a discovery URL, always create discovery URLs for new clusters.
 
 Moreover, discovery URLs should ONLY be used for the initial bootstrapping of a cluster. To change cluster membership after the cluster is already running, see the [runtime reconfiguration][runtime-conf] guide.
 
 #### Custom etcd Discovery Service
 
-Discovery uses an existing cluster to bootstrap itself. If you are using your own etcd cluster you can create a URL like so:
+Discovery uses an existing cluster to bootstrap itself. If using a private etcd cluster, can create a URL like so:
 
 ```
 $ curl -X PUT https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83/_config/size -d value=3
 ```
 
-By setting the size key to the URL, you create a discovery URL with an expected cluster size of 3.
+By setting the size key to the URL, a discovery URL is created with an expected cluster size of 3.
 
-The URL you will use in this case will be `https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83` and the etcd members will use the `https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83` directory for registration as they start.
+The URL to use in this case will be `https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83` and the etcd members will use the `https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83` directory for registration as they start.
 
 **Each member must have a different name flag specified. `Hostname` or `machine-id` can be a good choice. Or discovery will fail due to duplicated name.**
 
@@ -264,14 +264,14 @@ This will cause each member to register itself with the custom etcd discovery se
 
 #### Public etcd Discovery Service
 
-If you do not have access to an existing cluster, you can use the public discovery service hosted at `discovery.etcd.io`.  You can create a private discovery URL using the "new" endpoint like so:
+If no exiting cluster is available, use the public discovery service hosted at `discovery.etcd.io`.  To create a private discovery URL using the "new" endpoint, use the command:
 
 ```
 $ curl https://discovery.etcd.io/new?size=3
 https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de
 ```
 
-This will create the cluster with an initial expected size of 3 members. If you do not specify a size, a default of 3 will be used.
+This will create the cluster with an initial expected size of 3 members. If no size is specified, a default of 3 is used.
 
 ```
 ETCD_DISCOVERY=https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de
@@ -309,7 +309,7 @@ $ etcd --name infra2 --initial-advertise-peer-urls http://10.0.1.12:2380 \
 
 This will cause each member to register itself with the discovery service and begin the cluster once all members have been registered.
 
-You can use the environment variable `ETCD_DISCOVERY_PROXY` to cause etcd to use an HTTP proxy to connect to the discovery service.
+Use the environment variable `ETCD_DISCOVERY_PROXY` to cause etcd to use an HTTP proxy to connect to the discovery service.
 
 #### Error and Warning Cases
 
@@ -328,8 +328,7 @@ exit 1
 
 ##### Warnings
 
-This is a harmless warning notifying you that the discovery URL will be
-ignored on this machine.
+This is a harmless warning indicating the discovery URL will be ignored on this machine.
 
 ```
 $ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \
@@ -420,7 +419,7 @@ $ etcd --name infra2 \
 --listen-peer-urls http://infra2.example.com:2380
 ```
 
-You can also bootstrap the cluster using IP addresses instead of domain names:
+The cluster can also bootstrap using IP addresses instead of domain names:
 
 ```
 $ etcd --name infra0 \
diff --git a/Documentation/op-guide/configuration.md b/Documentation/op-guide/configuration.md
index ed57cc2..630d690 100644
--- a/Documentation/op-guide/configuration.md
+++ b/Documentation/op-guide/configuration.md
@@ -14,7 +14,7 @@ To start etcd automatically using custom settings at startup in Linux, using a [
 + Human-readable name for this member.
 + default: "default"
 + env variable: ETCD_NAME
-+ This value is referenced as this node's own entries listed in the `--initial-cluster` flag (e.g., `default=http://localhost:2380`). This needs to match the key used in the flag if you're using [static bootstrapping][build-cluster]. When using discovery, each member must have a unique name. `Hostname` or `machine-id` can be a good choice.
++ This value is referenced as this node's own entries listed in the `--initial-cluster` flag (e.g., `default=http://localhost:2380`). This needs to match the key used in the flag if using [static bootstrapping][build-cluster]. When using discovery, each member must have a unique name. `Hostname` or `machine-id` can be a good choice.
 
 ### --data-dir
 + Path to the data directory.
@@ -59,13 +59,13 @@ To start etcd automatically using custom settings at startup in Linux, using a [
 + Maximum number of snapshot files to retain (0 is unlimited)
 + default: 5
 + env variable: ETCD_MAX_SNAPSHOTS
-+ The default for users on Windows is unlimited, and manual purging down to 5 (or your preference for safety) is recommended.
++ The default for users on Windows is unlimited, and manual purging down to 5 (or some preference for safety) is recommended.
 
 ### --max-wals
 + Maximum number of wal files to retain (0 is unlimited)
 + default: 5
 + env variable: ETCD_MAX_WALS
-+ The default for users on Windows is unlimited, and manual purging down to 5 (or your preference for safety) is recommended.
++ The default for users on Windows is unlimited, and manual purging down to 5 (or some preference for safety) is recommended.
 
 ### --cors
 + Comma-separated white list of origins for CORS (cross-origin resource sharing).
@@ -108,7 +108,7 @@ To start etcd automatically using custom settings at startup in Linux, using a [
 + default: "http://localhost:2379"
 + env variable: ETCD_ADVERTISE_CLIENT_URLS
 + example: "http://example.com:2379, http://10.0.0.1:2379"
-+ Be careful if you are advertising URLs such as http://localhost:2379 from a cluster member and are using the proxy feature of etcd. This will cause loops, because the proxy will be forwarding requests to itself until its resources (memory, file descriptors) are eventually depleted.
++ Be careful if advertising URLs such as http://localhost:2379 from a cluster member and are using the proxy feature of etcd. This will cause loops, because the proxy will be forwarding requests to itself until its resources (memory, file descriptors) are eventually depleted.
 
 ### --discovery
 + Discovery URL used to bootstrap the cluster.
@@ -171,7 +171,7 @@ To start etcd automatically using custom settings at startup in Linux, using a [
 
 ### --proxy-read-timeout
 + Time (in milliseconds) for a read to timeout or 0 to disable the timeout.
-+ Don't change this value if you use watches because they are using long polling requests.
++ Don't change this value if using watches because use long polling requests.
 + default: 0
 + env variable: ETCD_PROXY_READ_TIMEOUT
 
diff --git a/Documentation/op-guide/runtime-configuration.md b/Documentation/op-guide/runtime-configuration.md
index e4d7382..33959e4 100644
--- a/Documentation/op-guide/runtime-configuration.md
+++ b/Documentation/op-guide/runtime-configuration.md
@@ -4,7 +4,7 @@ etcd comes with support for incremental runtime reconfiguration, which allows us
 
 Reconfiguration requests can only be processed when the majority of the cluster members are functioning. It is **highly recommended** to always have a cluster size greater than two in production. It is unsafe to remove a member from a two member cluster. The majority of a two member cluster is also two. If there is a failure during the removal process, the cluster might not able to make progress and need to [restart from majority failure][majority failure].
 
-To better understand the design behind runtime reconfiguration, we suggest you read [the runtime reconfiguration document][runtime-reconf].
+To better understand the design behind runtime reconfiguration, we suggest reading [the runtime reconfiguration document][runtime-reconf].
 
 ## Reconfiguration Use Cases
 
@@ -12,9 +12,9 @@ Let's walk through some common reasons for reconfiguring a cluster. Most of thes
 
 ### Cycle or Upgrade Multiple Machines
 
-If you need to move multiple members of your cluster due to planned maintenance (hardware upgrades, network downtime, etc.), it is recommended to modify members one at a time.
+If multiple cluster members need to move due to planned maintenance (hardware upgrades, network downtime, etc.), it is recommended to modify members one at a time.
 
-It is safe to remove the leader, however there is a brief period of downtime while the election process takes place. If your cluster holds more than 50MB, it is recommended to [migrate the member's data directory][member migration].
+It is safe to remove the leader, however there is a brief period of downtime while the election process takes place. If the cluster holds more than 50MB, it is recommended to [migrate the member's data directory][member migration].
 
 ### Change the Cluster Size
 
@@ -24,13 +24,13 @@ Decreasing the cluster size can improve the write performance of a cluster, with
 
 ### Replace A Failed Machine
 
-If a machine fails due to hardware failure, data directory corruption, or some other fatal situation, it should be replaced as soon as possible. Machines that have failed but haven't been removed adversely affect your quorum and reduce the tolerance for an additional failure.
+If a machine fails due to hardware failure, data directory corruption, or some other fatal situation, it should be replaced as soon as possible. Machines that have failed but haven't been removed adversely affect the quorum and reduce the tolerance for an additional failure.
 
-To replace the machine, follow the instructions for [removing the member][remove member] from the cluster, and then [add a new member][add member] in its place. If your cluster holds more than 50MB, it is recommended to [migrate the failed member's data directory][member migration] if you can still access it.
+To replace the machine, follow the instructions for [removing the member][remove member] from the cluster, and then [add a new member][add member] in its place. If the cluster holds more than 50MB, it is recommended to [migrate the failed member's data directory][member migration] if it is still accessible.
 
 ### Restart Cluster from Majority Failure
 
-If the majority of your cluster is lost or all of your nodes have changed IP addresses, then you need to take manual action in order to recover safely.
+If the majority of the cluster is lost or all of the nodes have changed IP addresses, then manual action is necessary to recover safely.
 The basic steps in the recovery process include [creating a new cluster using the old data][disaster recovery], forcing a single member to act as the leader, and finally using runtime configuration to [add new members][add member] to this new cluster one at a time.
 
 ## Cluster Reconfiguration Operations
@@ -42,13 +42,13 @@ This is essentially the same requirement as for any other write to etcd.
 
 All changes to the cluster are done one at a time:
 
-* To update a single member peerURLs you will make an update operation
-* To replace a single member you will make an add then a remove operation
-* To increase from 3 to 5 members you will make two add operations
-* To decrease from 5 to 3 you will make two remove operations
+* To update a single member peerURLs, make an update operation
+* To replace a single member, make an add then a remove operation
+* To increase from 3 to 5 members, make two add operations
+* To decrease from 5 to 3, make two remove operations
 
 All of these examples will use the `etcdctl` command line tool that ships with etcd.
-If you want to use the members API directly you can find the documentation [here][member-api].
+To change membership without `etcdctl`, use the [members API][member-api].
 
 TODO: v3 member API documentation
 
@@ -56,18 +56,18 @@ TODO: v3 member API documentation
 
 #### Update advertise client URLs
 
-If you would like to update the advertise client URLs of a member, you can simply restart
+To update the advertise client URLs of a member, simply restart
 that member with updated client urls flag (`--advertise-client-urls`) or environment variable
 (`ETCD_ADVERTISE_CLIENT_URLS`). The restarted member will self publish the updated URLs.
 A wrongly updated client URL will not affect the health of the etcd cluster.
 
 #### Update advertise peer URLs
 
-If you would like to update the advertise peer URLs of a member, you have to first update 
+To update the advertise peer URLs of a member, first update 
 it explicitly via member command and then restart the member. The additional action is required
 since updating peer URLs changes the cluster wide configuration and can affect the health of the etcd cluster. 
 
-To update the peer URLs, first, we need to find the target member's ID. You can list all members with `etcdctl`:
+To update the peer URLs, first, we need to find the target member's ID. To list all members with `etcdctl`:
 
 ```sh
 $ etcdctl member list
@@ -131,8 +131,8 @@ $ etcd --listen-client-urls http://10.0.1.13:2379 --advertise-client-urls http:/
 
 The new member will run as a part of the cluster and immediately begin catching up with the rest of the cluster.
 
-If you are adding multiple members the best practice is to configure a single member at a time and verify it starts correctly before adding more new members.
-If you add a new member to a 1-node cluster, the cluster cannot make progress before the new member starts because it needs two members as majority to agree on the consensus. You will only see this behavior between the time `etcdctl member add` informs the cluster about the new member and the new member successfully establishing a connection to the existing one.
+If adding multiple members the best practice is to configure a single member at a time and verify it starts correctly before adding more new members.
+If adding a new member to a 1-node cluster, the cluster cannot make progress before the new member starts because it needs two members as majority to agree on the consensus. This behavior only happens between the time `etcdctl member add` informs the cluster about the new member and the new member successfully establishing a connection to the existing one.
 
 #### Error Cases When Adding Members
 
diff --git a/Documentation/op-guide/runtime-reconf-design.md b/Documentation/op-guide/runtime-reconf-design.md
index 32467e6..42fadaf 100644
--- a/Documentation/op-guide/runtime-reconf-design.md
+++ b/Documentation/op-guide/runtime-reconf-design.md
@@ -4,47 +4,47 @@ Runtime reconfiguration is one of the hardest and most error prone features in a
 
 Read on to learn about the design of etcd's runtime reconfiguration commands and how we tackled these problems.
 
-## Two Phase Config Changes Keep you Safe
+## Two phase config changes keep the cluster safe
 
-In etcd, every runtime reconfiguration has to go through [two phases][add-member] for safety reasons. For example, to add a member you need to first inform cluster of new configuration and then start the new member.
+In etcd, every runtime reconfiguration has to go through [two phases][add-member] for safety reasons. For example, to add a member, first inform cluster of new configuration and then start the new member.
 
 Phase 1 - Inform cluster of new configuration
 
-To add a member into etcd cluster, you need to make an API call to request a new member to be added to the cluster. And this is only way that you can add a new member into an existing cluster. The API call returns when the cluster agrees on the configuration change.
+To add a member into etcd cluster, make an API call to request a new member to be added to the cluster. This is only way to add a new member into an existing cluster. The API call returns when the cluster agrees on the configuration change.
 
 Phase 2 - Start new member
 
-To join the etcd member into the existing cluster, you need to specify the correct `initial-cluster` and set `initial-cluster-state` to `existing`. When the member starts, it will contact the existing cluster first and verify the current cluster configuration matches the expected one specified in `initial-cluster`. When the new member successfully starts, you know your cluster reached the expected configuration.
+To join the etcd member into the existing cluster, specify the correct `initial-cluster` and set `initial-cluster-state` to `existing`. When the member starts, it will contact the existing cluster first and verify the current cluster configuration matches the expected one specified in `initial-cluster`. When the new member successfully starts, the cluster has reached the expected configuration.
 
 By splitting the process into two discrete phases users are forced to be explicit regarding cluster membership changes. This actually gives users more flexibility and makes things easier to reason about. For example, if there is an attempt to add a new member with the same ID as an existing member in an etcd cluster, the action will fail immediately during phase one without impacting the running cluster. Similar protection is provided to prevent adding new members by mistake. If a new etcd member attempts to join the cluster before the cluster has accepted the configuration change,, it will not be accepted by the cluster.
 
 Without the explicit workflow around cluster membership etcd would be vulnerable to unexpected cluster membership changes. For example, if etcd is running under an init system such as systemd, etcd would be restarted after being removed via the membership API, and attempt to rejoin the cluster on startup. This cycle would continue every time a member is removed via the API and systemd is set to restart etcd after failing, which is unexpected.
 
-We think runtime reconfiguration should be a low frequent operation. We made the decision to keep it explicit and user-driven to ensure configuration safety and keep your cluster always running smoothly under your control.
+We expect runtime reconfiguration to be an infrequent operation. We decided to keep it explicit and user-driven to ensure configuration safety and keep the cluster always running smoothly under explicit control.
 
 ## Permanent Loss of Quorum Requires New Cluster
 
 If a cluster permanently loses a majority of its members, a new cluster will need to be started from an old data directory to recover the previous state.
 
-It is entirely possible to force removing the failed members from the existing cluster to recover. However, we decided not to support this method since it bypasses the normal consensus committing phase, which is unsafe. If the member to remove is not actually dead or you force to remove different members through different members in the same cluster, you will end up with diverged cluster with same clusterID. This is very dangerous and hard to debug/fix afterwards. 
+It is entirely possible to force removing the failed members from the existing cluster to recover. However, we decided not to support this method since it bypasses the normal consensus committing phase, which is unsafe. If the member to remove is not actually dead or force removed through different members in the same cluster, etcd will end up with a diverged cluster with same clusterID. This is very dangerous and hard to debug/fix afterwards. 
 
-If you have a correct deployment, the possibility of permanent majority lose is very low. But it is a severe enough problem that worth special care. We strongly suggest you to read the [disaster recovery documentation][disaster-recovery] and prepare for permanent majority lose before you put etcd into production.
+With a correct deployment, the possibility of permanent majority lose is very low. But it is a severe enough problem that worth special care. We strongly suggest reading the [disaster recovery documentation][disaster-recovery] and prepare for permanent majority lose before putting etcd into production.
 
 ## Do Not Use Public Discovery Service For Runtime Reconfiguration
 
-The public discovery service should only be used for bootstrapping a cluster. To join member into an existing cluster, you should use runtime reconfiguration API. 
+The public discovery service should only be used for bootstrapping a cluster. To join member into an existing cluster, use runtime reconfiguration API. 
 
-Discovery service is designed for bootstrapping an etcd cluster in the cloud environment, when you do not know the IP addresses of all the members beforehand. After you successfully bootstrap a cluster, the IP addresses of all the members are known. Technically, you should not need the discovery service any more.
+Discovery service is designed for bootstrapping an etcd cluster in the cloud environment, when the IP addresses of all the members are not known beforehand. After successfully bootstrapping a cluster, the IP addresses of all the members are known. Technically, the discovery service should no longer be needed.
 
 It seems that using public discovery service is a convenient way to do runtime reconfiguration, after all discovery service already has all the cluster configuration information. However relying on public discovery service brings troubles: 
 
-1. it introduces external dependencies for the entire life-cycle of your cluster, not just bootstrap time. If there is a network issue between your cluster and public discovery service, your cluster will suffer from it.
+1. it introduces external dependencies for the entire life-cycle of the cluster, not just bootstrap time. If there is a network issue between the cluster and public discovery service, the cluster will suffer from it.
  
-2. public discovery service must reflect correct runtime configuration of your cluster during it life-cycle. It has to provide security mechanism to avoid bad actions, and it is hard. 
+2. public discovery service must reflect correct runtime configuration of the cluster during it life-cycle. It has to provide security mechanism to avoid bad actions, and it is hard. 
 
 3. public discovery service has to keep tens of thousands of cluster configurations. Our public discovery service backend is not ready for that workload.
 
-If you want to have a discovery service that supports runtime reconfiguration, the best choice is to build your private one.
+To have a discovery service that supports runtime reconfiguration, the best choice is to build a private one.
 
 [add-member]: runtime-configuration.md#add-a-new-member
 [disaster-recovery]: recovery.md
diff --git a/Documentation/op-guide/security.md b/Documentation/op-guide/security.md
index aa16ee5..38c4cdd 100644
--- a/Documentation/op-guide/security.md
+++ b/Documentation/op-guide/security.md
@@ -2,9 +2,9 @@
 
 etcd supports automatic TLS as well as authentication through client certificates for both clients to server as well as peer (server to server / cluster) communication.
 
-To get up and running you first need to have a CA certificate and a signed key pair for one member. It is recommended to create and sign a new key pair for every member in a cluster.
+To get up and running, first have a CA certificate and a signed key pair for one member. It is recommended to create and sign a new key pair for every member in a cluster.
 
-For convenience, the [cfssl] tool provides an easy interface to certificate generation, and we provide an example using the tool [here][tls-setup]. You can also examine this [alternative guide to generating self-signed key pairs][tls-guide].
+For convenience, the [cfssl] tool provides an easy interface to certificate generation, and we provide an example using the tool [here][tls-setup]. Alternatively, try this [guide to generating self-signed key pairs][tls-guide].
 
 ## Basic setup
 
@@ -12,7 +12,7 @@ etcd takes several certificate related configuration options, either through com
 
 **Client-to-server communication:**
 
-`--cert-file=<path>`: Certificate used for SSL/TLS connections **to** etcd. When this option is set, you can set advertise-client-urls using HTTPS schema.
+`--cert-file=<path>`: Certificate used for SSL/TLS connections **to** etcd. When this option is set, advertise-client-urls can use the HTTPS schema.
 
 `--key-file=<path>`: Key for the certificate. Must be unencrypted.
 
@@ -40,7 +40,7 @@ If either a client-to-server or peer certificate is supplied the key must also b
 
 ## Example 1: Client-to-server transport security with HTTPS
 
-For this you need your CA certificate (`ca.crt`) and signed key pair (`server.crt`, `server.key`) ready.
+For this, have a CA certificate (`ca.crt`) and signed key pair (`server.crt`, `server.key`) ready.
 
 Let us configure etcd to provide simple HTTPS transport security step by step:
 
@@ -50,19 +50,19 @@ $ etcd --name infra0 --data-dir infra0 \
   --advertise-client-urls=https://127.0.0.1:2379 --listen-client-urls=https://127.0.0.1:2379
 ```
 
-This should start up fine and you can now test the configuration by speaking HTTPS to etcd:
+This should start up fine and it will be possible to test the configuration by speaking HTTPS to etcd:
 
 ```sh
 $ curl --cacert /path/to/ca.crt https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v
 ```
 
-You should be able to see the handshake succeed. Because we use self-signed certificates with our own certificate authorities you need to provide the CA to curl using the `--cacert` option. Another possibility would be to add your CA certificate to the trusted certificates on your system (usually in `/etc/pki/tls/certs` or `/etc/ssl/certs`).
+The command should show that the handshake succeed. Since we use self-signed certificates with our own certificate authority, the CA must be passed to curl using the `--cacert` option. Another possibility would be to add the CA certificate to the system's trusted certificates directory (usually in `/etc/pki/tls/certs` or `/etc/ssl/certs`).
 
 **OSX 10.9+ Users**: curl 7.30.0 on OSX 10.9+ doesn't understand certificates passed in on the command line.
-Instead you must import the dummy ca.crt directly into the keychain or add the `-k` flag to curl to ignore errors.
-If you want to test without the `-k` flag run `open ./fixtures/ca/ca.crt` and follow the prompts.
-Please remove this certificate after you are done testing!
-If you know of a workaround let us know.
+Instead, import the dummy ca.crt directly into the keychain or add the `-k` flag to curl to ignore errors.
+To test without the `-k` flag, run `open ./fixtures/ca/ca.crt` and follow the prompts.
+Please remove this certificate after testing!
+If there is a workaround, let us know.
 
 ## Example 2: Client-to-server authentication with HTTPS client certificates
 
@@ -70,7 +70,7 @@ For now we've given the etcd client the ability to verify the server identity an
 
 The clients will provide their certificates to the server and the server will check whether the cert is signed by the supplied CA and decide whether to serve the request.
 
-You need the same files mentioned in the first example for this, as well as a key pair for the client (`client.crt`, `client.key`) signed by the same certificate authority.
+The same files mentioned in the first example are needed for this, as well as a key pair for the client (`client.crt`, `client.key`) signed by the same certificate authority.
 
 ```sh
 $ etcd --name infra0 --data-dir infra0 \
@@ -99,7 +99,7 @@ $ curl --cacert /path/to/ca.crt --cert /path/to/client.crt --key /path/to/client
   -L https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v
 ```
 
-You should be able to see:
+The output should include:
 
 ```
 ...
@@ -145,7 +145,7 @@ $ etcd --name infra2 --data-dir infra2 \
   --discovery ${DISCOVERY_URL}
 ```
 
-The etcd members will form a cluster and all communication between members in the cluster will be encrypted and authenticated using the client certificates. You will see in the output of etcd that the addresses it connects to use HTTPS.
+The etcd members will form a cluster and all communication between members in the cluster will be encrypted and authenticated using the client certificates. The output of etcd will show that the addresses it connects to use HTTPS.
 
 ## Example 4: Automatic self-signed transport security
 
@@ -198,7 +198,7 @@ To use the certificate public key to do client auth, we need to add `clientAuth`
 
 Here is how to do it:
 
-Add the following section to your openssl.cnf:
+Add the following section to openssl.cnf:
 
 ```
 [ ssl_client ]
@@ -214,9 +214,9 @@ $ openssl ca -config openssl.cnf -policy policy_anything -extensions ssl_client
 ```
 
 ### With peer certificate authentication I receive "certificate is valid for 127.0.0.1, not $MY_IP"
-Make sure that you sign your certificates with a Subject Name your member's public IP address. The `etcd-ca` tool for example provides an `--ip=` option for its `new-cert` command.
+Make sure to sign the certificates with a Subject Name the member's public IP address. The `etcd-ca` tool for example provides an `--ip=` option for its `new-cert` command.
 
-If you need your certificate to be signed for your member's FQDN in its Subject Name then you could use Subject Alternative Names (short IP SANs) to add your IP address. The `etcd-ca` tool provides `--domain=` option for its `new-cert` command, and openssl can make [it][alt-name] too.
+The certificate needs to be signed for the member's FQDN in its Subject Name, use Subject Alternative Names (short IP SANs) to add the IP address. The `etcd-ca` tool provides `--domain=` option for its `new-cert` command, and openssl can make [it][alt-name] too.
 
 [cfssl]: https://github.com/cloudflare/cfssl
 [tls-setup]: /hack/tls-setup
diff --git a/Documentation/production-users.md b/Documentation/production-users.md
index 43e311b..daf1344 100644
--- a/Documentation/production-users.md
+++ b/Documentation/production-users.md
@@ -1,6 +1,6 @@
 # Production Users
 
-This document tracks people and use cases for etcd in production. By creating a list of production use cases we hope to build a community of advisors that we can reach out to with experience using various etcd applications, operation environments, and cluster sizes. The etcd development team may reach out periodically to check-in on your experience and update this list.
+This document tracks people and use cases for etcd in production. By creating a list of production use cases we hope to build a community of advisors that we can reach out to with experience using various etcd applications, operation environments, and cluster sizes. The etcd development team may reach out periodically to check-in on how etcd is working in the field and update this list.
 
 ## discovery.etcd.io
 
diff --git a/Documentation/reporting_bugs.md b/Documentation/reporting_bugs.md
index 0187ab0..5ceddcb 100644
--- a/Documentation/reporting_bugs.md
+++ b/Documentation/reporting_bugs.md
@@ -1,22 +1,22 @@
 # Reporting Bugs
 
-If you find bugs or documentation mistakes in the etcd project, please let us know by [opening an issue][issue]. We treat bugs and mistakes very seriously and believe no issue is too small. Before creating a bug report, please check that an issue reporting the same problem does not already exist.
+If any part of the etcd project has bugs or documentation mistakes, please let us know by [opening an issue][issue]. We treat bugs and mistakes very seriously and believe no issue is too small. Before creating a bug report, please check that an issue reporting the same problem does not already exist.
 
-To make your bug report accurate and easy to understand, please try to create bug reports that are:
+To make the bug report accurate and easy to understand, please try to create bug reports that are:
 
-- Specific. Include as much details as possible: which version, what environment, what configuration, etc. You can also attach etcd log (the starting log with etcd configuration is especially important).
+- Specific. Include as much details as possible: which version, what environment, what configuration, etc. If the bug is related to running the etcd server, please attach the etcd log (the starting log with etcd configuration is especially important).
 
-- Reproducible. Include the steps to reproduce the problem. We understand some issues might be hard to reproduce, please includes the steps that might lead to the problem. You can also attach the affected etcd data dir and stack strace to the bug report.
+- Reproducible. Include the steps to reproduce the problem. We understand some issues might be hard to reproduce, please includes the steps that might lead to the problem. If possible, please attach the affected etcd data dir and stack strace to the bug report.
 
-- Isolated. Please try to isolate and reproduce the bug with minimum dependencies. It would significantly slow down the speed to fix a bug if too many dependencies are involved in a bug report. Debugging external systems that rely on etcd is out of scope, but we are happy to point you in the right direction or help you interact with etcd in the correct manner.
+- Isolated. Please try to isolate and reproduce the bug with minimum dependencies. It would significantly slow down the speed to fix a bug if too many dependencies are involved in a bug report. Debugging external systems that rely on etcd is out of scope, but we are happy to provide guidance in the right direction or help with using etcd itself.
 
 - Unique. Do not duplicate existing bug report.
 
 - Scoped. One bug per report. Do not follow up with another bug inside one report.
 
-You might also want to read [Elika Etemad’s article on filing good bug reports][filing-good-bugs] before creating a bug report.
+It may be worthwhile to read [Elika Etemad’s article on filing good bug reports][filing-good-bugs] before creating a bug report.
 
-We might ask you for further information to locate a bug. A duplicated bug report will be closed.
+We might ask for further information to locate a bug. A duplicated bug report will be closed.
 
 ## Frequently Asked Questions
 
@@ -39,7 +39,7 @@ $ sudo systemctl cat etcd2
 $ sudo journalctl -u etcd2
 ```
 
-Due to an upstream systemd bug, journald may miss the last few log lines when its process exit. If journalctl tells you that etcd stops without fatal or panic message, you could try `sudo journalctl -f -t etcd2` to get full log.
+Due to an upstream systemd bug, journald may miss the last few log lines when its processes exit. If journalctl says etcd stopped without fatal or panic message, try `sudo journalctl -f -t etcd2` to get full log.
 
 [etcd-issue]: https://github.com/coreos/etcd/issues/new
 [filing-good-bugs]: http://fantasai.inkedblade.net/style/talks/filing-good-bugs/
diff --git a/Documentation/tuning.md b/Documentation/tuning.md
index d388ee1..903d04d 100644
--- a/Documentation/tuning.md
+++ b/Documentation/tuning.md
@@ -1,7 +1,6 @@
 # Tuning
 
-The default settings in etcd should work well for installations on a local network where the average network latency is low.
-However, when using etcd across multiple data centers or over networks with high latency you may need to tweak the heartbeat interval and election timeout settings.
+The default settings in etcd should work well for installations on a local network where the average network latency is low. However, when using etcd across multiple data centers or over networks with high latency, the heartbeat interval and election timeout settings may need tuning.
 
 The network isn't the only source of latency. Each request and response may be impacted by slow disks on both the leader and follower. Each of these timeouts represents the total time from request to successful response from the other machine.
 
@@ -24,20 +23,20 @@ On the other side, a too high heartbeat interval leads to high election timeout.
 The easiest way to measure round-trip time (RTT) is to use [PING utility][ping].
 
 The election timeout should be set based on the heartbeat interval and average round-trip time between members.
-Election timeouts must be at least 10 times the round-trip time so it can account for variance in your network.
-For example, if the round-trip time between your members is 10ms then you should have at least a 100ms election timeout.
+Election timeouts must be at least 10 times the round-trip time so it can account for variance in the network.
+For example, if the round-trip time between members is 10ms then the election timeout should be at least 100ms.
 
-You should also set your election timeout to at least 5 to 10 times your heartbeat interval to account for variance in leader replication.
-For a heartbeat interval of 50ms you should set your election timeout to at least 250ms - 500ms.
+The election timeout should be set to at least 5 to 10 times the heartbeat interval to account for variance in leader replication.
+For a heartbeat interval of 50ms, set the election timeout to at least 250ms - 500ms.
 
 The upper limit of election timeout is 50000ms (50s), which should only be used when deploying a globally-distributed etcd cluster.
 A reasonable round-trip time for the continental United States is 130ms, and the time between US and Japan is around 350-400ms.
-If your network has uneven performance or regular packet delays/loss then it is possible that a couple of retries may be necessary to successfully send a packet. So 5s is a safe upper limit of global round-trip time.
+If the network has uneven performance or regular packet delays/loss then it is possible that a couple of retries may be necessary to successfully send a packet. So 5s is a safe upper limit of global round-trip time.
 As the election timeout should be an order of magnitude bigger than broadcast time, in the case of ~5s for a globally distributed cluster, then 50 seconds becomes a reasonable maximum.
 
 The heartbeat interval and election timeout value should be the same for all members in one cluster. Setting different values for etcd members may disrupt cluster stability.
 
-You can override the default values on the command line:
+The default values can be overridden on the command line:
 
 ```sh
 # Command line arguments:
@@ -62,7 +61,7 @@ These snapshots provide a way for etcd to compact the log by saving the current
 
 Creating snapshots can be expensive so they're only created after a given number of changes to etcd.
 By default, snapshots will be made after every 10,000 changes.
-If etcd's memory usage and disk usage are too high, you can lower the snapshot threshold by setting the following on the command line:
+If etcd's memory usage and disk usage are too high, try lowering the snapshot threshold by setting the following on the command line:
 
 ```sh
 # Command line arguments:
