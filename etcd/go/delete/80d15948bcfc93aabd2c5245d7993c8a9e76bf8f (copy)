commit 80d15948bcfc93aabd2c5245d7993c8a9e76bf8f
Author: Gyuho Lee <gyuhox@gmail.com>
Date:   Fri Jan 26 11:14:41 2018 -0800

    *: move "mvcc" to "internal/mvcc"
    
    Signed-off-by: Gyuho Lee <gyuhox@gmail.com>

diff --git a/auth/range_perm_cache.go b/auth/range_perm_cache.go
index 691b65b..62acdf2 100644
--- a/auth/range_perm_cache.go
+++ b/auth/range_perm_cache.go
@@ -16,7 +16,7 @@ package auth
 
 import (
 	"github.com/coreos/etcd/auth/authpb"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/pkg/adt"
 )
 
diff --git a/auth/store.go b/auth/store.go
index d379ffa..e935608 100644
--- a/auth/store.go
+++ b/auth/store.go
@@ -26,7 +26,7 @@ import (
 
 	"github.com/coreos/etcd/auth/authpb"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 
 	"github.com/coreos/pkg/capnslog"
 	"golang.org/x/crypto/bcrypt"
diff --git a/auth/store_test.go b/auth/store_test.go
index b4eaa5e..739d8fc 100644
--- a/auth/store_test.go
+++ b/auth/store_test.go
@@ -26,7 +26,7 @@ import (
 
 	"github.com/coreos/etcd/auth/authpb"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 
 	"golang.org/x/crypto/bcrypt"
 	"google.golang.org/grpc/metadata"
diff --git a/clientv3/concurrency/election.go b/clientv3/concurrency/election.go
index e18a0ed..84156a3 100644
--- a/clientv3/concurrency/election.go
+++ b/clientv3/concurrency/election.go
@@ -21,7 +21,7 @@ import (
 
 	v3 "github.com/coreos/etcd/clientv3"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 var (
diff --git a/clientv3/concurrency/key.go b/clientv3/concurrency/key.go
index 4b6e399..4d11ffe 100644
--- a/clientv3/concurrency/key.go
+++ b/clientv3/concurrency/key.go
@@ -20,7 +20,7 @@ import (
 
 	v3 "github.com/coreos/etcd/clientv3"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 func waitDelete(ctx context.Context, client *v3.Client, key string, rev int64) error {
diff --git a/clientv3/integration/kv_test.go b/clientv3/integration/kv_test.go
index 66de753..81630c5 100644
--- a/clientv3/integration/kv_test.go
+++ b/clientv3/integration/kv_test.go
@@ -26,7 +26,7 @@ import (
 	"github.com/coreos/etcd/clientv3"
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	"github.com/coreos/etcd/integration"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/pkg/testutil"
 
 	"google.golang.org/grpc"
diff --git a/clientv3/integration/maintenance_test.go b/clientv3/integration/maintenance_test.go
index d0ac326..7db1938 100644
--- a/clientv3/integration/maintenance_test.go
+++ b/clientv3/integration/maintenance_test.go
@@ -27,8 +27,8 @@ import (
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	"github.com/coreos/etcd/integration"
 	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/pkg/testutil"
 )
 
diff --git a/clientv3/integration/mirror_test.go b/clientv3/integration/mirror_test.go
index 01bfef1..9a2bac5 100644
--- a/clientv3/integration/mirror_test.go
+++ b/clientv3/integration/mirror_test.go
@@ -24,7 +24,7 @@ import (
 
 	"github.com/coreos/etcd/clientv3/mirror"
 	"github.com/coreos/etcd/integration"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/pkg/testutil"
 )
 
diff --git a/clientv3/integration/namespace_test.go b/clientv3/integration/namespace_test.go
index b952d33..f884b17 100644
--- a/clientv3/integration/namespace_test.go
+++ b/clientv3/integration/namespace_test.go
@@ -22,7 +22,7 @@ import (
 	"github.com/coreos/etcd/clientv3"
 	"github.com/coreos/etcd/clientv3/namespace"
 	"github.com/coreos/etcd/integration"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/pkg/testutil"
 )
 
diff --git a/clientv3/integration/watch_test.go b/clientv3/integration/watch_test.go
index f9ac47b..a3559fa 100644
--- a/clientv3/integration/watch_test.go
+++ b/clientv3/integration/watch_test.go
@@ -27,7 +27,7 @@ import (
 	"github.com/coreos/etcd/etcdserver/api/v3rpc"
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	"github.com/coreos/etcd/integration"
-	mvccpb "github.com/coreos/etcd/mvcc/mvccpb"
+	mvccpb "github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/pkg/testutil"
 
 	"google.golang.org/grpc"
diff --git a/clientv3/leasing/cache.go b/clientv3/leasing/cache.go
index 77a1d06..5df1d84 100644
--- a/clientv3/leasing/cache.go
+++ b/clientv3/leasing/cache.go
@@ -22,7 +22,7 @@ import (
 
 	v3 "github.com/coreos/etcd/clientv3"
 	v3pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 const revokeBackoff = 2 * time.Second
diff --git a/clientv3/leasing/kv.go b/clientv3/leasing/kv.go
index 051a8fc..0263207 100644
--- a/clientv3/leasing/kv.go
+++ b/clientv3/leasing/kv.go
@@ -24,7 +24,7 @@ import (
 	"github.com/coreos/etcd/clientv3/concurrency"
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 
 	"google.golang.org/grpc/codes"
 	"google.golang.org/grpc/status"
diff --git a/clientv3/watch.go b/clientv3/watch.go
index 312845c..9452d0d 100644
--- a/clientv3/watch.go
+++ b/clientv3/watch.go
@@ -22,7 +22,7 @@ import (
 
 	v3rpc "github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	mvccpb "github.com/coreos/etcd/mvcc/mvccpb"
+	mvccpb "github.com/coreos/etcd/internal/mvcc/mvccpb"
 
 	"google.golang.org/grpc"
 	"google.golang.org/grpc/codes"
diff --git a/clientv3/watch_test.go b/clientv3/watch_test.go
index 8d33805..1edb4a8 100644
--- a/clientv3/watch_test.go
+++ b/clientv3/watch_test.go
@@ -17,7 +17,7 @@ package clientv3
 import (
 	"testing"
 
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 func TestEvent(t *testing.T) {
diff --git a/contrib/recipes/barrier.go b/contrib/recipes/barrier.go
index 6e92817..7dc18cd 100644
--- a/contrib/recipes/barrier.go
+++ b/contrib/recipes/barrier.go
@@ -18,7 +18,7 @@ import (
 	"context"
 
 	v3 "github.com/coreos/etcd/clientv3"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 // Barrier creates a key in etcd to block processes, then deletes the key to
diff --git a/contrib/recipes/client.go b/contrib/recipes/client.go
index 111b0b4..79b23a8 100644
--- a/contrib/recipes/client.go
+++ b/contrib/recipes/client.go
@@ -19,7 +19,7 @@ import (
 	"errors"
 
 	v3 "github.com/coreos/etcd/clientv3"
-	spb "github.com/coreos/etcd/mvcc/mvccpb"
+	spb "github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 var (
diff --git a/contrib/recipes/double_barrier.go b/contrib/recipes/double_barrier.go
index 93cc61b..27ff76a 100644
--- a/contrib/recipes/double_barrier.go
+++ b/contrib/recipes/double_barrier.go
@@ -19,7 +19,7 @@ import (
 
 	"github.com/coreos/etcd/clientv3"
 	"github.com/coreos/etcd/clientv3/concurrency"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 // DoubleBarrier blocks processes on Enter until an expected count enters, then
diff --git a/contrib/recipes/priority_queue.go b/contrib/recipes/priority_queue.go
index 2378ce2..8be0db7 100644
--- a/contrib/recipes/priority_queue.go
+++ b/contrib/recipes/priority_queue.go
@@ -19,7 +19,7 @@ import (
 	"fmt"
 
 	v3 "github.com/coreos/etcd/clientv3"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 // PriorityQueue implements a multi-reader, multi-writer distributed queue.
diff --git a/contrib/recipes/queue.go b/contrib/recipes/queue.go
index 5d0423a..33a8f31 100644
--- a/contrib/recipes/queue.go
+++ b/contrib/recipes/queue.go
@@ -18,7 +18,7 @@ import (
 	"context"
 
 	v3 "github.com/coreos/etcd/clientv3"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 // Queue implements a multi-reader, multi-writer distributed queue.
diff --git a/contrib/recipes/rwmutex.go b/contrib/recipes/rwmutex.go
index 1213b7e..436ee09 100644
--- a/contrib/recipes/rwmutex.go
+++ b/contrib/recipes/rwmutex.go
@@ -19,7 +19,7 @@ import (
 
 	v3 "github.com/coreos/etcd/clientv3"
 	"github.com/coreos/etcd/clientv3/concurrency"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 type RWMutex struct {
diff --git a/contrib/recipes/watch.go b/contrib/recipes/watch.go
index 5367872..7226a8e 100644
--- a/contrib/recipes/watch.go
+++ b/contrib/recipes/watch.go
@@ -18,7 +18,7 @@ import (
 	"context"
 
 	"github.com/coreos/etcd/clientv3"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 // WaitEvents waits on a key until it observes the given events and returns the final one.
diff --git a/e2e/etcd_corrupt_test.go b/e2e/etcd_corrupt_test.go
index a2bbb4c..aa6020e 100644
--- a/e2e/etcd_corrupt_test.go
+++ b/e2e/etcd_corrupt_test.go
@@ -24,7 +24,7 @@ import (
 	"time"
 
 	"github.com/coreos/etcd/clientv3"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 
 	bolt "github.com/coreos/bbolt"
 )
diff --git a/etcdctl/ctlv3/command/defrag_command.go b/etcdctl/ctlv3/command/defrag_command.go
index a7e6f76..097da59 100644
--- a/etcdctl/ctlv3/command/defrag_command.go
+++ b/etcdctl/ctlv3/command/defrag_command.go
@@ -20,7 +20,7 @@ import (
 	"path/filepath"
 	"time"
 
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/spf13/cobra"
 )
 
diff --git a/etcdctl/ctlv3/command/make_mirror_command.go b/etcdctl/ctlv3/command/make_mirror_command.go
index 8afa479..030e558 100644
--- a/etcdctl/ctlv3/command/make_mirror_command.go
+++ b/etcdctl/ctlv3/command/make_mirror_command.go
@@ -25,7 +25,7 @@ import (
 	"github.com/coreos/etcd/clientv3"
 	"github.com/coreos/etcd/clientv3/mirror"
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 
 	"github.com/spf13/cobra"
 )
diff --git a/etcdctl/ctlv3/command/migrate_command.go b/etcdctl/ctlv3/command/migrate_command.go
index f7db0be..6b185e1 100644
--- a/etcdctl/ctlv3/command/migrate_command.go
+++ b/etcdctl/ctlv3/command/migrate_command.go
@@ -30,11 +30,11 @@ import (
 	"github.com/coreos/etcd/etcdserver/api"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
 	"github.com/coreos/etcd/etcdserver/membership"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/internal/raftsnap"
 	"github.com/coreos/etcd/internal/store"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
 	"github.com/coreos/etcd/pkg/pbutil"
 	"github.com/coreos/etcd/pkg/types"
 	"github.com/coreos/etcd/raft/raftpb"
diff --git a/etcdctl/ctlv3/command/printer_fields.go b/etcdctl/ctlv3/command/printer_fields.go
index 7351aa7..e8dbe3d 100644
--- a/etcdctl/ctlv3/command/printer_fields.go
+++ b/etcdctl/ctlv3/command/printer_fields.go
@@ -19,7 +19,7 @@ import (
 
 	v3 "github.com/coreos/etcd/clientv3"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	spb "github.com/coreos/etcd/mvcc/mvccpb"
+	spb "github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/snapshot"
 )
 
diff --git a/etcdctl/ctlv3/command/printer_protobuf.go b/etcdctl/ctlv3/command/printer_protobuf.go
index c5109c5..3557331 100644
--- a/etcdctl/ctlv3/command/printer_protobuf.go
+++ b/etcdctl/ctlv3/command/printer_protobuf.go
@@ -20,7 +20,7 @@ import (
 
 	v3 "github.com/coreos/etcd/clientv3"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	mvccpb "github.com/coreos/etcd/mvcc/mvccpb"
+	mvccpb "github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 type pbPrinter struct{ printer }
diff --git a/etcdctl/ctlv3/command/util.go b/etcdctl/ctlv3/command/util.go
index addd023..8c94a2d 100644
--- a/etcdctl/ctlv3/command/util.go
+++ b/etcdctl/ctlv3/command/util.go
@@ -20,7 +20,7 @@ import (
 	"fmt"
 	"regexp"
 
-	pb "github.com/coreos/etcd/mvcc/mvccpb"
+	pb "github.com/coreos/etcd/internal/mvcc/mvccpb"
 
 	"github.com/spf13/cobra"
 )
diff --git a/etcdserver/api/v2v3/store.go b/etcdserver/api/v2v3/store.go
index 5585065..8a33a15 100644
--- a/etcdserver/api/v2v3/store.go
+++ b/etcdserver/api/v2v3/store.go
@@ -24,8 +24,8 @@ import (
 	"github.com/coreos/etcd/clientv3"
 	"github.com/coreos/etcd/clientv3/concurrency"
 	etcdErr "github.com/coreos/etcd/error"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/internal/store"
-	"github.com/coreos/etcd/mvcc/mvccpb"
 )
 
 // store implements the Store interface for V2 using
diff --git a/etcdserver/api/v3election/v3electionpb/v3election.pb.go b/etcdserver/api/v3election/v3electionpb/v3election.pb.go
index e298e45..4033b0d 100644
--- a/etcdserver/api/v3election/v3electionpb/v3election.pb.go
+++ b/etcdserver/api/v3election/v3electionpb/v3election.pb.go
@@ -31,7 +31,7 @@ import (
 
 	etcdserverpb "github.com/coreos/etcd/etcdserver/etcdserverpb"
 
-	mvccpb "github.com/coreos/etcd/mvcc/mvccpb"
+	mvccpb "github.com/coreos/etcd/internal/mvcc/mvccpb"
 
 	context "golang.org/x/net/context"
 
diff --git a/etcdserver/api/v3rpc/maintenance.go b/etcdserver/api/v3rpc/maintenance.go
index 79fcf35..18ed30a 100644
--- a/etcdserver/api/v3rpc/maintenance.go
+++ b/etcdserver/api/v3rpc/maintenance.go
@@ -23,8 +23,8 @@ import (
 	"github.com/coreos/etcd/etcdserver"
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/pkg/types"
 	"github.com/coreos/etcd/raft"
 	"github.com/coreos/etcd/version"
diff --git a/etcdserver/api/v3rpc/util.go b/etcdserver/api/v3rpc/util.go
index 79c3559..bd092b3 100644
--- a/etcdserver/api/v3rpc/util.go
+++ b/etcdserver/api/v3rpc/util.go
@@ -23,7 +23,7 @@ import (
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	"github.com/coreos/etcd/etcdserver/membership"
 	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc"
+	"github.com/coreos/etcd/internal/mvcc"
 
 	"google.golang.org/grpc/codes"
 	"google.golang.org/grpc/status"
diff --git a/etcdserver/api/v3rpc/util_test.go b/etcdserver/api/v3rpc/util_test.go
index 8890b1d..ddc0858 100644
--- a/etcdserver/api/v3rpc/util_test.go
+++ b/etcdserver/api/v3rpc/util_test.go
@@ -20,7 +20,7 @@ import (
 	"testing"
 
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
-	"github.com/coreos/etcd/mvcc"
+	"github.com/coreos/etcd/internal/mvcc"
 
 	"google.golang.org/grpc/codes"
 	"google.golang.org/grpc/status"
diff --git a/etcdserver/api/v3rpc/watch.go b/etcdserver/api/v3rpc/watch.go
index 0d5a4c2..d8e05ee 100644
--- a/etcdserver/api/v3rpc/watch.go
+++ b/etcdserver/api/v3rpc/watch.go
@@ -24,8 +24,8 @@ import (
 	"github.com/coreos/etcd/etcdserver"
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 type watchServer struct {
diff --git a/etcdserver/apply.go b/etcdserver/apply.go
index 5cc1c69..a790992 100644
--- a/etcdserver/apply.go
+++ b/etcdserver/apply.go
@@ -23,8 +23,8 @@ import (
 	"github.com/coreos/etcd/auth"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
 	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/pkg/types"
 
 	"github.com/gogo/protobuf/proto"
diff --git a/etcdserver/apply_auth.go b/etcdserver/apply_auth.go
index b2ecc22..d95385a 100644
--- a/etcdserver/apply_auth.go
+++ b/etcdserver/apply_auth.go
@@ -20,7 +20,7 @@ import (
 	"github.com/coreos/etcd/auth"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
 	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc"
+	"github.com/coreos/etcd/internal/mvcc"
 )
 
 type authApplierV3 struct {
diff --git a/etcdserver/backend.go b/etcdserver/backend.go
index 2351b15..f6af4cb 100644
--- a/etcdserver/backend.go
+++ b/etcdserver/backend.go
@@ -20,9 +20,9 @@ import (
 	"time"
 
 	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/internal/raftsnap"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
 	"github.com/coreos/etcd/raft/raftpb"
 )
 
diff --git a/etcdserver/corrupt.go b/etcdserver/corrupt.go
index d998ec5..acd57a6 100644
--- a/etcdserver/corrupt.go
+++ b/etcdserver/corrupt.go
@@ -22,7 +22,7 @@ import (
 	"github.com/coreos/etcd/clientv3"
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc"
+	"github.com/coreos/etcd/internal/mvcc"
 	"github.com/coreos/etcd/pkg/types"
 )
 
diff --git a/etcdserver/etcdserverpb/rpc.pb.go b/etcdserver/etcdserverpb/rpc.pb.go
index 4074511..d0e59ca 100644
--- a/etcdserver/etcdserverpb/rpc.pb.go
+++ b/etcdserver/etcdserverpb/rpc.pb.go
@@ -12,7 +12,7 @@ import (
 
 	_ "github.com/gogo/protobuf/gogoproto"
 
-	mvccpb "github.com/coreos/etcd/mvcc/mvccpb"
+	mvccpb "github.com/coreos/etcd/internal/mvcc/mvccpb"
 
 	authpb "github.com/coreos/etcd/auth/authpb"
 
diff --git a/etcdserver/membership/cluster.go b/etcdserver/membership/cluster.go
index 4aa9396..84a8ffe 100644
--- a/etcdserver/membership/cluster.go
+++ b/etcdserver/membership/cluster.go
@@ -27,8 +27,8 @@ import (
 	"sync"
 	"time"
 
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/internal/store"
-	"github.com/coreos/etcd/mvcc/backend"
 	"github.com/coreos/etcd/pkg/netutil"
 	"github.com/coreos/etcd/pkg/types"
 	"github.com/coreos/etcd/raft"
diff --git a/etcdserver/membership/store.go b/etcdserver/membership/store.go
index 5e878a4..62e8813 100644
--- a/etcdserver/membership/store.go
+++ b/etcdserver/membership/store.go
@@ -19,8 +19,8 @@ import (
 	"fmt"
 	"path"
 
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/internal/store"
-	"github.com/coreos/etcd/mvcc/backend"
 	"github.com/coreos/etcd/pkg/types"
 
 	"github.com/coreos/go-semver/semver"
diff --git a/etcdserver/server.go b/etcdserver/server.go
index 0f075eb..87aeed6 100644
--- a/etcdserver/server.go
+++ b/etcdserver/server.go
@@ -40,10 +40,10 @@ import (
 	"github.com/coreos/etcd/internal/discovery"
 	"github.com/coreos/etcd/internal/lease"
 	"github.com/coreos/etcd/internal/lease/leasehttp"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/internal/raftsnap"
 	"github.com/coreos/etcd/internal/store"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
 	"github.com/coreos/etcd/pkg/fileutil"
 	"github.com/coreos/etcd/pkg/idutil"
 	"github.com/coreos/etcd/pkg/pbutil"
diff --git a/etcdserver/server_test.go b/etcdserver/server_test.go
index dc0bba8..3c51dcc 100644
--- a/etcdserver/server_test.go
+++ b/etcdserver/server_test.go
@@ -29,10 +29,10 @@ import (
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
 	"github.com/coreos/etcd/etcdserver/membership"
 	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/internal/raftsnap"
 	"github.com/coreos/etcd/internal/store"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
 	"github.com/coreos/etcd/pkg/fileutil"
 	"github.com/coreos/etcd/pkg/idutil"
 	"github.com/coreos/etcd/pkg/mock/mockstorage"
diff --git a/etcdserver/snapshot_merge.go b/etcdserver/snapshot_merge.go
index b238b4c..20894e8 100644
--- a/etcdserver/snapshot_merge.go
+++ b/etcdserver/snapshot_merge.go
@@ -17,8 +17,8 @@ package etcdserver
 import (
 	"io"
 
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/internal/raftsnap"
-	"github.com/coreos/etcd/mvcc/backend"
 	"github.com/coreos/etcd/raft/raftpb"
 )
 
diff --git a/etcdserver/v3_server.go b/etcdserver/v3_server.go
index 059e5f6..a668970 100644
--- a/etcdserver/v3_server.go
+++ b/etcdserver/v3_server.go
@@ -25,7 +25,7 @@ import (
 	"github.com/coreos/etcd/etcdserver/membership"
 	"github.com/coreos/etcd/internal/lease"
 	"github.com/coreos/etcd/internal/lease/leasehttp"
-	"github.com/coreos/etcd/mvcc"
+	"github.com/coreos/etcd/internal/mvcc"
 	"github.com/coreos/etcd/raft"
 
 	"github.com/gogo/protobuf/proto"
diff --git a/integration/v3_alarm_test.go b/integration/v3_alarm_test.go
index 0dbaf6b..6a1fe0a 100644
--- a/integration/v3_alarm_test.go
+++ b/integration/v3_alarm_test.go
@@ -24,8 +24,8 @@ import (
 
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/pkg/testutil"
 )
 
diff --git a/integration/v3_lease_test.go b/integration/v3_lease_test.go
index 7ec2d3c..85e5c2f 100644
--- a/integration/v3_lease_test.go
+++ b/integration/v3_lease_test.go
@@ -22,7 +22,7 @@ import (
 
 	"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/pkg/testutil"
 
 	"google.golang.org/grpc/metadata"
diff --git a/integration/v3_lock_test.go b/integration/v3_lock_test.go
index 889a6ef..c9b00b7 100644
--- a/integration/v3_lock_test.go
+++ b/integration/v3_lock_test.go
@@ -24,7 +24,7 @@ import (
 	"github.com/coreos/etcd/clientv3"
 	"github.com/coreos/etcd/clientv3/concurrency"
 	"github.com/coreos/etcd/contrib/recipes"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/pkg/testutil"
 )
 
diff --git a/integration/v3_watch_test.go b/integration/v3_watch_test.go
index c91f4df..b6d7cfe 100644
--- a/integration/v3_watch_test.go
+++ b/integration/v3_watch_test.go
@@ -26,7 +26,7 @@ import (
 
 	"github.com/coreos/etcd/etcdserver/api/v3rpc"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 	"github.com/coreos/etcd/pkg/testutil"
 )
 
diff --git a/internal/alarm/alarms.go b/internal/alarm/alarms.go
index 4f0ebe9..58da777 100644
--- a/internal/alarm/alarms.go
+++ b/internal/alarm/alarms.go
@@ -19,7 +19,7 @@ import (
 	"sync"
 
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/pkg/types"
 	"github.com/coreos/pkg/capnslog"
 )
diff --git a/internal/compactor/periodic.go b/internal/compactor/periodic.go
index 447352e..c2ebbe8 100644
--- a/internal/compactor/periodic.go
+++ b/internal/compactor/periodic.go
@@ -20,7 +20,7 @@ import (
 	"time"
 
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc"
+	"github.com/coreos/etcd/internal/mvcc"
 
 	"github.com/jonboulle/clockwork"
 )
diff --git a/internal/compactor/revision.go b/internal/compactor/revision.go
index 4a87614..54561e9 100644
--- a/internal/compactor/revision.go
+++ b/internal/compactor/revision.go
@@ -19,7 +19,7 @@ import (
 	"sync"
 
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc"
+	"github.com/coreos/etcd/internal/mvcc"
 
 	"github.com/jonboulle/clockwork"
 )
diff --git a/internal/lease/leasehttp/http_test.go b/internal/lease/leasehttp/http_test.go
index a839539..29b6035 100644
--- a/internal/lease/leasehttp/http_test.go
+++ b/internal/lease/leasehttp/http_test.go
@@ -24,7 +24,7 @@ import (
 	"time"
 
 	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 )
 
 func TestRenewHTTP(t *testing.T) {
diff --git a/internal/lease/lessor.go b/internal/lease/lessor.go
index 5134589..cdb60be 100644
--- a/internal/lease/lessor.go
+++ b/internal/lease/lessor.go
@@ -23,7 +23,7 @@ import (
 	"time"
 
 	"github.com/coreos/etcd/internal/lease/leasepb"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 )
 
 // NoLease is a special LeaseID representing the absence of a lease.
diff --git a/internal/lease/lessor_test.go b/internal/lease/lessor_test.go
index 3f6a5ce..3c6b9d1 100644
--- a/internal/lease/lessor_test.go
+++ b/internal/lease/lessor_test.go
@@ -25,7 +25,7 @@ import (
 	"testing"
 	"time"
 
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 )
 
 const (
diff --git a/internal/mvcc/backend/backend.go b/internal/mvcc/backend/backend.go
new file mode 100644
index 0000000..c0305cf
--- /dev/null
+++ b/internal/mvcc/backend/backend.go
@@ -0,0 +1,446 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package backend
+
+import (
+	"fmt"
+	"hash/crc32"
+	"io"
+	"io/ioutil"
+	"os"
+	"path/filepath"
+	"sync"
+	"sync/atomic"
+	"time"
+
+	bolt "github.com/coreos/bbolt"
+	"github.com/coreos/pkg/capnslog"
+)
+
+var (
+	defaultBatchLimit    = 10000
+	defaultBatchInterval = 100 * time.Millisecond
+
+	defragLimit = 10000
+
+	// initialMmapSize is the initial size of the mmapped region. Setting this larger than
+	// the potential max db size can prevent writer from blocking reader.
+	// This only works for linux.
+	initialMmapSize = uint64(10 * 1024 * 1024 * 1024)
+
+	plog = capnslog.NewPackageLogger("github.com/coreos/etcd", "mvcc/backend")
+
+	// minSnapshotWarningTimeout is the minimum threshold to trigger a long running snapshot warning.
+	minSnapshotWarningTimeout = time.Duration(30 * time.Second)
+)
+
+type Backend interface {
+	ReadTx() ReadTx
+	BatchTx() BatchTx
+
+	Snapshot() Snapshot
+	Hash(ignores map[IgnoreKey]struct{}) (uint32, error)
+	// Size returns the current size of the backend.
+	Size() int64
+	Defrag() error
+	ForceCommit()
+	Close() error
+}
+
+type Snapshot interface {
+	// Size gets the size of the snapshot.
+	Size() int64
+	// WriteTo writes the snapshot into the given writer.
+	WriteTo(w io.Writer) (n int64, err error)
+	// Close closes the snapshot.
+	Close() error
+}
+
+type backend struct {
+	// size and commits are used with atomic operations so they must be
+	// 64-bit aligned, otherwise 32-bit tests will crash
+
+	// size is the number of bytes in the backend
+	size int64
+	// commits counts number of commits since start
+	commits int64
+
+	mu sync.RWMutex
+	db *bolt.DB
+
+	batchInterval time.Duration
+	batchLimit    int
+	batchTx       *batchTxBuffered
+
+	readTx *readTx
+
+	stopc chan struct{}
+	donec chan struct{}
+}
+
+type BackendConfig struct {
+	// Path is the file path to the backend file.
+	Path string
+	// BatchInterval is the maximum time before flushing the BatchTx.
+	BatchInterval time.Duration
+	// BatchLimit is the maximum puts before flushing the BatchTx.
+	BatchLimit int
+	// MmapSize is the number of bytes to mmap for the backend.
+	MmapSize uint64
+}
+
+func DefaultBackendConfig() BackendConfig {
+	return BackendConfig{
+		BatchInterval: defaultBatchInterval,
+		BatchLimit:    defaultBatchLimit,
+		MmapSize:      initialMmapSize,
+	}
+}
+
+func New(bcfg BackendConfig) Backend {
+	return newBackend(bcfg)
+}
+
+func NewDefaultBackend(path string) Backend {
+	bcfg := DefaultBackendConfig()
+	bcfg.Path = path
+	return newBackend(bcfg)
+}
+
+func newBackend(bcfg BackendConfig) *backend {
+	bopts := &bolt.Options{}
+	if boltOpenOptions != nil {
+		*bopts = *boltOpenOptions
+	}
+	bopts.InitialMmapSize = bcfg.mmapSize()
+
+	db, err := bolt.Open(bcfg.Path, 0600, bopts)
+	if err != nil {
+		plog.Panicf("cannot open database at %s (%v)", bcfg.Path, err)
+	}
+
+	// In future, may want to make buffering optional for low-concurrency systems
+	// or dynamically swap between buffered/non-buffered depending on workload.
+	b := &backend{
+		db: db,
+
+		batchInterval: bcfg.BatchInterval,
+		batchLimit:    bcfg.BatchLimit,
+
+		readTx: &readTx{
+			buf: txReadBuffer{
+				txBuffer: txBuffer{make(map[string]*bucketBuffer)},
+			},
+			buckets: make(map[string]*bolt.Bucket),
+		},
+
+		stopc: make(chan struct{}),
+		donec: make(chan struct{}),
+	}
+	b.batchTx = newBatchTxBuffered(b)
+	go b.run()
+	return b
+}
+
+// BatchTx returns the current batch tx in coalescer. The tx can be used for read and
+// write operations. The write result can be retrieved within the same tx immediately.
+// The write result is isolated with other txs until the current one get committed.
+func (b *backend) BatchTx() BatchTx {
+	return b.batchTx
+}
+
+func (b *backend) ReadTx() ReadTx { return b.readTx }
+
+// ForceCommit forces the current batching tx to commit.
+func (b *backend) ForceCommit() {
+	b.batchTx.Commit()
+}
+
+func (b *backend) Snapshot() Snapshot {
+	b.batchTx.Commit()
+
+	b.mu.RLock()
+	defer b.mu.RUnlock()
+	tx, err := b.db.Begin(false)
+	if err != nil {
+		plog.Fatalf("cannot begin tx (%s)", err)
+	}
+
+	stopc, donec := make(chan struct{}), make(chan struct{})
+	dbBytes := tx.Size()
+	go func() {
+		defer close(donec)
+		// sendRateBytes is based on transferring snapshot data over a 1 gigabit/s connection
+		// assuming a min tcp throughput of 100MB/s.
+		var sendRateBytes int64 = 100 * 1024 * 1014
+		warningTimeout := time.Duration(int64((float64(dbBytes) / float64(sendRateBytes)) * float64(time.Second)))
+		if warningTimeout < minSnapshotWarningTimeout {
+			warningTimeout = minSnapshotWarningTimeout
+		}
+		start := time.Now()
+		ticker := time.NewTicker(warningTimeout)
+		defer ticker.Stop()
+		for {
+			select {
+			case <-ticker.C:
+				plog.Warningf("snapshotting is taking more than %v seconds to finish transferring %v MB [started at %v]", time.Since(start).Seconds(), float64(dbBytes)/float64(1024*1014), start)
+			case <-stopc:
+				snapshotDurations.Observe(time.Since(start).Seconds())
+				return
+			}
+		}
+	}()
+
+	return &snapshot{tx, stopc, donec}
+}
+
+type IgnoreKey struct {
+	Bucket string
+	Key    string
+}
+
+func (b *backend) Hash(ignores map[IgnoreKey]struct{}) (uint32, error) {
+	h := crc32.New(crc32.MakeTable(crc32.Castagnoli))
+
+	b.mu.RLock()
+	defer b.mu.RUnlock()
+	err := b.db.View(func(tx *bolt.Tx) error {
+		c := tx.Cursor()
+		for next, _ := c.First(); next != nil; next, _ = c.Next() {
+			b := tx.Bucket(next)
+			if b == nil {
+				return fmt.Errorf("cannot get hash of bucket %s", string(next))
+			}
+			h.Write(next)
+			b.ForEach(func(k, v []byte) error {
+				bk := IgnoreKey{Bucket: string(next), Key: string(k)}
+				if _, ok := ignores[bk]; !ok {
+					h.Write(k)
+					h.Write(v)
+				}
+				return nil
+			})
+		}
+		return nil
+	})
+
+	if err != nil {
+		return 0, err
+	}
+
+	return h.Sum32(), nil
+}
+
+func (b *backend) Size() int64 {
+	return atomic.LoadInt64(&b.size)
+}
+
+func (b *backend) run() {
+	defer close(b.donec)
+	t := time.NewTimer(b.batchInterval)
+	defer t.Stop()
+	for {
+		select {
+		case <-t.C:
+		case <-b.stopc:
+			b.batchTx.CommitAndStop()
+			return
+		}
+		b.batchTx.Commit()
+		t.Reset(b.batchInterval)
+	}
+}
+
+func (b *backend) Close() error {
+	close(b.stopc)
+	<-b.donec
+	return b.db.Close()
+}
+
+// Commits returns total number of commits since start
+func (b *backend) Commits() int64 {
+	return atomic.LoadInt64(&b.commits)
+}
+
+func (b *backend) Defrag() error {
+	err := b.defrag()
+	if err != nil {
+		return err
+	}
+
+	// commit to update metadata like db.size
+	b.batchTx.Commit()
+
+	return nil
+}
+
+func (b *backend) defrag() error {
+	// TODO: make this non-blocking?
+	// lock batchTx to ensure nobody is using previous tx, and then
+	// close previous ongoing tx.
+	b.batchTx.Lock()
+	defer b.batchTx.Unlock()
+
+	// lock database after lock tx to avoid deadlock.
+	b.mu.Lock()
+	defer b.mu.Unlock()
+
+	// block concurrent read requests while resetting tx
+	b.readTx.mu.Lock()
+	defer b.readTx.mu.Unlock()
+
+	b.batchTx.unsafeCommit(true)
+	b.batchTx.tx = nil
+
+	tmpdb, err := bolt.Open(b.db.Path()+".tmp", 0600, boltOpenOptions)
+	if err != nil {
+		return err
+	}
+
+	err = defragdb(b.db, tmpdb, defragLimit)
+
+	if err != nil {
+		tmpdb.Close()
+		os.RemoveAll(tmpdb.Path())
+		return err
+	}
+
+	dbp := b.db.Path()
+	tdbp := tmpdb.Path()
+
+	err = b.db.Close()
+	if err != nil {
+		plog.Fatalf("cannot close database (%s)", err)
+	}
+	err = tmpdb.Close()
+	if err != nil {
+		plog.Fatalf("cannot close database (%s)", err)
+	}
+	err = os.Rename(tdbp, dbp)
+	if err != nil {
+		plog.Fatalf("cannot rename database (%s)", err)
+	}
+
+	b.db, err = bolt.Open(dbp, 0600, boltOpenOptions)
+	if err != nil {
+		plog.Panicf("cannot open database at %s (%v)", dbp, err)
+	}
+	b.batchTx.tx, err = b.db.Begin(true)
+	if err != nil {
+		plog.Fatalf("cannot begin tx (%s)", err)
+	}
+
+	b.readTx.reset()
+	b.readTx.tx = b.unsafeBegin(false)
+	atomic.StoreInt64(&b.size, b.readTx.tx.Size())
+
+	return nil
+}
+
+func defragdb(odb, tmpdb *bolt.DB, limit int) error {
+	// open a tx on tmpdb for writes
+	tmptx, err := tmpdb.Begin(true)
+	if err != nil {
+		return err
+	}
+
+	// open a tx on old db for read
+	tx, err := odb.Begin(false)
+	if err != nil {
+		return err
+	}
+	defer tx.Rollback()
+
+	c := tx.Cursor()
+
+	count := 0
+	for next, _ := c.First(); next != nil; next, _ = c.Next() {
+		b := tx.Bucket(next)
+		if b == nil {
+			return fmt.Errorf("backend: cannot defrag bucket %s", string(next))
+		}
+
+		tmpb, berr := tmptx.CreateBucketIfNotExists(next)
+		if berr != nil {
+			return berr
+		}
+		tmpb.FillPercent = 0.9 // for seq write in for each
+
+		b.ForEach(func(k, v []byte) error {
+			count++
+			if count > limit {
+				err = tmptx.Commit()
+				if err != nil {
+					return err
+				}
+				tmptx, err = tmpdb.Begin(true)
+				if err != nil {
+					return err
+				}
+				tmpb = tmptx.Bucket(next)
+				tmpb.FillPercent = 0.9 // for seq write in for each
+
+				count = 0
+			}
+			return tmpb.Put(k, v)
+		})
+	}
+
+	return tmptx.Commit()
+}
+
+func (b *backend) begin(write bool) *bolt.Tx {
+	b.mu.RLock()
+	tx := b.unsafeBegin(write)
+	b.mu.RUnlock()
+	atomic.StoreInt64(&b.size, tx.Size())
+	return tx
+}
+
+func (b *backend) unsafeBegin(write bool) *bolt.Tx {
+	tx, err := b.db.Begin(write)
+	if err != nil {
+		plog.Fatalf("cannot begin tx (%s)", err)
+	}
+	return tx
+}
+
+// NewTmpBackend creates a backend implementation for testing.
+func NewTmpBackend(batchInterval time.Duration, batchLimit int) (*backend, string) {
+	dir, err := ioutil.TempDir(os.TempDir(), "etcd_backend_test")
+	if err != nil {
+		plog.Fatal(err)
+	}
+	tmpPath := filepath.Join(dir, "database")
+	bcfg := DefaultBackendConfig()
+	bcfg.Path, bcfg.BatchInterval, bcfg.BatchLimit = tmpPath, batchInterval, batchLimit
+	return newBackend(bcfg), tmpPath
+}
+
+func NewDefaultTmpBackend() (*backend, string) {
+	return NewTmpBackend(defaultBatchInterval, defaultBatchLimit)
+}
+
+type snapshot struct {
+	*bolt.Tx
+	stopc chan struct{}
+	donec chan struct{}
+}
+
+func (s *snapshot) Close() error {
+	close(s.stopc)
+	<-s.donec
+	return s.Tx.Rollback()
+}
diff --git a/internal/mvcc/backend/backend_bench_test.go b/internal/mvcc/backend/backend_bench_test.go
new file mode 100644
index 0000000..30b4751
--- /dev/null
+++ b/internal/mvcc/backend/backend_bench_test.go
@@ -0,0 +1,50 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package backend
+
+import (
+	"crypto/rand"
+	"os"
+	"testing"
+	"time"
+)
+
+func BenchmarkBackendPut(b *testing.B) {
+	backend, tmppath := NewTmpBackend(100*time.Millisecond, 10000)
+	defer backend.Close()
+	defer os.Remove(tmppath)
+
+	// prepare keys
+	keys := make([][]byte, b.N)
+	for i := 0; i < b.N; i++ {
+		keys[i] = make([]byte, 64)
+		rand.Read(keys[i])
+	}
+	value := make([]byte, 128)
+	rand.Read(value)
+
+	batchTx := backend.BatchTx()
+
+	batchTx.Lock()
+	batchTx.UnsafeCreateBucket([]byte("test"))
+	batchTx.Unlock()
+
+	b.ResetTimer()
+	for i := 0; i < b.N; i++ {
+		batchTx.Lock()
+		batchTx.UnsafePut([]byte("test"), keys[i], value)
+		batchTx.Unlock()
+	}
+}
diff --git a/internal/mvcc/backend/backend_test.go b/internal/mvcc/backend/backend_test.go
new file mode 100644
index 0000000..9bdec5c
--- /dev/null
+++ b/internal/mvcc/backend/backend_test.go
@@ -0,0 +1,306 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package backend
+
+import (
+	"fmt"
+	"io/ioutil"
+	"os"
+	"reflect"
+	"testing"
+	"time"
+
+	bolt "github.com/coreos/bbolt"
+)
+
+func TestBackendClose(t *testing.T) {
+	b, tmpPath := NewTmpBackend(time.Hour, 10000)
+	defer os.Remove(tmpPath)
+
+	// check close could work
+	done := make(chan struct{})
+	go func() {
+		err := b.Close()
+		if err != nil {
+			t.Errorf("close error = %v, want nil", err)
+		}
+		done <- struct{}{}
+	}()
+	select {
+	case <-done:
+	case <-time.After(10 * time.Second):
+		t.Errorf("failed to close database in 10s")
+	}
+}
+
+func TestBackendSnapshot(t *testing.T) {
+	b, tmpPath := NewTmpBackend(time.Hour, 10000)
+	defer cleanup(b, tmpPath)
+
+	tx := b.BatchTx()
+	tx.Lock()
+	tx.UnsafeCreateBucket([]byte("test"))
+	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
+	tx.Unlock()
+	b.ForceCommit()
+
+	// write snapshot to a new file
+	f, err := ioutil.TempFile(os.TempDir(), "etcd_backend_test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	snap := b.Snapshot()
+	defer snap.Close()
+	if _, err := snap.WriteTo(f); err != nil {
+		t.Fatal(err)
+	}
+	f.Close()
+
+	// bootstrap new backend from the snapshot
+	bcfg := DefaultBackendConfig()
+	bcfg.Path, bcfg.BatchInterval, bcfg.BatchLimit = f.Name(), time.Hour, 10000
+	nb := New(bcfg)
+	defer cleanup(nb, f.Name())
+
+	newTx := b.BatchTx()
+	newTx.Lock()
+	ks, _ := newTx.UnsafeRange([]byte("test"), []byte("foo"), []byte("goo"), 0)
+	if len(ks) != 1 {
+		t.Errorf("len(kvs) = %d, want 1", len(ks))
+	}
+	newTx.Unlock()
+}
+
+func TestBackendBatchIntervalCommit(t *testing.T) {
+	// start backend with super short batch interval so
+	// we do not need to wait long before commit to happen.
+	b, tmpPath := NewTmpBackend(time.Nanosecond, 10000)
+	defer cleanup(b, tmpPath)
+
+	pc := b.Commits()
+
+	tx := b.BatchTx()
+	tx.Lock()
+	tx.UnsafeCreateBucket([]byte("test"))
+	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
+	tx.Unlock()
+
+	for i := 0; i < 10; i++ {
+		if b.Commits() >= pc+1 {
+			break
+		}
+		time.Sleep(time.Duration(i*100) * time.Millisecond)
+	}
+
+	// check whether put happens via db view
+	b.db.View(func(tx *bolt.Tx) error {
+		bucket := tx.Bucket([]byte("test"))
+		if bucket == nil {
+			t.Errorf("bucket test does not exit")
+			return nil
+		}
+		v := bucket.Get([]byte("foo"))
+		if v == nil {
+			t.Errorf("foo key failed to written in backend")
+		}
+		return nil
+	})
+}
+
+func TestBackendDefrag(t *testing.T) {
+	b, tmpPath := NewDefaultTmpBackend()
+	defer cleanup(b, tmpPath)
+
+	tx := b.BatchTx()
+	tx.Lock()
+	tx.UnsafeCreateBucket([]byte("test"))
+	for i := 0; i < defragLimit+100; i++ {
+		tx.UnsafePut([]byte("test"), []byte(fmt.Sprintf("foo_%d", i)), []byte("bar"))
+	}
+	tx.Unlock()
+	b.ForceCommit()
+
+	// remove some keys to ensure the disk space will be reclaimed after defrag
+	tx = b.BatchTx()
+	tx.Lock()
+	for i := 0; i < 50; i++ {
+		tx.UnsafeDelete([]byte("test"), []byte(fmt.Sprintf("foo_%d", i)))
+	}
+	tx.Unlock()
+	b.ForceCommit()
+
+	size := b.Size()
+
+	// shrink and check hash
+	oh, err := b.Hash(nil)
+	if err != nil {
+		t.Fatal(err)
+	}
+
+	err = b.Defrag()
+	if err != nil {
+		t.Fatal(err)
+	}
+
+	nh, err := b.Hash(nil)
+	if err != nil {
+		t.Fatal(err)
+	}
+	if oh != nh {
+		t.Errorf("hash = %v, want %v", nh, oh)
+	}
+
+	nsize := b.Size()
+	if nsize >= size {
+		t.Errorf("new size = %v, want < %d", nsize, size)
+	}
+
+	// try put more keys after shrink.
+	tx = b.BatchTx()
+	tx.Lock()
+	tx.UnsafeCreateBucket([]byte("test"))
+	tx.UnsafePut([]byte("test"), []byte("more"), []byte("bar"))
+	tx.Unlock()
+	b.ForceCommit()
+}
+
+// TestBackendWriteback ensures writes are stored to the read txn on write txn unlock.
+func TestBackendWriteback(t *testing.T) {
+	b, tmpPath := NewDefaultTmpBackend()
+	defer cleanup(b, tmpPath)
+
+	tx := b.BatchTx()
+	tx.Lock()
+	tx.UnsafeCreateBucket([]byte("key"))
+	tx.UnsafePut([]byte("key"), []byte("abc"), []byte("bar"))
+	tx.UnsafePut([]byte("key"), []byte("def"), []byte("baz"))
+	tx.UnsafePut([]byte("key"), []byte("overwrite"), []byte("1"))
+	tx.Unlock()
+
+	// overwrites should be propagated too
+	tx.Lock()
+	tx.UnsafePut([]byte("key"), []byte("overwrite"), []byte("2"))
+	tx.Unlock()
+
+	keys := []struct {
+		key   []byte
+		end   []byte
+		limit int64
+
+		wkey [][]byte
+		wval [][]byte
+	}{
+		{
+			key: []byte("abc"),
+			end: nil,
+
+			wkey: [][]byte{[]byte("abc")},
+			wval: [][]byte{[]byte("bar")},
+		},
+		{
+			key: []byte("abc"),
+			end: []byte("def"),
+
+			wkey: [][]byte{[]byte("abc")},
+			wval: [][]byte{[]byte("bar")},
+		},
+		{
+			key: []byte("abc"),
+			end: []byte("deg"),
+
+			wkey: [][]byte{[]byte("abc"), []byte("def")},
+			wval: [][]byte{[]byte("bar"), []byte("baz")},
+		},
+		{
+			key:   []byte("abc"),
+			end:   []byte("\xff"),
+			limit: 1,
+
+			wkey: [][]byte{[]byte("abc")},
+			wval: [][]byte{[]byte("bar")},
+		},
+		{
+			key: []byte("abc"),
+			end: []byte("\xff"),
+
+			wkey: [][]byte{[]byte("abc"), []byte("def"), []byte("overwrite")},
+			wval: [][]byte{[]byte("bar"), []byte("baz"), []byte("2")},
+		},
+	}
+	rtx := b.ReadTx()
+	for i, tt := range keys {
+		rtx.Lock()
+		k, v := rtx.UnsafeRange([]byte("key"), tt.key, tt.end, tt.limit)
+		rtx.Unlock()
+		if !reflect.DeepEqual(tt.wkey, k) || !reflect.DeepEqual(tt.wval, v) {
+			t.Errorf("#%d: want k=%+v, v=%+v; got k=%+v, v=%+v", i, tt.wkey, tt.wval, k, v)
+		}
+	}
+}
+
+// TestBackendWritebackForEach checks that partially written / buffered
+// data is visited in the same order as fully committed data.
+func TestBackendWritebackForEach(t *testing.T) {
+	b, tmpPath := NewTmpBackend(time.Hour, 10000)
+	defer cleanup(b, tmpPath)
+
+	tx := b.BatchTx()
+	tx.Lock()
+	tx.UnsafeCreateBucket([]byte("key"))
+	for i := 0; i < 5; i++ {
+		k := []byte(fmt.Sprintf("%04d", i))
+		tx.UnsafePut([]byte("key"), k, []byte("bar"))
+	}
+	tx.Unlock()
+
+	// writeback
+	b.ForceCommit()
+
+	tx.Lock()
+	tx.UnsafeCreateBucket([]byte("key"))
+	for i := 5; i < 20; i++ {
+		k := []byte(fmt.Sprintf("%04d", i))
+		tx.UnsafePut([]byte("key"), k, []byte("bar"))
+	}
+	tx.Unlock()
+
+	seq := ""
+	getSeq := func(k, v []byte) error {
+		seq += string(k)
+		return nil
+	}
+	rtx := b.ReadTx()
+	rtx.Lock()
+	rtx.UnsafeForEach([]byte("key"), getSeq)
+	rtx.Unlock()
+
+	partialSeq := seq
+
+	seq = ""
+	b.ForceCommit()
+
+	tx.Lock()
+	tx.UnsafeForEach([]byte("key"), getSeq)
+	tx.Unlock()
+
+	if seq != partialSeq {
+		t.Fatalf("expected %q, got %q", seq, partialSeq)
+	}
+}
+
+func cleanup(b Backend, path string) {
+	b.Close()
+	os.Remove(path)
+}
diff --git a/internal/mvcc/backend/batch_tx.go b/internal/mvcc/backend/batch_tx.go
new file mode 100644
index 0000000..43ddc71
--- /dev/null
+++ b/internal/mvcc/backend/batch_tx.go
@@ -0,0 +1,260 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package backend
+
+import (
+	"bytes"
+	"math"
+	"sync"
+	"sync/atomic"
+	"time"
+
+	bolt "github.com/coreos/bbolt"
+)
+
+type BatchTx interface {
+	ReadTx
+	UnsafeCreateBucket(name []byte)
+	UnsafePut(bucketName []byte, key []byte, value []byte)
+	UnsafeSeqPut(bucketName []byte, key []byte, value []byte)
+	UnsafeDelete(bucketName []byte, key []byte)
+	// Commit commits a previous tx and begins a new writable one.
+	Commit()
+	// CommitAndStop commits the previous tx and does not create a new one.
+	CommitAndStop()
+}
+
+type batchTx struct {
+	sync.Mutex
+	tx      *bolt.Tx
+	backend *backend
+
+	pending int
+}
+
+func (t *batchTx) UnsafeCreateBucket(name []byte) {
+	_, err := t.tx.CreateBucket(name)
+	if err != nil && err != bolt.ErrBucketExists {
+		plog.Fatalf("cannot create bucket %s (%v)", name, err)
+	}
+	t.pending++
+}
+
+// UnsafePut must be called holding the lock on the tx.
+func (t *batchTx) UnsafePut(bucketName []byte, key []byte, value []byte) {
+	t.unsafePut(bucketName, key, value, false)
+}
+
+// UnsafeSeqPut must be called holding the lock on the tx.
+func (t *batchTx) UnsafeSeqPut(bucketName []byte, key []byte, value []byte) {
+	t.unsafePut(bucketName, key, value, true)
+}
+
+func (t *batchTx) unsafePut(bucketName []byte, key []byte, value []byte, seq bool) {
+	bucket := t.tx.Bucket(bucketName)
+	if bucket == nil {
+		plog.Fatalf("bucket %s does not exist", bucketName)
+	}
+	if seq {
+		// it is useful to increase fill percent when the workloads are mostly append-only.
+		// this can delay the page split and reduce space usage.
+		bucket.FillPercent = 0.9
+	}
+	if err := bucket.Put(key, value); err != nil {
+		plog.Fatalf("cannot put key into bucket (%v)", err)
+	}
+	t.pending++
+}
+
+// UnsafeRange must be called holding the lock on the tx.
+func (t *batchTx) UnsafeRange(bucketName, key, endKey []byte, limit int64) ([][]byte, [][]byte) {
+	bucket := t.tx.Bucket(bucketName)
+	if bucket == nil {
+		plog.Fatalf("bucket %s does not exist", bucketName)
+	}
+	return unsafeRange(bucket.Cursor(), key, endKey, limit)
+}
+
+func unsafeRange(c *bolt.Cursor, key, endKey []byte, limit int64) (keys [][]byte, vs [][]byte) {
+	if limit <= 0 {
+		limit = math.MaxInt64
+	}
+	var isMatch func(b []byte) bool
+	if len(endKey) > 0 {
+		isMatch = func(b []byte) bool { return bytes.Compare(b, endKey) < 0 }
+	} else {
+		isMatch = func(b []byte) bool { return bytes.Equal(b, key) }
+		limit = 1
+	}
+	for ck, cv := c.Seek(key); ck != nil && isMatch(ck); ck, cv = c.Next() {
+		vs = append(vs, cv)
+		keys = append(keys, ck)
+		if limit == int64(len(keys)) {
+			break
+		}
+	}
+	return keys, vs
+}
+
+// UnsafeDelete must be called holding the lock on the tx.
+func (t *batchTx) UnsafeDelete(bucketName []byte, key []byte) {
+	bucket := t.tx.Bucket(bucketName)
+	if bucket == nil {
+		plog.Fatalf("bucket %s does not exist", bucketName)
+	}
+	err := bucket.Delete(key)
+	if err != nil {
+		plog.Fatalf("cannot delete key from bucket (%v)", err)
+	}
+	t.pending++
+}
+
+// UnsafeForEach must be called holding the lock on the tx.
+func (t *batchTx) UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error {
+	return unsafeForEach(t.tx, bucketName, visitor)
+}
+
+func unsafeForEach(tx *bolt.Tx, bucket []byte, visitor func(k, v []byte) error) error {
+	if b := tx.Bucket(bucket); b != nil {
+		return b.ForEach(visitor)
+	}
+	return nil
+}
+
+// Commit commits a previous tx and begins a new writable one.
+func (t *batchTx) Commit() {
+	t.Lock()
+	defer t.Unlock()
+	t.commit(false)
+}
+
+// CommitAndStop commits the previous tx and does not create a new one.
+func (t *batchTx) CommitAndStop() {
+	t.Lock()
+	defer t.Unlock()
+	t.commit(true)
+}
+
+func (t *batchTx) Unlock() {
+	if t.pending >= t.backend.batchLimit {
+		t.commit(false)
+	}
+	t.Mutex.Unlock()
+}
+
+func (t *batchTx) commit(stop bool) {
+	// commit the last tx
+	if t.tx != nil {
+		if t.pending == 0 && !stop {
+			t.backend.mu.RLock()
+			defer t.backend.mu.RUnlock()
+
+			// t.tx.DB()==nil if 'CommitAndStop' calls 'batchTx.commit(true)',
+			// which initializes *bolt.Tx.db and *bolt.Tx.meta as nil; panics t.tx.Size().
+			// Server must make sure 'batchTx.commit(false)' does not follow
+			// 'batchTx.commit(true)' (e.g. stopping backend, and inflight Hash call).
+			atomic.StoreInt64(&t.backend.size, t.tx.Size())
+			return
+		}
+
+		start := time.Now()
+		// gofail: var beforeCommit struct{}
+		err := t.tx.Commit()
+		// gofail: var afterCommit struct{}
+		commitDurations.Observe(time.Since(start).Seconds())
+		atomic.AddInt64(&t.backend.commits, 1)
+
+		t.pending = 0
+		if err != nil {
+			plog.Fatalf("cannot commit tx (%s)", err)
+		}
+	}
+	if !stop {
+		t.tx = t.backend.begin(true)
+	}
+}
+
+type batchTxBuffered struct {
+	batchTx
+	buf txWriteBuffer
+}
+
+func newBatchTxBuffered(backend *backend) *batchTxBuffered {
+	tx := &batchTxBuffered{
+		batchTx: batchTx{backend: backend},
+		buf: txWriteBuffer{
+			txBuffer: txBuffer{make(map[string]*bucketBuffer)},
+			seq:      true,
+		},
+	}
+	tx.Commit()
+	return tx
+}
+
+func (t *batchTxBuffered) Unlock() {
+	if t.pending != 0 {
+		t.backend.readTx.mu.Lock()
+		t.buf.writeback(&t.backend.readTx.buf)
+		t.backend.readTx.mu.Unlock()
+		if t.pending >= t.backend.batchLimit {
+			t.commit(false)
+		}
+	}
+	t.batchTx.Unlock()
+}
+
+func (t *batchTxBuffered) Commit() {
+	t.Lock()
+	defer t.Unlock()
+	t.commit(false)
+}
+
+func (t *batchTxBuffered) CommitAndStop() {
+	t.Lock()
+	defer t.Unlock()
+	t.commit(true)
+}
+
+func (t *batchTxBuffered) commit(stop bool) {
+	// all read txs must be closed to acquire boltdb commit rwlock
+	t.backend.readTx.mu.Lock()
+	defer t.backend.readTx.mu.Unlock()
+	t.unsafeCommit(stop)
+}
+
+func (t *batchTxBuffered) unsafeCommit(stop bool) {
+	if t.backend.readTx.tx != nil {
+		if err := t.backend.readTx.tx.Rollback(); err != nil {
+			plog.Fatalf("cannot rollback tx (%s)", err)
+		}
+		t.backend.readTx.reset()
+	}
+
+	t.batchTx.commit(stop)
+
+	if !stop {
+		t.backend.readTx.tx = t.backend.begin(false)
+	}
+}
+
+func (t *batchTxBuffered) UnsafePut(bucketName []byte, key []byte, value []byte) {
+	t.batchTx.UnsafePut(bucketName, key, value)
+	t.buf.put(bucketName, key, value)
+}
+
+func (t *batchTxBuffered) UnsafeSeqPut(bucketName []byte, key []byte, value []byte) {
+	t.batchTx.UnsafeSeqPut(bucketName, key, value)
+	t.buf.putSeq(bucketName, key, value)
+}
diff --git a/internal/mvcc/backend/batch_tx_test.go b/internal/mvcc/backend/batch_tx_test.go
new file mode 100644
index 0000000..57549b9
--- /dev/null
+++ b/internal/mvcc/backend/batch_tx_test.go
@@ -0,0 +1,197 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package backend
+
+import (
+	"reflect"
+	"testing"
+	"time"
+
+	bolt "github.com/coreos/bbolt"
+)
+
+func TestBatchTxPut(t *testing.T) {
+	b, tmpPath := NewTmpBackend(time.Hour, 10000)
+	defer cleanup(b, tmpPath)
+
+	tx := b.batchTx
+	tx.Lock()
+	defer tx.Unlock()
+
+	// create bucket
+	tx.UnsafeCreateBucket([]byte("test"))
+
+	// put
+	v := []byte("bar")
+	tx.UnsafePut([]byte("test"), []byte("foo"), v)
+
+	// check put result before and after tx is committed
+	for k := 0; k < 2; k++ {
+		_, gv := tx.UnsafeRange([]byte("test"), []byte("foo"), nil, 0)
+		if !reflect.DeepEqual(gv[0], v) {
+			t.Errorf("v = %s, want %s", string(gv[0]), string(v))
+		}
+		tx.commit(false)
+	}
+}
+
+func TestBatchTxRange(t *testing.T) {
+	b, tmpPath := NewTmpBackend(time.Hour, 10000)
+	defer cleanup(b, tmpPath)
+
+	tx := b.batchTx
+	tx.Lock()
+	defer tx.Unlock()
+
+	tx.UnsafeCreateBucket([]byte("test"))
+	// put keys
+	allKeys := [][]byte{[]byte("foo"), []byte("foo1"), []byte("foo2")}
+	allVals := [][]byte{[]byte("bar"), []byte("bar1"), []byte("bar2")}
+	for i := range allKeys {
+		tx.UnsafePut([]byte("test"), allKeys[i], allVals[i])
+	}
+
+	tests := []struct {
+		key    []byte
+		endKey []byte
+		limit  int64
+
+		wkeys [][]byte
+		wvals [][]byte
+	}{
+		// single key
+		{
+			[]byte("foo"), nil, 0,
+			allKeys[:1], allVals[:1],
+		},
+		// single key, bad
+		{
+			[]byte("doo"), nil, 0,
+			nil, nil,
+		},
+		// key range
+		{
+			[]byte("foo"), []byte("foo1"), 0,
+			allKeys[:1], allVals[:1],
+		},
+		// key range, get all keys
+		{
+			[]byte("foo"), []byte("foo3"), 0,
+			allKeys, allVals,
+		},
+		// key range, bad
+		{
+			[]byte("goo"), []byte("goo3"), 0,
+			nil, nil,
+		},
+		// key range with effective limit
+		{
+			[]byte("foo"), []byte("foo3"), 1,
+			allKeys[:1], allVals[:1],
+		},
+		// key range with limit
+		{
+			[]byte("foo"), []byte("foo3"), 4,
+			allKeys, allVals,
+		},
+	}
+	for i, tt := range tests {
+		keys, vals := tx.UnsafeRange([]byte("test"), tt.key, tt.endKey, tt.limit)
+		if !reflect.DeepEqual(keys, tt.wkeys) {
+			t.Errorf("#%d: keys = %+v, want %+v", i, keys, tt.wkeys)
+		}
+		if !reflect.DeepEqual(vals, tt.wvals) {
+			t.Errorf("#%d: vals = %+v, want %+v", i, vals, tt.wvals)
+		}
+	}
+}
+
+func TestBatchTxDelete(t *testing.T) {
+	b, tmpPath := NewTmpBackend(time.Hour, 10000)
+	defer cleanup(b, tmpPath)
+
+	tx := b.batchTx
+	tx.Lock()
+	defer tx.Unlock()
+
+	tx.UnsafeCreateBucket([]byte("test"))
+	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
+
+	tx.UnsafeDelete([]byte("test"), []byte("foo"))
+
+	// check put result before and after tx is committed
+	for k := 0; k < 2; k++ {
+		ks, _ := tx.UnsafeRange([]byte("test"), []byte("foo"), nil, 0)
+		if len(ks) != 0 {
+			t.Errorf("keys on foo = %v, want nil", ks)
+		}
+		tx.commit(false)
+	}
+}
+
+func TestBatchTxCommit(t *testing.T) {
+	b, tmpPath := NewTmpBackend(time.Hour, 10000)
+	defer cleanup(b, tmpPath)
+
+	tx := b.batchTx
+	tx.Lock()
+	tx.UnsafeCreateBucket([]byte("test"))
+	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
+	tx.Unlock()
+
+	tx.Commit()
+
+	// check whether put happens via db view
+	b.db.View(func(tx *bolt.Tx) error {
+		bucket := tx.Bucket([]byte("test"))
+		if bucket == nil {
+			t.Errorf("bucket test does not exit")
+			return nil
+		}
+		v := bucket.Get([]byte("foo"))
+		if v == nil {
+			t.Errorf("foo key failed to written in backend")
+		}
+		return nil
+	})
+}
+
+func TestBatchTxBatchLimitCommit(t *testing.T) {
+	// start backend with batch limit 1 so one write can
+	// trigger a commit
+	b, tmpPath := NewTmpBackend(time.Hour, 1)
+	defer cleanup(b, tmpPath)
+
+	tx := b.batchTx
+	tx.Lock()
+	tx.UnsafeCreateBucket([]byte("test"))
+	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
+	tx.Unlock()
+
+	// batch limit commit should have been triggered
+	// check whether put happens via db view
+	b.db.View(func(tx *bolt.Tx) error {
+		bucket := tx.Bucket([]byte("test"))
+		if bucket == nil {
+			t.Errorf("bucket test does not exit")
+			return nil
+		}
+		v := bucket.Get([]byte("foo"))
+		if v == nil {
+			t.Errorf("foo key failed to written in backend")
+		}
+		return nil
+	})
+}
diff --git a/internal/mvcc/backend/config_default.go b/internal/mvcc/backend/config_default.go
new file mode 100644
index 0000000..edfed00
--- /dev/null
+++ b/internal/mvcc/backend/config_default.go
@@ -0,0 +1,23 @@
+// Copyright 2016 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+// +build !linux,!windows
+
+package backend
+
+import bolt "github.com/coreos/bbolt"
+
+var boltOpenOptions *bolt.Options = nil
+
+func (bcfg *BackendConfig) mmapSize() int { return int(bcfg.MmapSize) }
diff --git a/internal/mvcc/backend/config_linux.go b/internal/mvcc/backend/config_linux.go
new file mode 100644
index 0000000..b01785f
--- /dev/null
+++ b/internal/mvcc/backend/config_linux.go
@@ -0,0 +1,34 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package backend
+
+import (
+	"syscall"
+
+	bolt "github.com/coreos/bbolt"
+)
+
+// syscall.MAP_POPULATE on linux 2.6.23+ does sequential read-ahead
+// which can speed up entire-database read with boltdb. We want to
+// enable MAP_POPULATE for faster key-value store recovery in storage
+// package. If your kernel version is lower than 2.6.23
+// (https://github.com/torvalds/linux/releases/tag/v2.6.23), mmap might
+// silently ignore this flag. Please update your kernel to prevent this.
+var boltOpenOptions = &bolt.Options{
+	MmapFlags:      syscall.MAP_POPULATE,
+	NoFreelistSync: true,
+}
+
+func (bcfg *BackendConfig) mmapSize() int { return int(bcfg.MmapSize) }
diff --git a/internal/mvcc/backend/config_windows.go b/internal/mvcc/backend/config_windows.go
new file mode 100644
index 0000000..71d0270
--- /dev/null
+++ b/internal/mvcc/backend/config_windows.go
@@ -0,0 +1,26 @@
+// Copyright 2017 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+// +build windows
+
+package backend
+
+import bolt "github.com/coreos/bbolt"
+
+var boltOpenOptions *bolt.Options = nil
+
+// setting mmap size != 0 on windows will allocate the entire
+// mmap size for the file, instead of growing it. So, force 0.
+
+func (bcfg *BackendConfig) mmapSize() int { return 0 }
diff --git a/internal/mvcc/backend/doc.go b/internal/mvcc/backend/doc.go
new file mode 100644
index 0000000..9cc42fa
--- /dev/null
+++ b/internal/mvcc/backend/doc.go
@@ -0,0 +1,16 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+// Package backend defines a standard interface for etcd's backend MVCC storage.
+package backend
diff --git a/internal/mvcc/backend/metrics.go b/internal/mvcc/backend/metrics.go
new file mode 100644
index 0000000..30a3880
--- /dev/null
+++ b/internal/mvcc/backend/metrics.go
@@ -0,0 +1,41 @@
+// Copyright 2016 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package backend
+
+import "github.com/prometheus/client_golang/prometheus"
+
+var (
+	commitDurations = prometheus.NewHistogram(prometheus.HistogramOpts{
+		Namespace: "etcd",
+		Subsystem: "disk",
+		Name:      "backend_commit_duration_seconds",
+		Help:      "The latency distributions of commit called by backend.",
+		Buckets:   prometheus.ExponentialBuckets(0.001, 2, 14),
+	})
+
+	snapshotDurations = prometheus.NewHistogram(prometheus.HistogramOpts{
+		Namespace: "etcd",
+		Subsystem: "disk",
+		Name:      "backend_snapshot_duration_seconds",
+		Help:      "The latency distribution of backend snapshots.",
+		// 10 ms -> 655 seconds
+		Buckets: prometheus.ExponentialBuckets(.01, 2, 17),
+	})
+)
+
+func init() {
+	prometheus.MustRegister(commitDurations)
+	prometheus.MustRegister(snapshotDurations)
+}
diff --git a/internal/mvcc/backend/read_tx.go b/internal/mvcc/backend/read_tx.go
new file mode 100644
index 0000000..0536de7
--- /dev/null
+++ b/internal/mvcc/backend/read_tx.go
@@ -0,0 +1,120 @@
+// Copyright 2017 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package backend
+
+import (
+	"bytes"
+	"math"
+	"sync"
+
+	bolt "github.com/coreos/bbolt"
+)
+
+// safeRangeBucket is a hack to avoid inadvertently reading duplicate keys;
+// overwrites on a bucket should only fetch with limit=1, but safeRangeBucket
+// is known to never overwrite any key so range is safe.
+var safeRangeBucket = []byte("key")
+
+type ReadTx interface {
+	Lock()
+	Unlock()
+
+	UnsafeRange(bucketName []byte, key, endKey []byte, limit int64) (keys [][]byte, vals [][]byte)
+	UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error
+}
+
+type readTx struct {
+	// mu protects accesses to the txReadBuffer
+	mu  sync.RWMutex
+	buf txReadBuffer
+
+	// txmu protects accesses to buckets and tx on Range requests.
+	txmu    sync.RWMutex
+	tx      *bolt.Tx
+	buckets map[string]*bolt.Bucket
+}
+
+func (rt *readTx) Lock()   { rt.mu.RLock() }
+func (rt *readTx) Unlock() { rt.mu.RUnlock() }
+
+func (rt *readTx) UnsafeRange(bucketName, key, endKey []byte, limit int64) ([][]byte, [][]byte) {
+	if endKey == nil {
+		// forbid duplicates for single keys
+		limit = 1
+	}
+	if limit <= 0 {
+		limit = math.MaxInt64
+	}
+	if limit > 1 && !bytes.Equal(bucketName, safeRangeBucket) {
+		panic("do not use unsafeRange on non-keys bucket")
+	}
+	keys, vals := rt.buf.Range(bucketName, key, endKey, limit)
+	if int64(len(keys)) == limit {
+		return keys, vals
+	}
+
+	// find/cache bucket
+	bn := string(bucketName)
+	rt.txmu.RLock()
+	bucket, ok := rt.buckets[bn]
+	rt.txmu.RUnlock()
+	if !ok {
+		rt.txmu.Lock()
+		bucket = rt.tx.Bucket(bucketName)
+		rt.buckets[bn] = bucket
+		rt.txmu.Unlock()
+	}
+
+	// ignore missing bucket since may have been created in this batch
+	if bucket == nil {
+		return keys, vals
+	}
+	rt.txmu.Lock()
+	c := bucket.Cursor()
+	rt.txmu.Unlock()
+
+	k2, v2 := unsafeRange(c, key, endKey, limit-int64(len(keys)))
+	return append(k2, keys...), append(v2, vals...)
+}
+
+func (rt *readTx) UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error {
+	dups := make(map[string]struct{})
+	getDups := func(k, v []byte) error {
+		dups[string(k)] = struct{}{}
+		return nil
+	}
+	visitNoDup := func(k, v []byte) error {
+		if _, ok := dups[string(k)]; ok {
+			return nil
+		}
+		return visitor(k, v)
+	}
+	if err := rt.buf.ForEach(bucketName, getDups); err != nil {
+		return err
+	}
+	rt.txmu.Lock()
+	err := unsafeForEach(rt.tx, bucketName, visitNoDup)
+	rt.txmu.Unlock()
+	if err != nil {
+		return err
+	}
+	return rt.buf.ForEach(bucketName, visitor)
+}
+
+func (rt *readTx) reset() {
+	rt.buf.reset()
+	rt.buckets = make(map[string]*bolt.Bucket)
+	rt.tx = nil
+}
diff --git a/internal/mvcc/backend/tx_buffer.go b/internal/mvcc/backend/tx_buffer.go
new file mode 100644
index 0000000..56e885d
--- /dev/null
+++ b/internal/mvcc/backend/tx_buffer.go
@@ -0,0 +1,181 @@
+// Copyright 2017 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package backend
+
+import (
+	"bytes"
+	"sort"
+)
+
+// txBuffer handles functionality shared between txWriteBuffer and txReadBuffer.
+type txBuffer struct {
+	buckets map[string]*bucketBuffer
+}
+
+func (txb *txBuffer) reset() {
+	for k, v := range txb.buckets {
+		if v.used == 0 {
+			// demote
+			delete(txb.buckets, k)
+		}
+		v.used = 0
+	}
+}
+
+// txWriteBuffer buffers writes of pending updates that have not yet committed.
+type txWriteBuffer struct {
+	txBuffer
+	seq bool
+}
+
+func (txw *txWriteBuffer) put(bucket, k, v []byte) {
+	txw.seq = false
+	txw.putSeq(bucket, k, v)
+}
+
+func (txw *txWriteBuffer) putSeq(bucket, k, v []byte) {
+	b, ok := txw.buckets[string(bucket)]
+	if !ok {
+		b = newBucketBuffer()
+		txw.buckets[string(bucket)] = b
+	}
+	b.add(k, v)
+}
+
+func (txw *txWriteBuffer) writeback(txr *txReadBuffer) {
+	for k, wb := range txw.buckets {
+		rb, ok := txr.buckets[k]
+		if !ok {
+			delete(txw.buckets, k)
+			txr.buckets[k] = wb
+			continue
+		}
+		if !txw.seq && wb.used > 1 {
+			// assume no duplicate keys
+			sort.Sort(wb)
+		}
+		rb.merge(wb)
+	}
+	txw.reset()
+}
+
+// txReadBuffer accesses buffered updates.
+type txReadBuffer struct{ txBuffer }
+
+func (txr *txReadBuffer) Range(bucketName, key, endKey []byte, limit int64) ([][]byte, [][]byte) {
+	if b := txr.buckets[string(bucketName)]; b != nil {
+		return b.Range(key, endKey, limit)
+	}
+	return nil, nil
+}
+
+func (txr *txReadBuffer) ForEach(bucketName []byte, visitor func(k, v []byte) error) error {
+	if b := txr.buckets[string(bucketName)]; b != nil {
+		return b.ForEach(visitor)
+	}
+	return nil
+}
+
+type kv struct {
+	key []byte
+	val []byte
+}
+
+// bucketBuffer buffers key-value pairs that are pending commit.
+type bucketBuffer struct {
+	buf []kv
+	// used tracks number of elements in use so buf can be reused without reallocation.
+	used int
+}
+
+func newBucketBuffer() *bucketBuffer {
+	return &bucketBuffer{buf: make([]kv, 512), used: 0}
+}
+
+func (bb *bucketBuffer) Range(key, endKey []byte, limit int64) (keys [][]byte, vals [][]byte) {
+	f := func(i int) bool { return bytes.Compare(bb.buf[i].key, key) >= 0 }
+	idx := sort.Search(bb.used, f)
+	if idx < 0 {
+		return nil, nil
+	}
+	if len(endKey) == 0 {
+		if bytes.Equal(key, bb.buf[idx].key) {
+			keys = append(keys, bb.buf[idx].key)
+			vals = append(vals, bb.buf[idx].val)
+		}
+		return keys, vals
+	}
+	if bytes.Compare(endKey, bb.buf[idx].key) <= 0 {
+		return nil, nil
+	}
+	for i := idx; i < bb.used && int64(len(keys)) < limit; i++ {
+		if bytes.Compare(endKey, bb.buf[i].key) <= 0 {
+			break
+		}
+		keys = append(keys, bb.buf[i].key)
+		vals = append(vals, bb.buf[i].val)
+	}
+	return keys, vals
+}
+
+func (bb *bucketBuffer) ForEach(visitor func(k, v []byte) error) error {
+	for i := 0; i < bb.used; i++ {
+		if err := visitor(bb.buf[i].key, bb.buf[i].val); err != nil {
+			return err
+		}
+	}
+	return nil
+}
+
+func (bb *bucketBuffer) add(k, v []byte) {
+	bb.buf[bb.used].key, bb.buf[bb.used].val = k, v
+	bb.used++
+	if bb.used == len(bb.buf) {
+		buf := make([]kv, (3*len(bb.buf))/2)
+		copy(buf, bb.buf)
+		bb.buf = buf
+	}
+}
+
+// merge merges data from bb into bbsrc.
+func (bb *bucketBuffer) merge(bbsrc *bucketBuffer) {
+	for i := 0; i < bbsrc.used; i++ {
+		bb.add(bbsrc.buf[i].key, bbsrc.buf[i].val)
+	}
+	if bb.used == bbsrc.used {
+		return
+	}
+	if bytes.Compare(bb.buf[(bb.used-bbsrc.used)-1].key, bbsrc.buf[0].key) < 0 {
+		return
+	}
+
+	sort.Stable(bb)
+
+	// remove duplicates, using only newest update
+	widx := 0
+	for ridx := 1; ridx < bb.used; ridx++ {
+		if !bytes.Equal(bb.buf[ridx].key, bb.buf[widx].key) {
+			widx++
+		}
+		bb.buf[widx] = bb.buf[ridx]
+	}
+	bb.used = widx + 1
+}
+
+func (bb *bucketBuffer) Len() int { return bb.used }
+func (bb *bucketBuffer) Less(i, j int) bool {
+	return bytes.Compare(bb.buf[i].key, bb.buf[j].key) < 0
+}
+func (bb *bucketBuffer) Swap(i, j int) { bb.buf[i], bb.buf[j] = bb.buf[j], bb.buf[i] }
diff --git a/internal/mvcc/doc.go b/internal/mvcc/doc.go
new file mode 100644
index 0000000..ad5be03
--- /dev/null
+++ b/internal/mvcc/doc.go
@@ -0,0 +1,16 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+// Package mvcc defines etcd's stable MVCC storage.
+package mvcc
diff --git a/internal/mvcc/index.go b/internal/mvcc/index.go
new file mode 100644
index 0000000..b27a9e5
--- /dev/null
+++ b/internal/mvcc/index.go
@@ -0,0 +1,251 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"sort"
+	"sync"
+
+	"github.com/google/btree"
+)
+
+type index interface {
+	Get(key []byte, atRev int64) (rev, created revision, ver int64, err error)
+	Range(key, end []byte, atRev int64) ([][]byte, []revision)
+	Revisions(key, end []byte, atRev int64) []revision
+	Put(key []byte, rev revision)
+	Tombstone(key []byte, rev revision) error
+	RangeSince(key, end []byte, rev int64) []revision
+	Compact(rev int64) map[revision]struct{}
+	Keep(rev int64) map[revision]struct{}
+	Equal(b index) bool
+
+	Insert(ki *keyIndex)
+	KeyIndex(ki *keyIndex) *keyIndex
+}
+
+type treeIndex struct {
+	sync.RWMutex
+	tree *btree.BTree
+}
+
+func newTreeIndex() index {
+	return &treeIndex{
+		tree: btree.New(32),
+	}
+}
+
+func (ti *treeIndex) Put(key []byte, rev revision) {
+	keyi := &keyIndex{key: key}
+
+	ti.Lock()
+	defer ti.Unlock()
+	item := ti.tree.Get(keyi)
+	if item == nil {
+		keyi.put(rev.main, rev.sub)
+		ti.tree.ReplaceOrInsert(keyi)
+		return
+	}
+	okeyi := item.(*keyIndex)
+	okeyi.put(rev.main, rev.sub)
+}
+
+func (ti *treeIndex) Get(key []byte, atRev int64) (modified, created revision, ver int64, err error) {
+	keyi := &keyIndex{key: key}
+	ti.RLock()
+	defer ti.RUnlock()
+	if keyi = ti.keyIndex(keyi); keyi == nil {
+		return revision{}, revision{}, 0, ErrRevisionNotFound
+	}
+	return keyi.get(atRev)
+}
+
+func (ti *treeIndex) KeyIndex(keyi *keyIndex) *keyIndex {
+	ti.RLock()
+	defer ti.RUnlock()
+	return ti.keyIndex(keyi)
+}
+
+func (ti *treeIndex) keyIndex(keyi *keyIndex) *keyIndex {
+	if item := ti.tree.Get(keyi); item != nil {
+		return item.(*keyIndex)
+	}
+	return nil
+}
+
+func (ti *treeIndex) visit(key, end []byte, f func(ki *keyIndex)) {
+	keyi, endi := &keyIndex{key: key}, &keyIndex{key: end}
+
+	ti.RLock()
+	defer ti.RUnlock()
+
+	ti.tree.AscendGreaterOrEqual(keyi, func(item btree.Item) bool {
+		if len(endi.key) > 0 && !item.Less(endi) {
+			return false
+		}
+		f(item.(*keyIndex))
+		return true
+	})
+}
+
+func (ti *treeIndex) Revisions(key, end []byte, atRev int64) (revs []revision) {
+	if end == nil {
+		rev, _, _, err := ti.Get(key, atRev)
+		if err != nil {
+			return nil
+		}
+		return []revision{rev}
+	}
+	ti.visit(key, end, func(ki *keyIndex) {
+		if rev, _, _, err := ki.get(atRev); err == nil {
+			revs = append(revs, rev)
+		}
+	})
+	return revs
+}
+
+func (ti *treeIndex) Range(key, end []byte, atRev int64) (keys [][]byte, revs []revision) {
+	if end == nil {
+		rev, _, _, err := ti.Get(key, atRev)
+		if err != nil {
+			return nil, nil
+		}
+		return [][]byte{key}, []revision{rev}
+	}
+	ti.visit(key, end, func(ki *keyIndex) {
+		if rev, _, _, err := ki.get(atRev); err == nil {
+			revs = append(revs, rev)
+			keys = append(keys, ki.key)
+		}
+	})
+	return keys, revs
+}
+
+func (ti *treeIndex) Tombstone(key []byte, rev revision) error {
+	keyi := &keyIndex{key: key}
+
+	ti.Lock()
+	defer ti.Unlock()
+	item := ti.tree.Get(keyi)
+	if item == nil {
+		return ErrRevisionNotFound
+	}
+
+	ki := item.(*keyIndex)
+	return ki.tombstone(rev.main, rev.sub)
+}
+
+// RangeSince returns all revisions from key(including) to end(excluding)
+// at or after the given rev. The returned slice is sorted in the order
+// of revision.
+func (ti *treeIndex) RangeSince(key, end []byte, rev int64) []revision {
+	keyi := &keyIndex{key: key}
+
+	ti.RLock()
+	defer ti.RUnlock()
+
+	if end == nil {
+		item := ti.tree.Get(keyi)
+		if item == nil {
+			return nil
+		}
+		keyi = item.(*keyIndex)
+		return keyi.since(rev)
+	}
+
+	endi := &keyIndex{key: end}
+	var revs []revision
+	ti.tree.AscendGreaterOrEqual(keyi, func(item btree.Item) bool {
+		if len(endi.key) > 0 && !item.Less(endi) {
+			return false
+		}
+		curKeyi := item.(*keyIndex)
+		revs = append(revs, curKeyi.since(rev)...)
+		return true
+	})
+	sort.Sort(revisions(revs))
+
+	return revs
+}
+
+func (ti *treeIndex) Compact(rev int64) map[revision]struct{} {
+	available := make(map[revision]struct{})
+	var emptyki []*keyIndex
+	plog.Printf("store.index: compact %d", rev)
+	// TODO: do not hold the lock for long time?
+	// This is probably OK. Compacting 10M keys takes O(10ms).
+	ti.Lock()
+	defer ti.Unlock()
+	ti.tree.Ascend(compactIndex(rev, available, &emptyki))
+	for _, ki := range emptyki {
+		item := ti.tree.Delete(ki)
+		if item == nil {
+			plog.Panic("store.index: unexpected delete failure during compaction")
+		}
+	}
+	return available
+}
+
+// Keep finds all revisions to be kept for a Compaction at the given rev.
+func (ti *treeIndex) Keep(rev int64) map[revision]struct{} {
+	available := make(map[revision]struct{})
+	ti.RLock()
+	defer ti.RUnlock()
+	ti.tree.Ascend(func(i btree.Item) bool {
+		keyi := i.(*keyIndex)
+		keyi.keep(rev, available)
+		return true
+	})
+	return available
+}
+
+func compactIndex(rev int64, available map[revision]struct{}, emptyki *[]*keyIndex) func(i btree.Item) bool {
+	return func(i btree.Item) bool {
+		keyi := i.(*keyIndex)
+		keyi.compact(rev, available)
+		if keyi.isEmpty() {
+			*emptyki = append(*emptyki, keyi)
+		}
+		return true
+	}
+}
+
+func (ti *treeIndex) Equal(bi index) bool {
+	b := bi.(*treeIndex)
+
+	if ti.tree.Len() != b.tree.Len() {
+		return false
+	}
+
+	equal := true
+
+	ti.tree.Ascend(func(item btree.Item) bool {
+		aki := item.(*keyIndex)
+		bki := b.tree.Get(item).(*keyIndex)
+		if !aki.equal(bki) {
+			equal = false
+			return false
+		}
+		return true
+	})
+
+	return equal
+}
+
+func (ti *treeIndex) Insert(ki *keyIndex) {
+	ti.Lock()
+	defer ti.Unlock()
+	ti.tree.ReplaceOrInsert(ki)
+}
diff --git a/internal/mvcc/index_test.go b/internal/mvcc/index_test.go
new file mode 100644
index 0000000..d053156
--- /dev/null
+++ b/internal/mvcc/index_test.go
@@ -0,0 +1,292 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"reflect"
+	"testing"
+
+	"github.com/google/btree"
+)
+
+func TestIndexGet(t *testing.T) {
+	ti := newTreeIndex()
+	ti.Put([]byte("foo"), revision{main: 2})
+	ti.Put([]byte("foo"), revision{main: 4})
+	ti.Tombstone([]byte("foo"), revision{main: 6})
+
+	tests := []struct {
+		rev int64
+
+		wrev     revision
+		wcreated revision
+		wver     int64
+		werr     error
+	}{
+		{0, revision{}, revision{}, 0, ErrRevisionNotFound},
+		{1, revision{}, revision{}, 0, ErrRevisionNotFound},
+		{2, revision{main: 2}, revision{main: 2}, 1, nil},
+		{3, revision{main: 2}, revision{main: 2}, 1, nil},
+		{4, revision{main: 4}, revision{main: 2}, 2, nil},
+		{5, revision{main: 4}, revision{main: 2}, 2, nil},
+		{6, revision{}, revision{}, 0, ErrRevisionNotFound},
+	}
+	for i, tt := range tests {
+		rev, created, ver, err := ti.Get([]byte("foo"), tt.rev)
+		if err != tt.werr {
+			t.Errorf("#%d: err = %v, want %v", i, err, tt.werr)
+		}
+		if rev != tt.wrev {
+			t.Errorf("#%d: rev = %+v, want %+v", i, rev, tt.wrev)
+		}
+		if created != tt.wcreated {
+			t.Errorf("#%d: created = %+v, want %+v", i, created, tt.wcreated)
+		}
+		if ver != tt.wver {
+			t.Errorf("#%d: ver = %d, want %d", i, ver, tt.wver)
+		}
+	}
+}
+
+func TestIndexRange(t *testing.T) {
+	allKeys := [][]byte{[]byte("foo"), []byte("foo1"), []byte("foo2")}
+	allRevs := []revision{{main: 1}, {main: 2}, {main: 3}}
+
+	ti := newTreeIndex()
+	for i := range allKeys {
+		ti.Put(allKeys[i], allRevs[i])
+	}
+
+	atRev := int64(3)
+	tests := []struct {
+		key, end []byte
+		wkeys    [][]byte
+		wrevs    []revision
+	}{
+		// single key that not found
+		{
+			[]byte("bar"), nil, nil, nil,
+		},
+		// single key that found
+		{
+			[]byte("foo"), nil, allKeys[:1], allRevs[:1],
+		},
+		// range keys, return first member
+		{
+			[]byte("foo"), []byte("foo1"), allKeys[:1], allRevs[:1],
+		},
+		// range keys, return first two members
+		{
+			[]byte("foo"), []byte("foo2"), allKeys[:2], allRevs[:2],
+		},
+		// range keys, return all members
+		{
+			[]byte("foo"), []byte("fop"), allKeys, allRevs,
+		},
+		// range keys, return last two members
+		{
+			[]byte("foo1"), []byte("fop"), allKeys[1:], allRevs[1:],
+		},
+		// range keys, return last member
+		{
+			[]byte("foo2"), []byte("fop"), allKeys[2:], allRevs[2:],
+		},
+		// range keys, return nothing
+		{
+			[]byte("foo3"), []byte("fop"), nil, nil,
+		},
+	}
+	for i, tt := range tests {
+		keys, revs := ti.Range(tt.key, tt.end, atRev)
+		if !reflect.DeepEqual(keys, tt.wkeys) {
+			t.Errorf("#%d: keys = %+v, want %+v", i, keys, tt.wkeys)
+		}
+		if !reflect.DeepEqual(revs, tt.wrevs) {
+			t.Errorf("#%d: revs = %+v, want %+v", i, revs, tt.wrevs)
+		}
+	}
+}
+
+func TestIndexTombstone(t *testing.T) {
+	ti := newTreeIndex()
+	ti.Put([]byte("foo"), revision{main: 1})
+
+	err := ti.Tombstone([]byte("foo"), revision{main: 2})
+	if err != nil {
+		t.Errorf("tombstone error = %v, want nil", err)
+	}
+
+	_, _, _, err = ti.Get([]byte("foo"), 2)
+	if err != ErrRevisionNotFound {
+		t.Errorf("get error = %v, want nil", err)
+	}
+	err = ti.Tombstone([]byte("foo"), revision{main: 3})
+	if err != ErrRevisionNotFound {
+		t.Errorf("tombstone error = %v, want %v", err, ErrRevisionNotFound)
+	}
+}
+
+func TestIndexRangeSince(t *testing.T) {
+	allKeys := [][]byte{[]byte("foo"), []byte("foo1"), []byte("foo2"), []byte("foo2"), []byte("foo1"), []byte("foo")}
+	allRevs := []revision{{main: 1}, {main: 2}, {main: 3}, {main: 4}, {main: 5}, {main: 6}}
+
+	ti := newTreeIndex()
+	for i := range allKeys {
+		ti.Put(allKeys[i], allRevs[i])
+	}
+
+	atRev := int64(1)
+	tests := []struct {
+		key, end []byte
+		wrevs    []revision
+	}{
+		// single key that not found
+		{
+			[]byte("bar"), nil, nil,
+		},
+		// single key that found
+		{
+			[]byte("foo"), nil, []revision{{main: 1}, {main: 6}},
+		},
+		// range keys, return first member
+		{
+			[]byte("foo"), []byte("foo1"), []revision{{main: 1}, {main: 6}},
+		},
+		// range keys, return first two members
+		{
+			[]byte("foo"), []byte("foo2"), []revision{{main: 1}, {main: 2}, {main: 5}, {main: 6}},
+		},
+		// range keys, return all members
+		{
+			[]byte("foo"), []byte("fop"), allRevs,
+		},
+		// range keys, return last two members
+		{
+			[]byte("foo1"), []byte("fop"), []revision{{main: 2}, {main: 3}, {main: 4}, {main: 5}},
+		},
+		// range keys, return last member
+		{
+			[]byte("foo2"), []byte("fop"), []revision{{main: 3}, {main: 4}},
+		},
+		// range keys, return nothing
+		{
+			[]byte("foo3"), []byte("fop"), nil,
+		},
+	}
+	for i, tt := range tests {
+		revs := ti.RangeSince(tt.key, tt.end, atRev)
+		if !reflect.DeepEqual(revs, tt.wrevs) {
+			t.Errorf("#%d: revs = %+v, want %+v", i, revs, tt.wrevs)
+		}
+	}
+}
+
+func TestIndexCompactAndKeep(t *testing.T) {
+	maxRev := int64(20)
+	tests := []struct {
+		key     []byte
+		remove  bool
+		rev     revision
+		created revision
+		ver     int64
+	}{
+		{[]byte("foo"), false, revision{main: 1}, revision{main: 1}, 1},
+		{[]byte("foo1"), false, revision{main: 2}, revision{main: 2}, 1},
+		{[]byte("foo2"), false, revision{main: 3}, revision{main: 3}, 1},
+		{[]byte("foo2"), false, revision{main: 4}, revision{main: 3}, 2},
+		{[]byte("foo"), false, revision{main: 5}, revision{main: 1}, 2},
+		{[]byte("foo1"), false, revision{main: 6}, revision{main: 2}, 2},
+		{[]byte("foo1"), true, revision{main: 7}, revision{}, 0},
+		{[]byte("foo2"), true, revision{main: 8}, revision{}, 0},
+		{[]byte("foo"), true, revision{main: 9}, revision{}, 0},
+		{[]byte("foo"), false, revision{10, 0}, revision{10, 0}, 1},
+		{[]byte("foo1"), false, revision{10, 1}, revision{10, 1}, 1},
+	}
+
+	// Continuous Compact and Keep
+	ti := newTreeIndex()
+	for _, tt := range tests {
+		if tt.remove {
+			ti.Tombstone(tt.key, tt.rev)
+		} else {
+			ti.Put(tt.key, tt.rev)
+		}
+	}
+	for i := int64(1); i < maxRev; i++ {
+		am := ti.Compact(i)
+		keep := ti.Keep(i)
+		if !(reflect.DeepEqual(am, keep)) {
+			t.Errorf("#%d: compact keep %v != Keep keep %v", i, am, keep)
+		}
+		wti := &treeIndex{tree: btree.New(32)}
+		for _, tt := range tests {
+			if _, ok := am[tt.rev]; ok || tt.rev.GreaterThan(revision{main: i}) {
+				if tt.remove {
+					wti.Tombstone(tt.key, tt.rev)
+				} else {
+					restore(wti, tt.key, tt.created, tt.rev, tt.ver)
+				}
+			}
+		}
+		if !ti.Equal(wti) {
+			t.Errorf("#%d: not equal ti", i)
+		}
+	}
+
+	// Once Compact and Keep
+	for i := int64(1); i < maxRev; i++ {
+		ti := newTreeIndex()
+		for _, tt := range tests {
+			if tt.remove {
+				ti.Tombstone(tt.key, tt.rev)
+			} else {
+				ti.Put(tt.key, tt.rev)
+			}
+		}
+		am := ti.Compact(i)
+		keep := ti.Keep(i)
+		if !(reflect.DeepEqual(am, keep)) {
+			t.Errorf("#%d: compact keep %v != Keep keep %v", i, am, keep)
+		}
+		wti := &treeIndex{tree: btree.New(32)}
+		for _, tt := range tests {
+			if _, ok := am[tt.rev]; ok || tt.rev.GreaterThan(revision{main: i}) {
+				if tt.remove {
+					wti.Tombstone(tt.key, tt.rev)
+				} else {
+					restore(wti, tt.key, tt.created, tt.rev, tt.ver)
+				}
+			}
+		}
+		if !ti.Equal(wti) {
+			t.Errorf("#%d: not equal ti", i)
+		}
+	}
+}
+
+func restore(ti *treeIndex, key []byte, created, modified revision, ver int64) {
+	keyi := &keyIndex{key: key}
+
+	ti.Lock()
+	defer ti.Unlock()
+	item := ti.tree.Get(keyi)
+	if item == nil {
+		keyi.restore(created, modified, ver)
+		ti.tree.ReplaceOrInsert(keyi)
+		return
+	}
+	okeyi := item.(*keyIndex)
+	okeyi.put(modified.main, modified.sub)
+}
diff --git a/internal/mvcc/key_index.go b/internal/mvcc/key_index.go
new file mode 100644
index 0000000..805922b
--- /dev/null
+++ b/internal/mvcc/key_index.go
@@ -0,0 +1,356 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"bytes"
+	"errors"
+	"fmt"
+
+	"github.com/google/btree"
+)
+
+var (
+	ErrRevisionNotFound = errors.New("mvcc: revision not found")
+)
+
+// keyIndex stores the revisions of a key in the backend.
+// Each keyIndex has at least one key generation.
+// Each generation might have several key versions.
+// Tombstone on a key appends an tombstone version at the end
+// of the current generation and creates a new empty generation.
+// Each version of a key has an index pointing to the backend.
+//
+// For example: put(1.0);put(2.0);tombstone(3.0);put(4.0);tombstone(5.0) on key "foo"
+// generate a keyIndex:
+// key:     "foo"
+// rev: 5
+// generations:
+//    {empty}
+//    {4.0, 5.0(t)}
+//    {1.0, 2.0, 3.0(t)}
+//
+// Compact a keyIndex removes the versions with smaller or equal to
+// rev except the largest one. If the generation becomes empty
+// during compaction, it will be removed. if all the generations get
+// removed, the keyIndex should be removed.
+//
+// For example:
+// compact(2) on the previous example
+// generations:
+//    {empty}
+//    {4.0, 5.0(t)}
+//    {2.0, 3.0(t)}
+//
+// compact(4)
+// generations:
+//    {empty}
+//    {4.0, 5.0(t)}
+//
+// compact(5):
+// generations:
+//    {empty} -> key SHOULD be removed.
+//
+// compact(6):
+// generations:
+//    {empty} -> key SHOULD be removed.
+type keyIndex struct {
+	key         []byte
+	modified    revision // the main rev of the last modification
+	generations []generation
+}
+
+// put puts a revision to the keyIndex.
+func (ki *keyIndex) put(main int64, sub int64) {
+	rev := revision{main: main, sub: sub}
+
+	if !rev.GreaterThan(ki.modified) {
+		plog.Panicf("store.keyindex: put with unexpected smaller revision [%v / %v]", rev, ki.modified)
+	}
+	if len(ki.generations) == 0 {
+		ki.generations = append(ki.generations, generation{})
+	}
+	g := &ki.generations[len(ki.generations)-1]
+	if len(g.revs) == 0 { // create a new key
+		keysGauge.Inc()
+		g.created = rev
+	}
+	g.revs = append(g.revs, rev)
+	g.ver++
+	ki.modified = rev
+}
+
+func (ki *keyIndex) restore(created, modified revision, ver int64) {
+	if len(ki.generations) != 0 {
+		plog.Panicf("store.keyindex: cannot restore non-empty keyIndex")
+	}
+
+	ki.modified = modified
+	g := generation{created: created, ver: ver, revs: []revision{modified}}
+	ki.generations = append(ki.generations, g)
+	keysGauge.Inc()
+}
+
+// tombstone puts a revision, pointing to a tombstone, to the keyIndex.
+// It also creates a new empty generation in the keyIndex.
+// It returns ErrRevisionNotFound when tombstone on an empty generation.
+func (ki *keyIndex) tombstone(main int64, sub int64) error {
+	if ki.isEmpty() {
+		plog.Panicf("store.keyindex: unexpected tombstone on empty keyIndex %s", string(ki.key))
+	}
+	if ki.generations[len(ki.generations)-1].isEmpty() {
+		return ErrRevisionNotFound
+	}
+	ki.put(main, sub)
+	ki.generations = append(ki.generations, generation{})
+	keysGauge.Dec()
+	return nil
+}
+
+// get gets the modified, created revision and version of the key that satisfies the given atRev.
+// Rev must be higher than or equal to the given atRev.
+func (ki *keyIndex) get(atRev int64) (modified, created revision, ver int64, err error) {
+	if ki.isEmpty() {
+		plog.Panicf("store.keyindex: unexpected get on empty keyIndex %s", string(ki.key))
+	}
+	g := ki.findGeneration(atRev)
+	if g.isEmpty() {
+		return revision{}, revision{}, 0, ErrRevisionNotFound
+	}
+
+	n := g.walk(func(rev revision) bool { return rev.main > atRev })
+	if n != -1 {
+		return g.revs[n], g.created, g.ver - int64(len(g.revs)-n-1), nil
+	}
+
+	return revision{}, revision{}, 0, ErrRevisionNotFound
+}
+
+// since returns revisions since the given rev. Only the revision with the
+// largest sub revision will be returned if multiple revisions have the same
+// main revision.
+func (ki *keyIndex) since(rev int64) []revision {
+	if ki.isEmpty() {
+		plog.Panicf("store.keyindex: unexpected get on empty keyIndex %s", string(ki.key))
+	}
+	since := revision{rev, 0}
+	var gi int
+	// find the generations to start checking
+	for gi = len(ki.generations) - 1; gi > 0; gi-- {
+		g := ki.generations[gi]
+		if g.isEmpty() {
+			continue
+		}
+		if since.GreaterThan(g.created) {
+			break
+		}
+	}
+
+	var revs []revision
+	var last int64
+	for ; gi < len(ki.generations); gi++ {
+		for _, r := range ki.generations[gi].revs {
+			if since.GreaterThan(r) {
+				continue
+			}
+			if r.main == last {
+				// replace the revision with a new one that has higher sub value,
+				// because the original one should not be seen by external
+				revs[len(revs)-1] = r
+				continue
+			}
+			revs = append(revs, r)
+			last = r.main
+		}
+	}
+	return revs
+}
+
+// compact compacts a keyIndex by removing the versions with smaller or equal
+// revision than the given atRev except the largest one (If the largest one is
+// a tombstone, it will not be kept).
+// If a generation becomes empty during compaction, it will be removed.
+func (ki *keyIndex) compact(atRev int64, available map[revision]struct{}) {
+	if ki.isEmpty() {
+		plog.Panicf("store.keyindex: unexpected compact on empty keyIndex %s", string(ki.key))
+	}
+
+	genIdx, revIndex := ki.doCompact(atRev, available)
+
+	g := &ki.generations[genIdx]
+	if !g.isEmpty() {
+		// remove the previous contents.
+		if revIndex != -1 {
+			g.revs = g.revs[revIndex:]
+		}
+		// remove any tombstone
+		if len(g.revs) == 1 && genIdx != len(ki.generations)-1 {
+			delete(available, g.revs[0])
+			genIdx++
+		}
+	}
+
+	// remove the previous generations.
+	ki.generations = ki.generations[genIdx:]
+}
+
+// keep finds the revision to be kept if compact is called at given atRev.
+func (ki *keyIndex) keep(atRev int64, available map[revision]struct{}) {
+	if ki.isEmpty() {
+		return
+	}
+
+	genIdx, revIndex := ki.doCompact(atRev, available)
+	g := &ki.generations[genIdx]
+	if !g.isEmpty() {
+		// remove any tombstone
+		if revIndex == len(g.revs)-1 && genIdx != len(ki.generations)-1 {
+			delete(available, g.revs[revIndex])
+		}
+	}
+}
+
+func (ki *keyIndex) doCompact(atRev int64, available map[revision]struct{}) (genIdx int, revIndex int) {
+	// walk until reaching the first revision smaller or equal to "atRev",
+	// and add the revision to the available map
+	f := func(rev revision) bool {
+		if rev.main <= atRev {
+			available[rev] = struct{}{}
+			return false
+		}
+		return true
+	}
+
+	genIdx, g := 0, &ki.generations[0]
+	// find first generation includes atRev or created after atRev
+	for genIdx < len(ki.generations)-1 {
+		if tomb := g.revs[len(g.revs)-1].main; tomb > atRev {
+			break
+		}
+		genIdx++
+		g = &ki.generations[genIdx]
+	}
+
+	revIndex = g.walk(f)
+
+	return genIdx, revIndex
+}
+
+func (ki *keyIndex) isEmpty() bool {
+	return len(ki.generations) == 1 && ki.generations[0].isEmpty()
+}
+
+// findGeneration finds out the generation of the keyIndex that the
+// given rev belongs to. If the given rev is at the gap of two generations,
+// which means that the key does not exist at the given rev, it returns nil.
+func (ki *keyIndex) findGeneration(rev int64) *generation {
+	lastg := len(ki.generations) - 1
+	cg := lastg
+
+	for cg >= 0 {
+		if len(ki.generations[cg].revs) == 0 {
+			cg--
+			continue
+		}
+		g := ki.generations[cg]
+		if cg != lastg {
+			if tomb := g.revs[len(g.revs)-1].main; tomb <= rev {
+				return nil
+			}
+		}
+		if g.revs[0].main <= rev {
+			return &ki.generations[cg]
+		}
+		cg--
+	}
+	return nil
+}
+
+func (a *keyIndex) Less(b btree.Item) bool {
+	return bytes.Compare(a.key, b.(*keyIndex).key) == -1
+}
+
+func (a *keyIndex) equal(b *keyIndex) bool {
+	if !bytes.Equal(a.key, b.key) {
+		return false
+	}
+	if a.modified != b.modified {
+		return false
+	}
+	if len(a.generations) != len(b.generations) {
+		return false
+	}
+	for i := range a.generations {
+		ag, bg := a.generations[i], b.generations[i]
+		if !ag.equal(bg) {
+			return false
+		}
+	}
+	return true
+}
+
+func (ki *keyIndex) String() string {
+	var s string
+	for _, g := range ki.generations {
+		s += g.String()
+	}
+	return s
+}
+
+// generation contains multiple revisions of a key.
+type generation struct {
+	ver     int64
+	created revision // when the generation is created (put in first revision).
+	revs    []revision
+}
+
+func (g *generation) isEmpty() bool { return g == nil || len(g.revs) == 0 }
+
+// walk walks through the revisions in the generation in descending order.
+// It passes the revision to the given function.
+// walk returns until: 1. it finishes walking all pairs 2. the function returns false.
+// walk returns the position at where it stopped. If it stopped after
+// finishing walking, -1 will be returned.
+func (g *generation) walk(f func(rev revision) bool) int {
+	l := len(g.revs)
+	for i := range g.revs {
+		ok := f(g.revs[l-i-1])
+		if !ok {
+			return l - i - 1
+		}
+	}
+	return -1
+}
+
+func (g *generation) String() string {
+	return fmt.Sprintf("g: created[%d] ver[%d], revs %#v\n", g.created, g.ver, g.revs)
+}
+
+func (a generation) equal(b generation) bool {
+	if a.ver != b.ver {
+		return false
+	}
+	if len(a.revs) != len(b.revs) {
+		return false
+	}
+
+	for i := range a.revs {
+		ar, br := a.revs[i], b.revs[i]
+		if ar != br {
+			return false
+		}
+	}
+	return true
+}
diff --git a/internal/mvcc/key_index_test.go b/internal/mvcc/key_index_test.go
new file mode 100644
index 0000000..57e6a9c
--- /dev/null
+++ b/internal/mvcc/key_index_test.go
@@ -0,0 +1,698 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"reflect"
+	"testing"
+)
+
+func TestKeyIndexGet(t *testing.T) {
+	// key: "foo"
+	// rev: 16
+	// generations:
+	//    {empty}
+	//    {{14, 0}[1], {14, 1}[2], {16, 0}(t)[3]}
+	//    {{8, 0}[1], {10, 0}[2], {12, 0}(t)[3]}
+	//    {{2, 0}[1], {4, 0}[2], {6, 0}(t)[3]}
+	ki := newTestKeyIndex()
+	ki.compact(4, make(map[revision]struct{}))
+
+	tests := []struct {
+		rev int64
+
+		wmod   revision
+		wcreat revision
+		wver   int64
+		werr   error
+	}{
+		{17, revision{}, revision{}, 0, ErrRevisionNotFound},
+		{16, revision{}, revision{}, 0, ErrRevisionNotFound},
+
+		// get on generation 3
+		{15, revision{14, 1}, revision{14, 0}, 2, nil},
+		{14, revision{14, 1}, revision{14, 0}, 2, nil},
+
+		{13, revision{}, revision{}, 0, ErrRevisionNotFound},
+		{12, revision{}, revision{}, 0, ErrRevisionNotFound},
+
+		// get on generation 2
+		{11, revision{10, 0}, revision{8, 0}, 2, nil},
+		{10, revision{10, 0}, revision{8, 0}, 2, nil},
+		{9, revision{8, 0}, revision{8, 0}, 1, nil},
+		{8, revision{8, 0}, revision{8, 0}, 1, nil},
+
+		{7, revision{}, revision{}, 0, ErrRevisionNotFound},
+		{6, revision{}, revision{}, 0, ErrRevisionNotFound},
+
+		// get on generation 1
+		{5, revision{4, 0}, revision{2, 0}, 2, nil},
+		{4, revision{4, 0}, revision{2, 0}, 2, nil},
+
+		{3, revision{}, revision{}, 0, ErrRevisionNotFound},
+		{2, revision{}, revision{}, 0, ErrRevisionNotFound},
+		{1, revision{}, revision{}, 0, ErrRevisionNotFound},
+		{0, revision{}, revision{}, 0, ErrRevisionNotFound},
+	}
+
+	for i, tt := range tests {
+		mod, creat, ver, err := ki.get(tt.rev)
+		if err != tt.werr {
+			t.Errorf("#%d: err = %v, want %v", i, err, tt.werr)
+		}
+		if mod != tt.wmod {
+			t.Errorf("#%d: modified = %+v, want %+v", i, mod, tt.wmod)
+		}
+		if creat != tt.wcreat {
+			t.Errorf("#%d: created = %+v, want %+v", i, creat, tt.wcreat)
+		}
+		if ver != tt.wver {
+			t.Errorf("#%d: version = %d, want %d", i, ver, tt.wver)
+		}
+	}
+}
+
+func TestKeyIndexSince(t *testing.T) {
+	ki := newTestKeyIndex()
+	ki.compact(4, make(map[revision]struct{}))
+
+	allRevs := []revision{{4, 0}, {6, 0}, {8, 0}, {10, 0}, {12, 0}, {14, 1}, {16, 0}}
+	tests := []struct {
+		rev int64
+
+		wrevs []revision
+	}{
+		{17, nil},
+		{16, allRevs[6:]},
+		{15, allRevs[6:]},
+		{14, allRevs[5:]},
+		{13, allRevs[5:]},
+		{12, allRevs[4:]},
+		{11, allRevs[4:]},
+		{10, allRevs[3:]},
+		{9, allRevs[3:]},
+		{8, allRevs[2:]},
+		{7, allRevs[2:]},
+		{6, allRevs[1:]},
+		{5, allRevs[1:]},
+		{4, allRevs},
+		{3, allRevs},
+		{2, allRevs},
+		{1, allRevs},
+		{0, allRevs},
+	}
+
+	for i, tt := range tests {
+		revs := ki.since(tt.rev)
+		if !reflect.DeepEqual(revs, tt.wrevs) {
+			t.Errorf("#%d: revs = %+v, want %+v", i, revs, tt.wrevs)
+		}
+	}
+}
+
+func TestKeyIndexPut(t *testing.T) {
+	ki := &keyIndex{key: []byte("foo")}
+	ki.put(5, 0)
+
+	wki := &keyIndex{
+		key:         []byte("foo"),
+		modified:    revision{5, 0},
+		generations: []generation{{created: revision{5, 0}, ver: 1, revs: []revision{{main: 5}}}},
+	}
+	if !reflect.DeepEqual(ki, wki) {
+		t.Errorf("ki = %+v, want %+v", ki, wki)
+	}
+
+	ki.put(7, 0)
+
+	wki = &keyIndex{
+		key:         []byte("foo"),
+		modified:    revision{7, 0},
+		generations: []generation{{created: revision{5, 0}, ver: 2, revs: []revision{{main: 5}, {main: 7}}}},
+	}
+	if !reflect.DeepEqual(ki, wki) {
+		t.Errorf("ki = %+v, want %+v", ki, wki)
+	}
+}
+
+func TestKeyIndexRestore(t *testing.T) {
+	ki := &keyIndex{key: []byte("foo")}
+	ki.restore(revision{5, 0}, revision{7, 0}, 2)
+
+	wki := &keyIndex{
+		key:         []byte("foo"),
+		modified:    revision{7, 0},
+		generations: []generation{{created: revision{5, 0}, ver: 2, revs: []revision{{main: 7}}}},
+	}
+	if !reflect.DeepEqual(ki, wki) {
+		t.Errorf("ki = %+v, want %+v", ki, wki)
+	}
+}
+
+func TestKeyIndexTombstone(t *testing.T) {
+	ki := &keyIndex{key: []byte("foo")}
+	ki.put(5, 0)
+
+	err := ki.tombstone(7, 0)
+	if err != nil {
+		t.Errorf("unexpected tombstone error: %v", err)
+	}
+
+	wki := &keyIndex{
+		key:         []byte("foo"),
+		modified:    revision{7, 0},
+		generations: []generation{{created: revision{5, 0}, ver: 2, revs: []revision{{main: 5}, {main: 7}}}, {}},
+	}
+	if !reflect.DeepEqual(ki, wki) {
+		t.Errorf("ki = %+v, want %+v", ki, wki)
+	}
+
+	ki.put(8, 0)
+	ki.put(9, 0)
+	err = ki.tombstone(15, 0)
+	if err != nil {
+		t.Errorf("unexpected tombstone error: %v", err)
+	}
+
+	wki = &keyIndex{
+		key:      []byte("foo"),
+		modified: revision{15, 0},
+		generations: []generation{
+			{created: revision{5, 0}, ver: 2, revs: []revision{{main: 5}, {main: 7}}},
+			{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 9}, {main: 15}}},
+			{},
+		},
+	}
+	if !reflect.DeepEqual(ki, wki) {
+		t.Errorf("ki = %+v, want %+v", ki, wki)
+	}
+
+	err = ki.tombstone(16, 0)
+	if err != ErrRevisionNotFound {
+		t.Errorf("tombstone error = %v, want %v", err, ErrRevisionNotFound)
+	}
+}
+
+func TestKeyIndexCompactAndKeep(t *testing.T) {
+	tests := []struct {
+		compact int64
+
+		wki *keyIndex
+		wam map[revision]struct{}
+	}{
+		{
+			1,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 2}, {main: 4}, {main: 6}}},
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{},
+		},
+		{
+			2,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 2}, {main: 4}, {main: 6}}},
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 2}: {},
+			},
+		},
+		{
+			3,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 2}, {main: 4}, {main: 6}}},
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 2}: {},
+			},
+		},
+		{
+			4,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 4}, {main: 6}}},
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 4}: {},
+			},
+		},
+		{
+			5,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 4}, {main: 6}}},
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 4}: {},
+			},
+		},
+		{
+			6,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{},
+		},
+		{
+			7,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{},
+		},
+		{
+			8,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 8}: {},
+			},
+		},
+		{
+			9,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 8}: {},
+			},
+		},
+		{
+			10,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 10}: {},
+			},
+		},
+		{
+			11,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 10}, {main: 12}}},
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 10}: {},
+			},
+		},
+		{
+			12,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{},
+		},
+		{
+			13,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{},
+		},
+		{
+			14,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 14, sub: 1}: {},
+			},
+		},
+		{
+			15,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14, sub: 1}, {main: 16}}},
+					{},
+				},
+			},
+			map[revision]struct{}{
+				{main: 14, sub: 1}: {},
+			},
+		},
+		{
+			16,
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{16, 0},
+				generations: []generation{
+					{},
+				},
+			},
+			map[revision]struct{}{},
+		},
+	}
+
+	// Continuous Compaction and finding Keep
+	ki := newTestKeyIndex()
+	for i, tt := range tests {
+		am := make(map[revision]struct{})
+		kiclone := cloneKeyIndex(ki)
+		ki.keep(tt.compact, am)
+		if !reflect.DeepEqual(ki, kiclone) {
+			t.Errorf("#%d: ki = %+v, want %+v", i, ki, kiclone)
+		}
+		if !reflect.DeepEqual(am, tt.wam) {
+			t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
+		}
+		am = make(map[revision]struct{})
+		ki.compact(tt.compact, am)
+		if !reflect.DeepEqual(ki, tt.wki) {
+			t.Errorf("#%d: ki = %+v, want %+v", i, ki, tt.wki)
+		}
+		if !reflect.DeepEqual(am, tt.wam) {
+			t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
+		}
+	}
+
+	// Jump Compaction and finding Keep
+	ki = newTestKeyIndex()
+	for i, tt := range tests {
+		if (i%2 == 0 && i < 6) || (i%2 == 1 && i > 6) {
+			am := make(map[revision]struct{})
+			kiclone := cloneKeyIndex(ki)
+			ki.keep(tt.compact, am)
+			if !reflect.DeepEqual(ki, kiclone) {
+				t.Errorf("#%d: ki = %+v, want %+v", i, ki, kiclone)
+			}
+			if !reflect.DeepEqual(am, tt.wam) {
+				t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
+			}
+			am = make(map[revision]struct{})
+			ki.compact(tt.compact, am)
+			if !reflect.DeepEqual(ki, tt.wki) {
+				t.Errorf("#%d: ki = %+v, want %+v", i, ki, tt.wki)
+			}
+			if !reflect.DeepEqual(am, tt.wam) {
+				t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
+			}
+		}
+	}
+
+	kiClone := newTestKeyIndex()
+	// Once Compaction and finding Keep
+	for i, tt := range tests {
+		ki := newTestKeyIndex()
+		am := make(map[revision]struct{})
+		ki.keep(tt.compact, am)
+		if !reflect.DeepEqual(ki, kiClone) {
+			t.Errorf("#%d: ki = %+v, want %+v", i, ki, kiClone)
+		}
+		if !reflect.DeepEqual(am, tt.wam) {
+			t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
+		}
+		am = make(map[revision]struct{})
+		ki.compact(tt.compact, am)
+		if !reflect.DeepEqual(ki, tt.wki) {
+			t.Errorf("#%d: ki = %+v, want %+v", i, ki, tt.wki)
+		}
+		if !reflect.DeepEqual(am, tt.wam) {
+			t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
+		}
+	}
+}
+
+func cloneKeyIndex(ki *keyIndex) *keyIndex {
+	generations := make([]generation, len(ki.generations))
+	for i, gen := range ki.generations {
+		generations[i] = *cloneGeneration(&gen)
+	}
+	return &keyIndex{ki.key, ki.modified, generations}
+}
+
+func cloneGeneration(g *generation) *generation {
+	if g.revs == nil {
+		return &generation{g.ver, g.created, nil}
+	}
+	tmp := make([]revision, len(g.revs))
+	copy(tmp, g.revs)
+	return &generation{g.ver, g.created, tmp}
+}
+
+// test that compact on version that higher than last modified version works well
+func TestKeyIndexCompactOnFurtherRev(t *testing.T) {
+	ki := &keyIndex{key: []byte("foo")}
+	ki.put(1, 0)
+	ki.put(2, 0)
+	am := make(map[revision]struct{})
+	ki.compact(3, am)
+
+	wki := &keyIndex{
+		key:      []byte("foo"),
+		modified: revision{2, 0},
+		generations: []generation{
+			{created: revision{1, 0}, ver: 2, revs: []revision{{main: 2}}},
+		},
+	}
+	wam := map[revision]struct{}{
+		{main: 2}: {},
+	}
+	if !reflect.DeepEqual(ki, wki) {
+		t.Errorf("ki = %+v, want %+v", ki, wki)
+	}
+	if !reflect.DeepEqual(am, wam) {
+		t.Errorf("am = %+v, want %+v", am, wam)
+	}
+}
+
+func TestKeyIndexIsEmpty(t *testing.T) {
+	tests := []struct {
+		ki *keyIndex
+		w  bool
+	}{
+		{
+			&keyIndex{
+				key:         []byte("foo"),
+				generations: []generation{{}},
+			},
+			true,
+		},
+		{
+			&keyIndex{
+				key:      []byte("foo"),
+				modified: revision{2, 0},
+				generations: []generation{
+					{created: revision{1, 0}, ver: 2, revs: []revision{{main: 2}}},
+				},
+			},
+			false,
+		},
+	}
+	for i, tt := range tests {
+		g := tt.ki.isEmpty()
+		if g != tt.w {
+			t.Errorf("#%d: isEmpty = %v, want %v", i, g, tt.w)
+		}
+	}
+}
+
+func TestKeyIndexFindGeneration(t *testing.T) {
+	ki := newTestKeyIndex()
+
+	tests := []struct {
+		rev int64
+		wg  *generation
+	}{
+		{0, nil},
+		{1, nil},
+		{2, &ki.generations[0]},
+		{3, &ki.generations[0]},
+		{4, &ki.generations[0]},
+		{5, &ki.generations[0]},
+		{6, nil},
+		{7, nil},
+		{8, &ki.generations[1]},
+		{9, &ki.generations[1]},
+		{10, &ki.generations[1]},
+		{11, &ki.generations[1]},
+		{12, nil},
+		{13, nil},
+	}
+	for i, tt := range tests {
+		g := ki.findGeneration(tt.rev)
+		if g != tt.wg {
+			t.Errorf("#%d: generation = %+v, want %+v", i, g, tt.wg)
+		}
+	}
+}
+
+func TestKeyIndexLess(t *testing.T) {
+	ki := &keyIndex{key: []byte("foo")}
+
+	tests := []struct {
+		ki *keyIndex
+		w  bool
+	}{
+		{&keyIndex{key: []byte("doo")}, false},
+		{&keyIndex{key: []byte("foo")}, false},
+		{&keyIndex{key: []byte("goo")}, true},
+	}
+	for i, tt := range tests {
+		g := ki.Less(tt.ki)
+		if g != tt.w {
+			t.Errorf("#%d: Less = %v, want %v", i, g, tt.w)
+		}
+	}
+}
+
+func TestGenerationIsEmpty(t *testing.T) {
+	tests := []struct {
+		g *generation
+		w bool
+	}{
+		{nil, true},
+		{&generation{}, true},
+		{&generation{revs: []revision{{main: 1}}}, false},
+	}
+	for i, tt := range tests {
+		g := tt.g.isEmpty()
+		if g != tt.w {
+			t.Errorf("#%d: isEmpty = %v, want %v", i, g, tt.w)
+		}
+	}
+}
+
+func TestGenerationWalk(t *testing.T) {
+	g := &generation{
+		ver:     3,
+		created: revision{2, 0},
+		revs:    []revision{{main: 2}, {main: 4}, {main: 6}},
+	}
+	tests := []struct {
+		f  func(rev revision) bool
+		wi int
+	}{
+		{func(rev revision) bool { return rev.main >= 7 }, 2},
+		{func(rev revision) bool { return rev.main >= 6 }, 1},
+		{func(rev revision) bool { return rev.main >= 5 }, 1},
+		{func(rev revision) bool { return rev.main >= 4 }, 0},
+		{func(rev revision) bool { return rev.main >= 3 }, 0},
+		{func(rev revision) bool { return rev.main >= 2 }, -1},
+	}
+	for i, tt := range tests {
+		idx := g.walk(tt.f)
+		if idx != tt.wi {
+			t.Errorf("#%d: index = %d, want %d", i, idx, tt.wi)
+		}
+	}
+}
+
+func newTestKeyIndex() *keyIndex {
+	// key: "foo"
+	// rev: 16
+	// generations:
+	//    {empty}
+	//    {{14, 0}[1], {14, 1}[2], {16, 0}(t)[3]}
+	//    {{8, 0}[1], {10, 0}[2], {12, 0}(t)[3]}
+	//    {{2, 0}[1], {4, 0}[2], {6, 0}(t)[3]}
+
+	ki := &keyIndex{key: []byte("foo")}
+	ki.put(2, 0)
+	ki.put(4, 0)
+	ki.tombstone(6, 0)
+	ki.put(8, 0)
+	ki.put(10, 0)
+	ki.tombstone(12, 0)
+	ki.put(14, 0)
+	ki.put(14, 1)
+	ki.tombstone(16, 0)
+	return ki
+}
diff --git a/internal/mvcc/kv.go b/internal/mvcc/kv.go
new file mode 100644
index 0000000..e8cb1de
--- /dev/null
+++ b/internal/mvcc/kv.go
@@ -0,0 +1,149 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+)
+
+type RangeOptions struct {
+	Limit int64
+	Rev   int64
+	Count bool
+}
+
+type RangeResult struct {
+	KVs   []mvccpb.KeyValue
+	Rev   int64
+	Count int
+}
+
+type ReadView interface {
+	// FirstRev returns the first KV revision at the time of opening the txn.
+	// After a compaction, the first revision increases to the compaction
+	// revision.
+	FirstRev() int64
+
+	// Rev returns the revision of the KV at the time of opening the txn.
+	Rev() int64
+
+	// Range gets the keys in the range at rangeRev.
+	// The returned rev is the current revision of the KV when the operation is executed.
+	// If rangeRev <=0, range gets the keys at currentRev.
+	// If `end` is nil, the request returns the key.
+	// If `end` is not nil and not empty, it gets the keys in range [key, range_end).
+	// If `end` is not nil and empty, it gets the keys greater than or equal to key.
+	// Limit limits the number of keys returned.
+	// If the required rev is compacted, ErrCompacted will be returned.
+	Range(key, end []byte, ro RangeOptions) (r *RangeResult, err error)
+}
+
+// TxnRead represents a read-only transaction with operations that will not
+// block other read transactions.
+type TxnRead interface {
+	ReadView
+	// End marks the transaction is complete and ready to commit.
+	End()
+}
+
+type WriteView interface {
+	// DeleteRange deletes the given range from the store.
+	// A deleteRange increases the rev of the store if any key in the range exists.
+	// The number of key deleted will be returned.
+	// The returned rev is the current revision of the KV when the operation is executed.
+	// It also generates one event for each key delete in the event history.
+	// if the `end` is nil, deleteRange deletes the key.
+	// if the `end` is not nil, deleteRange deletes the keys in range [key, range_end).
+	DeleteRange(key, end []byte) (n, rev int64)
+
+	// Put puts the given key, value into the store. Put also takes additional argument lease to
+	// attach a lease to a key-value pair as meta-data. KV implementation does not validate the lease
+	// id.
+	// A put also increases the rev of the store, and generates one event in the event history.
+	// The returned rev is the current revision of the KV when the operation is executed.
+	Put(key, value []byte, lease lease.LeaseID) (rev int64)
+}
+
+// TxnWrite represents a transaction that can modify the store.
+type TxnWrite interface {
+	TxnRead
+	WriteView
+	// Changes gets the changes made since opening the write txn.
+	Changes() []mvccpb.KeyValue
+}
+
+// txnReadWrite coerces a read txn to a write, panicking on any write operation.
+type txnReadWrite struct{ TxnRead }
+
+func (trw *txnReadWrite) DeleteRange(key, end []byte) (n, rev int64) { panic("unexpected DeleteRange") }
+func (trw *txnReadWrite) Put(key, value []byte, lease lease.LeaseID) (rev int64) {
+	panic("unexpected Put")
+}
+func (trw *txnReadWrite) Changes() []mvccpb.KeyValue { return nil }
+
+func NewReadOnlyTxnWrite(txn TxnRead) TxnWrite { return &txnReadWrite{txn} }
+
+type KV interface {
+	ReadView
+	WriteView
+
+	// Read creates a read transaction.
+	Read() TxnRead
+
+	// Write creates a write transaction.
+	Write() TxnWrite
+
+	// Hash computes the hash of the KV's backend.
+	Hash() (hash uint32, revision int64, err error)
+
+	// HashByRev computes the hash of all MVCC revisions up to a given revision.
+	HashByRev(rev int64) (hash uint32, revision int64, compactRev int64, err error)
+
+	// Compact frees all superseded keys with revisions less than rev.
+	Compact(rev int64) (<-chan struct{}, error)
+
+	// Commit commits outstanding txns into the underlying backend.
+	Commit()
+
+	// Restore restores the KV store from a backend.
+	Restore(b backend.Backend) error
+	Close() error
+}
+
+// WatchableKV is a KV that can be watched.
+type WatchableKV interface {
+	KV
+	Watchable
+}
+
+// Watchable is the interface that wraps the NewWatchStream function.
+type Watchable interface {
+	// NewWatchStream returns a WatchStream that can be used to
+	// watch events happened or happening on the KV.
+	NewWatchStream() WatchStream
+}
+
+// ConsistentWatchableKV is a WatchableKV that understands the consistency
+// algorithm and consistent index.
+// If the consistent index of executing entry is not larger than the
+// consistent index of ConsistentWatchableKV, all operations in
+// this entry are skipped and return empty response.
+type ConsistentWatchableKV interface {
+	WatchableKV
+	// ConsistentIndex returns the current consistent index of the KV.
+	ConsistentIndex() uint64
+}
diff --git a/internal/mvcc/kv_test.go b/internal/mvcc/kv_test.go
new file mode 100644
index 0000000..e4185f4
--- /dev/null
+++ b/internal/mvcc/kv_test.go
@@ -0,0 +1,831 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"fmt"
+	"os"
+	"reflect"
+	"testing"
+	"time"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+	"github.com/coreos/etcd/pkg/testutil"
+
+	"github.com/prometheus/client_golang/prometheus"
+	dto "github.com/prometheus/client_model/go"
+)
+
+// Functional tests for features implemented in v3 store. It treats v3 store
+// as a black box, and tests it by feeding the input and validating the output.
+
+// TODO: add similar tests on operations in one txn/rev
+
+type (
+	rangeFunc       func(kv KV, key, end []byte, ro RangeOptions) (*RangeResult, error)
+	putFunc         func(kv KV, key, value []byte, lease lease.LeaseID) int64
+	deleteRangeFunc func(kv KV, key, end []byte) (n, rev int64)
+)
+
+var (
+	normalRangeFunc = func(kv KV, key, end []byte, ro RangeOptions) (*RangeResult, error) {
+		return kv.Range(key, end, ro)
+	}
+	txnRangeFunc = func(kv KV, key, end []byte, ro RangeOptions) (*RangeResult, error) {
+		txn := kv.Read()
+		defer txn.End()
+		return txn.Range(key, end, ro)
+	}
+
+	normalPutFunc = func(kv KV, key, value []byte, lease lease.LeaseID) int64 {
+		return kv.Put(key, value, lease)
+	}
+	txnPutFunc = func(kv KV, key, value []byte, lease lease.LeaseID) int64 {
+		txn := kv.Write()
+		defer txn.End()
+		return txn.Put(key, value, lease)
+	}
+
+	normalDeleteRangeFunc = func(kv KV, key, end []byte) (n, rev int64) {
+		return kv.DeleteRange(key, end)
+	}
+	txnDeleteRangeFunc = func(kv KV, key, end []byte) (n, rev int64) {
+		txn := kv.Write()
+		defer txn.End()
+		return txn.DeleteRange(key, end)
+	}
+)
+
+func TestKVRange(t *testing.T)    { testKVRange(t, normalRangeFunc) }
+func TestKVTxnRange(t *testing.T) { testKVRange(t, txnRangeFunc) }
+
+func testKVRange(t *testing.T, f rangeFunc) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	kvs := put3TestKVs(s)
+
+	wrev := int64(4)
+	tests := []struct {
+		key, end []byte
+		wkvs     []mvccpb.KeyValue
+	}{
+		// get no keys
+		{
+			[]byte("doo"), []byte("foo"),
+			nil,
+		},
+		// get no keys when key == end
+		{
+			[]byte("foo"), []byte("foo"),
+			nil,
+		},
+		// get no keys when ranging single key
+		{
+			[]byte("doo"), nil,
+			nil,
+		},
+		// get all keys
+		{
+			[]byte("foo"), []byte("foo3"),
+			kvs,
+		},
+		// get partial keys
+		{
+			[]byte("foo"), []byte("foo1"),
+			kvs[:1],
+		},
+		// get single key
+		{
+			[]byte("foo"), nil,
+			kvs[:1],
+		},
+		// get entire keyspace
+		{
+			[]byte(""), []byte(""),
+			kvs,
+		},
+	}
+
+	for i, tt := range tests {
+		r, err := f(s, tt.key, tt.end, RangeOptions{})
+		if err != nil {
+			t.Fatal(err)
+		}
+		if r.Rev != wrev {
+			t.Errorf("#%d: rev = %d, want %d", i, r.Rev, wrev)
+		}
+		if !reflect.DeepEqual(r.KVs, tt.wkvs) {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, tt.wkvs)
+		}
+	}
+}
+
+func TestKVRangeRev(t *testing.T)    { testKVRangeRev(t, normalRangeFunc) }
+func TestKVTxnRangeRev(t *testing.T) { testKVRangeRev(t, txnRangeFunc) }
+
+func testKVRangeRev(t *testing.T, f rangeFunc) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	kvs := put3TestKVs(s)
+
+	tests := []struct {
+		rev  int64
+		wrev int64
+		wkvs []mvccpb.KeyValue
+	}{
+		{-1, 4, kvs},
+		{0, 4, kvs},
+		{2, 4, kvs[:1]},
+		{3, 4, kvs[:2]},
+		{4, 4, kvs},
+	}
+
+	for i, tt := range tests {
+		r, err := f(s, []byte("foo"), []byte("foo3"), RangeOptions{Rev: tt.rev})
+		if err != nil {
+			t.Fatal(err)
+		}
+		if r.Rev != tt.wrev {
+			t.Errorf("#%d: rev = %d, want %d", i, r.Rev, tt.wrev)
+		}
+		if !reflect.DeepEqual(r.KVs, tt.wkvs) {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, tt.wkvs)
+		}
+	}
+}
+
+func TestKVRangeBadRev(t *testing.T)    { testKVRangeBadRev(t, normalRangeFunc) }
+func TestKVTxnRangeBadRev(t *testing.T) { testKVRangeBadRev(t, txnRangeFunc) }
+
+func testKVRangeBadRev(t *testing.T, f rangeFunc) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	put3TestKVs(s)
+	if _, err := s.Compact(4); err != nil {
+		t.Fatalf("compact error (%v)", err)
+	}
+
+	tests := []struct {
+		rev  int64
+		werr error
+	}{
+		{-1, nil}, // <= 0 is most recent store
+		{0, nil},
+		{1, ErrCompacted},
+		{2, ErrCompacted},
+		{4, nil},
+		{5, ErrFutureRev},
+		{100, ErrFutureRev},
+	}
+	for i, tt := range tests {
+		_, err := f(s, []byte("foo"), []byte("foo3"), RangeOptions{Rev: tt.rev})
+		if err != tt.werr {
+			t.Errorf("#%d: error = %v, want %v", i, err, tt.werr)
+		}
+	}
+}
+
+func TestKVRangeLimit(t *testing.T)    { testKVRangeLimit(t, normalRangeFunc) }
+func TestKVTxnRangeLimit(t *testing.T) { testKVRangeLimit(t, txnRangeFunc) }
+
+func testKVRangeLimit(t *testing.T, f rangeFunc) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	kvs := put3TestKVs(s)
+
+	wrev := int64(4)
+	tests := []struct {
+		limit int64
+		wkvs  []mvccpb.KeyValue
+	}{
+		// no limit
+		{-1, kvs},
+		// no limit
+		{0, kvs},
+		{1, kvs[:1]},
+		{2, kvs[:2]},
+		{3, kvs},
+		{100, kvs},
+	}
+	for i, tt := range tests {
+		r, err := f(s, []byte("foo"), []byte("foo3"), RangeOptions{Limit: tt.limit})
+		if err != nil {
+			t.Fatalf("#%d: range error (%v)", i, err)
+		}
+		if !reflect.DeepEqual(r.KVs, tt.wkvs) {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, tt.wkvs)
+		}
+		if r.Rev != wrev {
+			t.Errorf("#%d: rev = %d, want %d", i, r.Rev, wrev)
+		}
+		if r.Count != len(kvs) {
+			t.Errorf("#%d: count = %d, want %d", i, r.Count, len(kvs))
+		}
+	}
+}
+
+func TestKVPutMultipleTimes(t *testing.T)    { testKVPutMultipleTimes(t, normalPutFunc) }
+func TestKVTxnPutMultipleTimes(t *testing.T) { testKVPutMultipleTimes(t, txnPutFunc) }
+
+func testKVPutMultipleTimes(t *testing.T, f putFunc) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	for i := 0; i < 10; i++ {
+		base := int64(i + 1)
+
+		rev := f(s, []byte("foo"), []byte("bar"), lease.LeaseID(base))
+		if rev != base+1 {
+			t.Errorf("#%d: rev = %d, want %d", i, rev, base+1)
+		}
+
+		r, err := s.Range([]byte("foo"), nil, RangeOptions{})
+		if err != nil {
+			t.Fatal(err)
+		}
+		wkvs := []mvccpb.KeyValue{
+			{Key: []byte("foo"), Value: []byte("bar"), CreateRevision: 2, ModRevision: base + 1, Version: base, Lease: base},
+		}
+		if !reflect.DeepEqual(r.KVs, wkvs) {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, wkvs)
+		}
+	}
+}
+
+func TestKVDeleteRange(t *testing.T)    { testKVDeleteRange(t, normalDeleteRangeFunc) }
+func TestKVTxnDeleteRange(t *testing.T) { testKVDeleteRange(t, txnDeleteRangeFunc) }
+
+func testKVDeleteRange(t *testing.T, f deleteRangeFunc) {
+	tests := []struct {
+		key, end []byte
+
+		wrev int64
+		wN   int64
+	}{
+		{
+			[]byte("foo"), nil,
+			5, 1,
+		},
+		{
+			[]byte("foo"), []byte("foo1"),
+			5, 1,
+		},
+		{
+			[]byte("foo"), []byte("foo2"),
+			5, 2,
+		},
+		{
+			[]byte("foo"), []byte("foo3"),
+			5, 3,
+		},
+		{
+			[]byte("foo3"), []byte("foo8"),
+			4, 0,
+		},
+		{
+			[]byte("foo3"), nil,
+			4, 0,
+		},
+	}
+
+	for i, tt := range tests {
+		b, tmpPath := backend.NewDefaultTmpBackend()
+		s := NewStore(b, &lease.FakeLessor{}, nil)
+
+		s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
+		s.Put([]byte("foo1"), []byte("bar1"), lease.NoLease)
+		s.Put([]byte("foo2"), []byte("bar2"), lease.NoLease)
+
+		n, rev := f(s, tt.key, tt.end)
+		if n != tt.wN || rev != tt.wrev {
+			t.Errorf("#%d: n = %d, rev = %d, want (%d, %d)", i, n, rev, tt.wN, tt.wrev)
+		}
+
+		cleanup(s, b, tmpPath)
+	}
+}
+
+func TestKVDeleteMultipleTimes(t *testing.T)    { testKVDeleteMultipleTimes(t, normalDeleteRangeFunc) }
+func TestKVTxnDeleteMultipleTimes(t *testing.T) { testKVDeleteMultipleTimes(t, txnDeleteRangeFunc) }
+
+func testKVDeleteMultipleTimes(t *testing.T, f deleteRangeFunc) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
+
+	n, rev := f(s, []byte("foo"), nil)
+	if n != 1 || rev != 3 {
+		t.Fatalf("n = %d, rev = %d, want (%d, %d)", n, rev, 1, 3)
+	}
+
+	for i := 0; i < 10; i++ {
+		n, rev := f(s, []byte("foo"), nil)
+		if n != 0 || rev != 3 {
+			t.Fatalf("#%d: n = %d, rev = %d, want (%d, %d)", i, n, rev, 0, 3)
+		}
+	}
+}
+
+// test that range, put, delete on single key in sequence repeatedly works correctly.
+func TestKVOperationInSequence(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	for i := 0; i < 10; i++ {
+		base := int64(i*2 + 1)
+
+		// put foo
+		rev := s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
+		if rev != base+1 {
+			t.Errorf("#%d: put rev = %d, want %d", i, rev, base+1)
+		}
+
+		r, err := s.Range([]byte("foo"), nil, RangeOptions{Rev: base + 1})
+		if err != nil {
+			t.Fatal(err)
+		}
+		wkvs := []mvccpb.KeyValue{
+			{Key: []byte("foo"), Value: []byte("bar"), CreateRevision: base + 1, ModRevision: base + 1, Version: 1, Lease: int64(lease.NoLease)},
+		}
+		if !reflect.DeepEqual(r.KVs, wkvs) {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, wkvs)
+		}
+		if r.Rev != base+1 {
+			t.Errorf("#%d: range rev = %d, want %d", i, rev, base+1)
+		}
+
+		// delete foo
+		n, rev := s.DeleteRange([]byte("foo"), nil)
+		if n != 1 || rev != base+2 {
+			t.Errorf("#%d: n = %d, rev = %d, want (%d, %d)", i, n, rev, 1, base+2)
+		}
+
+		r, err = s.Range([]byte("foo"), nil, RangeOptions{Rev: base + 2})
+		if err != nil {
+			t.Fatal(err)
+		}
+		if r.KVs != nil {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, nil)
+		}
+		if r.Rev != base+2 {
+			t.Errorf("#%d: range rev = %d, want %d", i, r.Rev, base+2)
+		}
+	}
+}
+
+func TestKVTxnBlockWriteOperations(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+
+	tests := []func(){
+		func() { s.Put([]byte("foo"), nil, lease.NoLease) },
+		func() { s.DeleteRange([]byte("foo"), nil) },
+	}
+	for i, tt := range tests {
+		txn := s.Write()
+		done := make(chan struct{}, 1)
+		go func() {
+			tt()
+			done <- struct{}{}
+		}()
+		select {
+		case <-done:
+			t.Fatalf("#%d: operation failed to be blocked", i)
+		case <-time.After(10 * time.Millisecond):
+		}
+
+		txn.End()
+		select {
+		case <-done:
+		case <-time.After(10 * time.Second):
+			testutil.FatalStack(t, fmt.Sprintf("#%d: operation failed to be unblocked", i))
+		}
+	}
+
+	// only close backend when we know all the tx are finished
+	cleanup(s, b, tmpPath)
+}
+
+func TestKVTxnNonBlockRange(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	txn := s.Write()
+	defer txn.End()
+
+	donec := make(chan struct{})
+	go func() {
+		defer close(donec)
+		s.Range([]byte("foo"), nil, RangeOptions{})
+	}()
+	select {
+	case <-donec:
+	case <-time.After(100 * time.Millisecond):
+		t.Fatalf("range operation blocked on write txn")
+	}
+}
+
+// test that txn range, put, delete on single key in sequence repeatedly works correctly.
+func TestKVTxnOperationInSequence(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	for i := 0; i < 10; i++ {
+		txn := s.Write()
+		base := int64(i + 1)
+
+		// put foo
+		rev := txn.Put([]byte("foo"), []byte("bar"), lease.NoLease)
+		if rev != base+1 {
+			t.Errorf("#%d: put rev = %d, want %d", i, rev, base+1)
+		}
+
+		r, err := txn.Range([]byte("foo"), nil, RangeOptions{Rev: base + 1})
+		if err != nil {
+			t.Fatal(err)
+		}
+		wkvs := []mvccpb.KeyValue{
+			{Key: []byte("foo"), Value: []byte("bar"), CreateRevision: base + 1, ModRevision: base + 1, Version: 1, Lease: int64(lease.NoLease)},
+		}
+		if !reflect.DeepEqual(r.KVs, wkvs) {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, wkvs)
+		}
+		if r.Rev != base+1 {
+			t.Errorf("#%d: range rev = %d, want %d", i, r.Rev, base+1)
+		}
+
+		// delete foo
+		n, rev := txn.DeleteRange([]byte("foo"), nil)
+		if n != 1 || rev != base+1 {
+			t.Errorf("#%d: n = %d, rev = %d, want (%d, %d)", i, n, rev, 1, base+1)
+		}
+
+		r, err = txn.Range([]byte("foo"), nil, RangeOptions{Rev: base + 1})
+		if err != nil {
+			t.Errorf("#%d: range error (%v)", i, err)
+		}
+		if r.KVs != nil {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, nil)
+		}
+		if r.Rev != base+1 {
+			t.Errorf("#%d: range rev = %d, want %d", i, r.Rev, base+1)
+		}
+
+		txn.End()
+	}
+}
+
+func TestKVCompactReserveLastValue(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	s.Put([]byte("foo"), []byte("bar0"), 1)
+	s.Put([]byte("foo"), []byte("bar1"), 2)
+	s.DeleteRange([]byte("foo"), nil)
+	s.Put([]byte("foo"), []byte("bar2"), 3)
+
+	// rev in tests will be called in Compact() one by one on the same store
+	tests := []struct {
+		rev int64
+		// wanted kvs right after the compacted rev
+		wkvs []mvccpb.KeyValue
+	}{
+		{
+			1,
+			[]mvccpb.KeyValue{
+				{Key: []byte("foo"), Value: []byte("bar0"), CreateRevision: 2, ModRevision: 2, Version: 1, Lease: 1},
+			},
+		},
+		{
+			2,
+			[]mvccpb.KeyValue{
+				{Key: []byte("foo"), Value: []byte("bar1"), CreateRevision: 2, ModRevision: 3, Version: 2, Lease: 2},
+			},
+		},
+		{
+			3,
+			nil,
+		},
+		{
+			4,
+			[]mvccpb.KeyValue{
+				{Key: []byte("foo"), Value: []byte("bar2"), CreateRevision: 5, ModRevision: 5, Version: 1, Lease: 3},
+			},
+		},
+	}
+	for i, tt := range tests {
+		_, err := s.Compact(tt.rev)
+		if err != nil {
+			t.Errorf("#%d: unexpect compact error %v", i, err)
+		}
+		r, err := s.Range([]byte("foo"), nil, RangeOptions{Rev: tt.rev + 1})
+		if err != nil {
+			t.Errorf("#%d: unexpect range error %v", i, err)
+		}
+		if !reflect.DeepEqual(r.KVs, tt.wkvs) {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, tt.wkvs)
+		}
+	}
+}
+
+func TestKVCompactBad(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	s.Put([]byte("foo"), []byte("bar0"), lease.NoLease)
+	s.Put([]byte("foo"), []byte("bar1"), lease.NoLease)
+	s.Put([]byte("foo"), []byte("bar2"), lease.NoLease)
+
+	// rev in tests will be called in Compact() one by one on the same store
+	tests := []struct {
+		rev  int64
+		werr error
+	}{
+		{0, nil},
+		{1, nil},
+		{1, ErrCompacted},
+		{4, nil},
+		{5, ErrFutureRev},
+		{100, ErrFutureRev},
+	}
+	for i, tt := range tests {
+		_, err := s.Compact(tt.rev)
+		if err != tt.werr {
+			t.Errorf("#%d: compact error = %v, want %v", i, err, tt.werr)
+		}
+	}
+}
+
+func TestKVHash(t *testing.T) {
+	hashes := make([]uint32, 3)
+
+	for i := 0; i < len(hashes); i++ {
+		var err error
+		b, tmpPath := backend.NewDefaultTmpBackend()
+		kv := NewStore(b, &lease.FakeLessor{}, nil)
+		kv.Put([]byte("foo0"), []byte("bar0"), lease.NoLease)
+		kv.Put([]byte("foo1"), []byte("bar0"), lease.NoLease)
+		hashes[i], _, err = kv.Hash()
+		if err != nil {
+			t.Fatalf("failed to get hash: %v", err)
+		}
+		cleanup(kv, b, tmpPath)
+	}
+
+	for i := 1; i < len(hashes); i++ {
+		if hashes[i-1] != hashes[i] {
+			t.Errorf("hash[%d](%d) != hash[%d](%d)", i-1, hashes[i-1], i, hashes[i])
+		}
+	}
+}
+
+func TestKVRestore(t *testing.T) {
+	tests := []func(kv KV){
+		func(kv KV) {
+			kv.Put([]byte("foo"), []byte("bar0"), 1)
+			kv.Put([]byte("foo"), []byte("bar1"), 2)
+			kv.Put([]byte("foo"), []byte("bar2"), 3)
+			kv.Put([]byte("foo2"), []byte("bar0"), 1)
+		},
+		func(kv KV) {
+			kv.Put([]byte("foo"), []byte("bar0"), 1)
+			kv.DeleteRange([]byte("foo"), nil)
+			kv.Put([]byte("foo"), []byte("bar1"), 2)
+		},
+		func(kv KV) {
+			kv.Put([]byte("foo"), []byte("bar0"), 1)
+			kv.Put([]byte("foo"), []byte("bar1"), 2)
+			kv.Compact(1)
+		},
+	}
+	for i, tt := range tests {
+		b, tmpPath := backend.NewDefaultTmpBackend()
+		s := NewStore(b, &lease.FakeLessor{}, nil)
+		tt(s)
+		var kvss [][]mvccpb.KeyValue
+		for k := int64(0); k < 10; k++ {
+			r, _ := s.Range([]byte("a"), []byte("z"), RangeOptions{Rev: k})
+			kvss = append(kvss, r.KVs)
+		}
+
+		keysBefore := readGaugeInt(&keysGauge)
+		s.Close()
+
+		// ns should recover the the previous state from backend.
+		ns := NewStore(b, &lease.FakeLessor{}, nil)
+
+		if keysRestore := readGaugeInt(&keysGauge); keysBefore != keysRestore {
+			t.Errorf("#%d: got %d key count, expected %d", i, keysRestore, keysBefore)
+		}
+
+		// wait for possible compaction to finish
+		testutil.WaitSchedule()
+		var nkvss [][]mvccpb.KeyValue
+		for k := int64(0); k < 10; k++ {
+			r, _ := ns.Range([]byte("a"), []byte("z"), RangeOptions{Rev: k})
+			nkvss = append(nkvss, r.KVs)
+		}
+		cleanup(ns, b, tmpPath)
+
+		if !reflect.DeepEqual(nkvss, kvss) {
+			t.Errorf("#%d: kvs history = %+v, want %+v", i, nkvss, kvss)
+		}
+	}
+}
+
+func readGaugeInt(g *prometheus.Gauge) int {
+	ch := make(chan prometheus.Metric, 1)
+	keysGauge.Collect(ch)
+	m := <-ch
+	mm := &dto.Metric{}
+	m.Write(mm)
+	return int(mm.GetGauge().GetValue())
+}
+
+func TestKVSnapshot(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	wkvs := put3TestKVs(s)
+
+	newPath := "new_test"
+	f, err := os.Create(newPath)
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.Remove(newPath)
+
+	snap := s.b.Snapshot()
+	defer snap.Close()
+	_, err = snap.WriteTo(f)
+	if err != nil {
+		t.Fatal(err)
+	}
+	f.Close()
+
+	ns := NewStore(b, &lease.FakeLessor{}, nil)
+	defer ns.Close()
+	r, err := ns.Range([]byte("a"), []byte("z"), RangeOptions{})
+	if err != nil {
+		t.Errorf("unexpect range error (%v)", err)
+	}
+	if !reflect.DeepEqual(r.KVs, wkvs) {
+		t.Errorf("kvs = %+v, want %+v", r.KVs, wkvs)
+	}
+	if r.Rev != 4 {
+		t.Errorf("rev = %d, want %d", r.Rev, 4)
+	}
+}
+
+func TestWatchableKVWatch(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
+	defer cleanup(s, b, tmpPath)
+
+	w := s.NewWatchStream()
+	defer w.Close()
+
+	wid, _ := w.Watch(0, []byte("foo"), []byte("fop"), 0)
+
+	wev := []mvccpb.Event{
+		{Type: mvccpb.PUT,
+			Kv: &mvccpb.KeyValue{
+				Key:            []byte("foo"),
+				Value:          []byte("bar"),
+				CreateRevision: 2,
+				ModRevision:    2,
+				Version:        1,
+				Lease:          1,
+			},
+		},
+		{
+			Type: mvccpb.PUT,
+			Kv: &mvccpb.KeyValue{
+				Key:            []byte("foo1"),
+				Value:          []byte("bar1"),
+				CreateRevision: 3,
+				ModRevision:    3,
+				Version:        1,
+				Lease:          2,
+			},
+		},
+		{
+			Type: mvccpb.PUT,
+			Kv: &mvccpb.KeyValue{
+				Key:            []byte("foo1"),
+				Value:          []byte("bar11"),
+				CreateRevision: 3,
+				ModRevision:    4,
+				Version:        2,
+				Lease:          3,
+			},
+		},
+	}
+
+	s.Put([]byte("foo"), []byte("bar"), 1)
+	select {
+	case resp := <-w.Chan():
+		if resp.WatchID != wid {
+			t.Errorf("resp.WatchID got = %d, want = %d", resp.WatchID, wid)
+		}
+		ev := resp.Events[0]
+		if !reflect.DeepEqual(ev, wev[0]) {
+			t.Errorf("watched event = %+v, want %+v", ev, wev[0])
+		}
+	case <-time.After(5 * time.Second):
+		// CPU might be too slow, and the routine is not able to switch around
+		testutil.FatalStack(t, "failed to watch the event")
+	}
+
+	s.Put([]byte("foo1"), []byte("bar1"), 2)
+	select {
+	case resp := <-w.Chan():
+		if resp.WatchID != wid {
+			t.Errorf("resp.WatchID got = %d, want = %d", resp.WatchID, wid)
+		}
+		ev := resp.Events[0]
+		if !reflect.DeepEqual(ev, wev[1]) {
+			t.Errorf("watched event = %+v, want %+v", ev, wev[1])
+		}
+	case <-time.After(5 * time.Second):
+		testutil.FatalStack(t, "failed to watch the event")
+	}
+
+	w = s.NewWatchStream()
+	wid, _ = w.Watch(0, []byte("foo1"), []byte("foo2"), 3)
+
+	select {
+	case resp := <-w.Chan():
+		if resp.WatchID != wid {
+			t.Errorf("resp.WatchID got = %d, want = %d", resp.WatchID, wid)
+		}
+		ev := resp.Events[0]
+		if !reflect.DeepEqual(ev, wev[1]) {
+			t.Errorf("watched event = %+v, want %+v", ev, wev[1])
+		}
+	case <-time.After(5 * time.Second):
+		testutil.FatalStack(t, "failed to watch the event")
+	}
+
+	s.Put([]byte("foo1"), []byte("bar11"), 3)
+	select {
+	case resp := <-w.Chan():
+		if resp.WatchID != wid {
+			t.Errorf("resp.WatchID got = %d, want = %d", resp.WatchID, wid)
+		}
+		ev := resp.Events[0]
+		if !reflect.DeepEqual(ev, wev[2]) {
+			t.Errorf("watched event = %+v, want %+v", ev, wev[2])
+		}
+	case <-time.After(5 * time.Second):
+		testutil.FatalStack(t, "failed to watch the event")
+	}
+}
+
+func cleanup(s KV, b backend.Backend, path string) {
+	s.Close()
+	b.Close()
+	os.Remove(path)
+}
+
+func put3TestKVs(s KV) []mvccpb.KeyValue {
+	s.Put([]byte("foo"), []byte("bar"), 1)
+	s.Put([]byte("foo1"), []byte("bar1"), 2)
+	s.Put([]byte("foo2"), []byte("bar2"), 3)
+	return []mvccpb.KeyValue{
+		{Key: []byte("foo"), Value: []byte("bar"), CreateRevision: 2, ModRevision: 2, Version: 1, Lease: 1},
+		{Key: []byte("foo1"), Value: []byte("bar1"), CreateRevision: 3, ModRevision: 3, Version: 1, Lease: 2},
+		{Key: []byte("foo2"), Value: []byte("bar2"), CreateRevision: 4, ModRevision: 4, Version: 1, Lease: 3},
+	}
+}
diff --git a/internal/mvcc/kv_view.go b/internal/mvcc/kv_view.go
new file mode 100644
index 0000000..8269a72
--- /dev/null
+++ b/internal/mvcc/kv_view.go
@@ -0,0 +1,51 @@
+// Copyright 2017 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import "github.com/coreos/etcd/internal/lease"
+
+type readView struct{ kv KV }
+
+func (rv *readView) FirstRev() int64 {
+	tr := rv.kv.Read()
+	defer tr.End()
+	return tr.FirstRev()
+}
+
+func (rv *readView) Rev() int64 {
+	tr := rv.kv.Read()
+	defer tr.End()
+	return tr.Rev()
+}
+
+func (rv *readView) Range(key, end []byte, ro RangeOptions) (r *RangeResult, err error) {
+	tr := rv.kv.Read()
+	defer tr.End()
+	return tr.Range(key, end, ro)
+}
+
+type writeView struct{ kv KV }
+
+func (wv *writeView) DeleteRange(key, end []byte) (n, rev int64) {
+	tw := wv.kv.Write()
+	defer tw.End()
+	return tw.DeleteRange(key, end)
+}
+
+func (wv *writeView) Put(key, value []byte, lease lease.LeaseID) (rev int64) {
+	tw := wv.kv.Write()
+	defer tw.End()
+	return tw.Put(key, value, lease)
+}
diff --git a/internal/mvcc/kvstore.go b/internal/mvcc/kvstore.go
new file mode 100644
index 0000000..54bb204
--- /dev/null
+++ b/internal/mvcc/kvstore.go
@@ -0,0 +1,497 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"context"
+	"encoding/binary"
+	"errors"
+	"hash/crc32"
+	"math"
+	"sync"
+	"sync/atomic"
+	"time"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+	"github.com/coreos/etcd/pkg/schedule"
+	"github.com/coreos/pkg/capnslog"
+)
+
+var (
+	keyBucketName  = []byte("key")
+	metaBucketName = []byte("meta")
+
+	consistentIndexKeyName  = []byte("consistent_index")
+	scheduledCompactKeyName = []byte("scheduledCompactRev")
+	finishedCompactKeyName  = []byte("finishedCompactRev")
+
+	ErrCompacted = errors.New("mvcc: required revision has been compacted")
+	ErrFutureRev = errors.New("mvcc: required revision is a future revision")
+	ErrCanceled  = errors.New("mvcc: watcher is canceled")
+	ErrClosed    = errors.New("mvcc: closed")
+
+	plog = capnslog.NewPackageLogger("github.com/coreos/etcd", "mvcc")
+)
+
+const (
+	// markedRevBytesLen is the byte length of marked revision.
+	// The first `revBytesLen` bytes represents a normal revision. The last
+	// one byte is the mark.
+	markedRevBytesLen      = revBytesLen + 1
+	markBytePosition       = markedRevBytesLen - 1
+	markTombstone     byte = 't'
+)
+
+var restoreChunkKeys = 10000 // non-const for testing
+
+// ConsistentIndexGetter is an interface that wraps the Get method.
+// Consistent index is the offset of an entry in a consistent replicated log.
+type ConsistentIndexGetter interface {
+	// ConsistentIndex returns the consistent index of current executing entry.
+	ConsistentIndex() uint64
+}
+
+type store struct {
+	ReadView
+	WriteView
+
+	// consistentIndex caches the "consistent_index" key's value. Accessed
+	// through atomics so must be 64-bit aligned.
+	consistentIndex uint64
+
+	// mu read locks for txns and write locks for non-txn store changes.
+	mu sync.RWMutex
+
+	ig ConsistentIndexGetter
+
+	b       backend.Backend
+	kvindex index
+
+	le lease.Lessor
+
+	// revMuLock protects currentRev and compactMainRev.
+	// Locked at end of write txn and released after write txn unlock lock.
+	// Locked before locking read txn and released after locking.
+	revMu sync.RWMutex
+	// currentRev is the revision of the last completed transaction.
+	currentRev int64
+	// compactMainRev is the main revision of the last compaction.
+	compactMainRev int64
+
+	// bytesBuf8 is a byte slice of length 8
+	// to avoid a repetitive allocation in saveIndex.
+	bytesBuf8 []byte
+
+	fifoSched schedule.Scheduler
+
+	stopc chan struct{}
+}
+
+// NewStore returns a new store. It is useful to create a store inside
+// mvcc pkg. It should only be used for testing externally.
+func NewStore(b backend.Backend, le lease.Lessor, ig ConsistentIndexGetter) *store {
+	s := &store{
+		b:       b,
+		ig:      ig,
+		kvindex: newTreeIndex(),
+
+		le: le,
+
+		currentRev:     1,
+		compactMainRev: -1,
+
+		bytesBuf8: make([]byte, 8),
+		fifoSched: schedule.NewFIFOScheduler(),
+
+		stopc: make(chan struct{}),
+	}
+	s.ReadView = &readView{s}
+	s.WriteView = &writeView{s}
+	if s.le != nil {
+		s.le.SetRangeDeleter(func() lease.TxnDelete { return s.Write() })
+	}
+
+	tx := s.b.BatchTx()
+	tx.Lock()
+	tx.UnsafeCreateBucket(keyBucketName)
+	tx.UnsafeCreateBucket(metaBucketName)
+	tx.Unlock()
+	s.b.ForceCommit()
+
+	if err := s.restore(); err != nil {
+		// TODO: return the error instead of panic here?
+		panic("failed to recover store from backend")
+	}
+
+	return s
+}
+
+func (s *store) compactBarrier(ctx context.Context, ch chan struct{}) {
+	if ctx == nil || ctx.Err() != nil {
+		s.mu.Lock()
+		select {
+		case <-s.stopc:
+		default:
+			f := func(ctx context.Context) { s.compactBarrier(ctx, ch) }
+			s.fifoSched.Schedule(f)
+		}
+		s.mu.Unlock()
+		return
+	}
+	close(ch)
+}
+
+func (s *store) Hash() (hash uint32, revision int64, err error) {
+	s.b.ForceCommit()
+	h, err := s.b.Hash(DefaultIgnores)
+	return h, s.currentRev, err
+}
+
+func (s *store) HashByRev(rev int64) (hash uint32, currentRev int64, compactRev int64, err error) {
+	s.mu.RLock()
+	s.revMu.RLock()
+	compactRev, currentRev = s.compactMainRev, s.currentRev
+	s.revMu.RUnlock()
+
+	if rev > 0 && rev <= compactRev {
+		s.mu.RUnlock()
+		return 0, 0, compactRev, ErrCompacted
+	} else if rev > 0 && rev > currentRev {
+		s.mu.RUnlock()
+		return 0, currentRev, 0, ErrFutureRev
+	}
+
+	if rev == 0 {
+		rev = currentRev
+	}
+	keep := s.kvindex.Keep(rev)
+
+	tx := s.b.ReadTx()
+	tx.Lock()
+	defer tx.Unlock()
+	s.mu.RUnlock()
+
+	upper := revision{main: rev + 1}
+	lower := revision{main: compactRev + 1}
+	h := crc32.New(crc32.MakeTable(crc32.Castagnoli))
+
+	h.Write(keyBucketName)
+	err = tx.UnsafeForEach(keyBucketName, func(k, v []byte) error {
+		kr := bytesToRev(k)
+		if !upper.GreaterThan(kr) {
+			return nil
+		}
+		// skip revisions that are scheduled for deletion
+		// due to compacting; don't skip if there isn't one.
+		if lower.GreaterThan(kr) && len(keep) > 0 {
+			if _, ok := keep[kr]; !ok {
+				return nil
+			}
+		}
+		h.Write(k)
+		h.Write(v)
+		return nil
+	})
+	return h.Sum32(), currentRev, compactRev, err
+}
+
+func (s *store) Compact(rev int64) (<-chan struct{}, error) {
+	s.mu.Lock()
+	defer s.mu.Unlock()
+	s.revMu.Lock()
+	defer s.revMu.Unlock()
+
+	if rev <= s.compactMainRev {
+		ch := make(chan struct{})
+		f := func(ctx context.Context) { s.compactBarrier(ctx, ch) }
+		s.fifoSched.Schedule(f)
+		return ch, ErrCompacted
+	}
+	if rev > s.currentRev {
+		return nil, ErrFutureRev
+	}
+
+	start := time.Now()
+
+	s.compactMainRev = rev
+
+	rbytes := newRevBytes()
+	revToBytes(revision{main: rev}, rbytes)
+
+	tx := s.b.BatchTx()
+	tx.Lock()
+	tx.UnsafePut(metaBucketName, scheduledCompactKeyName, rbytes)
+	tx.Unlock()
+	// ensure that desired compaction is persisted
+	s.b.ForceCommit()
+
+	keep := s.kvindex.Compact(rev)
+	ch := make(chan struct{})
+	var j = func(ctx context.Context) {
+		if ctx.Err() != nil {
+			s.compactBarrier(ctx, ch)
+			return
+		}
+		if !s.scheduleCompaction(rev, keep) {
+			s.compactBarrier(nil, ch)
+			return
+		}
+		close(ch)
+	}
+
+	s.fifoSched.Schedule(j)
+
+	indexCompactionPauseDurations.Observe(float64(time.Since(start) / time.Millisecond))
+	return ch, nil
+}
+
+// DefaultIgnores is a map of keys to ignore in hash checking.
+var DefaultIgnores map[backend.IgnoreKey]struct{}
+
+func init() {
+	DefaultIgnores = map[backend.IgnoreKey]struct{}{
+		// consistent index might be changed due to v2 internal sync, which
+		// is not controllable by the user.
+		{Bucket: string(metaBucketName), Key: string(consistentIndexKeyName)}: {},
+	}
+}
+
+func (s *store) Commit() {
+	s.mu.Lock()
+	defer s.mu.Unlock()
+
+	tx := s.b.BatchTx()
+	tx.Lock()
+	s.saveIndex(tx)
+	tx.Unlock()
+	s.b.ForceCommit()
+}
+
+func (s *store) Restore(b backend.Backend) error {
+	s.mu.Lock()
+	defer s.mu.Unlock()
+
+	close(s.stopc)
+	s.fifoSched.Stop()
+
+	atomic.StoreUint64(&s.consistentIndex, 0)
+	s.b = b
+	s.kvindex = newTreeIndex()
+	s.currentRev = 1
+	s.compactMainRev = -1
+	s.fifoSched = schedule.NewFIFOScheduler()
+	s.stopc = make(chan struct{})
+
+	return s.restore()
+}
+
+func (s *store) restore() error {
+	reportDbTotalSizeInBytesMu.Lock()
+	b := s.b
+	reportDbTotalSizeInBytes = func() float64 { return float64(b.Size()) }
+	reportDbTotalSizeInBytesMu.Unlock()
+
+	min, max := newRevBytes(), newRevBytes()
+	revToBytes(revision{main: 1}, min)
+	revToBytes(revision{main: math.MaxInt64, sub: math.MaxInt64}, max)
+
+	keyToLease := make(map[string]lease.LeaseID)
+
+	// restore index
+	tx := s.b.BatchTx()
+	tx.Lock()
+
+	_, finishedCompactBytes := tx.UnsafeRange(metaBucketName, finishedCompactKeyName, nil, 0)
+	if len(finishedCompactBytes) != 0 {
+		s.compactMainRev = bytesToRev(finishedCompactBytes[0]).main
+		plog.Printf("restore compact to %d", s.compactMainRev)
+	}
+	_, scheduledCompactBytes := tx.UnsafeRange(metaBucketName, scheduledCompactKeyName, nil, 0)
+	scheduledCompact := int64(0)
+	if len(scheduledCompactBytes) != 0 {
+		scheduledCompact = bytesToRev(scheduledCompactBytes[0]).main
+	}
+
+	// index keys concurrently as they're loaded in from tx
+	keysGauge.Set(0)
+	rkvc, revc := restoreIntoIndex(s.kvindex)
+	for {
+		keys, vals := tx.UnsafeRange(keyBucketName, min, max, int64(restoreChunkKeys))
+		if len(keys) == 0 {
+			break
+		}
+		// rkvc blocks if the total pending keys exceeds the restore
+		// chunk size to keep keys from consuming too much memory.
+		restoreChunk(rkvc, keys, vals, keyToLease)
+		if len(keys) < restoreChunkKeys {
+			// partial set implies final set
+			break
+		}
+		// next set begins after where this one ended
+		newMin := bytesToRev(keys[len(keys)-1][:revBytesLen])
+		newMin.sub++
+		revToBytes(newMin, min)
+	}
+	close(rkvc)
+	s.currentRev = <-revc
+
+	// keys in the range [compacted revision -N, compaction] might all be deleted due to compaction.
+	// the correct revision should be set to compaction revision in the case, not the largest revision
+	// we have seen.
+	if s.currentRev < s.compactMainRev {
+		s.currentRev = s.compactMainRev
+	}
+	if scheduledCompact <= s.compactMainRev {
+		scheduledCompact = 0
+	}
+
+	for key, lid := range keyToLease {
+		if s.le == nil {
+			panic("no lessor to attach lease")
+		}
+		err := s.le.Attach(lid, []lease.LeaseItem{{Key: key}})
+		if err != nil {
+			plog.Errorf("unexpected Attach error: %v", err)
+		}
+	}
+
+	tx.Unlock()
+
+	if scheduledCompact != 0 {
+		s.Compact(scheduledCompact)
+		plog.Printf("resume scheduled compaction at %d", scheduledCompact)
+	}
+
+	return nil
+}
+
+type revKeyValue struct {
+	key  []byte
+	kv   mvccpb.KeyValue
+	kstr string
+}
+
+func restoreIntoIndex(idx index) (chan<- revKeyValue, <-chan int64) {
+	rkvc, revc := make(chan revKeyValue, restoreChunkKeys), make(chan int64, 1)
+	go func() {
+		currentRev := int64(1)
+		defer func() { revc <- currentRev }()
+		// restore the tree index from streaming the unordered index.
+		kiCache := make(map[string]*keyIndex, restoreChunkKeys)
+		for rkv := range rkvc {
+			ki, ok := kiCache[rkv.kstr]
+			// purge kiCache if many keys but still missing in the cache
+			if !ok && len(kiCache) >= restoreChunkKeys {
+				i := 10
+				for k := range kiCache {
+					delete(kiCache, k)
+					if i--; i == 0 {
+						break
+					}
+				}
+			}
+			// cache miss, fetch from tree index if there
+			if !ok {
+				ki = &keyIndex{key: rkv.kv.Key}
+				if idxKey := idx.KeyIndex(ki); idxKey != nil {
+					kiCache[rkv.kstr], ki = idxKey, idxKey
+					ok = true
+				}
+			}
+			rev := bytesToRev(rkv.key)
+			currentRev = rev.main
+			if ok {
+				if isTombstone(rkv.key) {
+					ki.tombstone(rev.main, rev.sub)
+					continue
+				}
+				ki.put(rev.main, rev.sub)
+			} else if !isTombstone(rkv.key) {
+				ki.restore(revision{rkv.kv.CreateRevision, 0}, rev, rkv.kv.Version)
+				idx.Insert(ki)
+				kiCache[rkv.kstr] = ki
+			}
+		}
+	}()
+	return rkvc, revc
+}
+
+func restoreChunk(kvc chan<- revKeyValue, keys, vals [][]byte, keyToLease map[string]lease.LeaseID) {
+	for i, key := range keys {
+		rkv := revKeyValue{key: key}
+		if err := rkv.kv.Unmarshal(vals[i]); err != nil {
+			plog.Fatalf("cannot unmarshal event: %v", err)
+		}
+		rkv.kstr = string(rkv.kv.Key)
+		if isTombstone(key) {
+			delete(keyToLease, rkv.kstr)
+		} else if lid := lease.LeaseID(rkv.kv.Lease); lid != lease.NoLease {
+			keyToLease[rkv.kstr] = lid
+		} else {
+			delete(keyToLease, rkv.kstr)
+		}
+		kvc <- rkv
+	}
+}
+
+func (s *store) Close() error {
+	close(s.stopc)
+	s.fifoSched.Stop()
+	return nil
+}
+
+func (s *store) saveIndex(tx backend.BatchTx) {
+	if s.ig == nil {
+		return
+	}
+	bs := s.bytesBuf8
+	ci := s.ig.ConsistentIndex()
+	binary.BigEndian.PutUint64(bs, ci)
+	// put the index into the underlying backend
+	// tx has been locked in TxnBegin, so there is no need to lock it again
+	tx.UnsafePut(metaBucketName, consistentIndexKeyName, bs)
+	atomic.StoreUint64(&s.consistentIndex, ci)
+}
+
+func (s *store) ConsistentIndex() uint64 {
+	if ci := atomic.LoadUint64(&s.consistentIndex); ci > 0 {
+		return ci
+	}
+	tx := s.b.BatchTx()
+	tx.Lock()
+	defer tx.Unlock()
+	_, vs := tx.UnsafeRange(metaBucketName, consistentIndexKeyName, nil, 0)
+	if len(vs) == 0 {
+		return 0
+	}
+	v := binary.BigEndian.Uint64(vs[0])
+	atomic.StoreUint64(&s.consistentIndex, v)
+	return v
+}
+
+// appendMarkTombstone appends tombstone mark to normal revision bytes.
+func appendMarkTombstone(b []byte) []byte {
+	if len(b) != revBytesLen {
+		plog.Panicf("cannot append mark to non normal revision bytes")
+	}
+	return append(b, markTombstone)
+}
+
+// isTombstone checks whether the revision bytes is a tombstone.
+func isTombstone(b []byte) bool {
+	return len(b) == markedRevBytesLen && b[markBytePosition] == markTombstone
+}
diff --git a/internal/mvcc/kvstore_bench_test.go b/internal/mvcc/kvstore_bench_test.go
new file mode 100644
index 0000000..0d4381a
--- /dev/null
+++ b/internal/mvcc/kvstore_bench_test.go
@@ -0,0 +1,174 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"sync/atomic"
+	"testing"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+)
+
+type fakeConsistentIndex uint64
+
+func (i *fakeConsistentIndex) ConsistentIndex() uint64 {
+	return atomic.LoadUint64((*uint64)(i))
+}
+
+func BenchmarkStorePut(b *testing.B) {
+	var i fakeConsistentIndex
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(be, &lease.FakeLessor{}, &i)
+	defer cleanup(s, be, tmpPath)
+
+	// arbitrary number of bytes
+	bytesN := 64
+	keys := createBytesSlice(bytesN, b.N)
+	vals := createBytesSlice(bytesN, b.N)
+
+	b.ResetTimer()
+	for i := 0; i < b.N; i++ {
+		s.Put(keys[i], vals[i], lease.NoLease)
+	}
+}
+
+func BenchmarkStoreRangeKey1(b *testing.B)   { benchmarkStoreRange(b, 1) }
+func BenchmarkStoreRangeKey100(b *testing.B) { benchmarkStoreRange(b, 100) }
+
+func benchmarkStoreRange(b *testing.B, n int) {
+	var i fakeConsistentIndex
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(be, &lease.FakeLessor{}, &i)
+	defer cleanup(s, be, tmpPath)
+
+	// 64 byte key/val
+	keys, val := createBytesSlice(64, n), createBytesSlice(64, 1)
+	for i := range keys {
+		s.Put(keys[i], val[0], lease.NoLease)
+	}
+	// Force into boltdb tx instead of backend read tx.
+	s.Commit()
+
+	var begin, end []byte
+	if n == 1 {
+		begin, end = keys[0], nil
+	} else {
+		begin, end = []byte{}, []byte{}
+	}
+
+	b.ReportAllocs()
+	b.ResetTimer()
+	for i := 0; i < b.N; i++ {
+		s.Range(begin, end, RangeOptions{})
+	}
+}
+
+func BenchmarkConsistentIndex(b *testing.B) {
+	fci := fakeConsistentIndex(10)
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(be, &lease.FakeLessor{}, &fci)
+	defer cleanup(s, be, tmpPath)
+
+	tx := s.b.BatchTx()
+	tx.Lock()
+	s.saveIndex(tx)
+	tx.Unlock()
+
+	b.ReportAllocs()
+	b.ResetTimer()
+	for i := 0; i < b.N; i++ {
+		s.ConsistentIndex()
+	}
+}
+
+// BenchmarkStoreTxnPutUpdate is same as above, but instead updates single key
+func BenchmarkStorePutUpdate(b *testing.B) {
+	var i fakeConsistentIndex
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(be, &lease.FakeLessor{}, &i)
+	defer cleanup(s, be, tmpPath)
+
+	// arbitrary number of bytes
+	keys := createBytesSlice(64, 1)
+	vals := createBytesSlice(1024, 1)
+
+	b.ResetTimer()
+	for i := 0; i < b.N; i++ {
+		s.Put(keys[0], vals[0], lease.NoLease)
+	}
+}
+
+// BenchmarkStoreTxnPut benchmarks the Put operation
+// with transaction begin and end, where transaction involves
+// some synchronization operations, such as mutex locking.
+func BenchmarkStoreTxnPut(b *testing.B) {
+	var i fakeConsistentIndex
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(be, &lease.FakeLessor{}, &i)
+	defer cleanup(s, be, tmpPath)
+
+	// arbitrary number of bytes
+	bytesN := 64
+	keys := createBytesSlice(bytesN, b.N)
+	vals := createBytesSlice(bytesN, b.N)
+
+	b.ResetTimer()
+	b.ReportAllocs()
+	for i := 0; i < b.N; i++ {
+		txn := s.Write()
+		txn.Put(keys[i], vals[i], lease.NoLease)
+		txn.End()
+	}
+}
+
+// benchmarkStoreRestore benchmarks the restore operation
+func benchmarkStoreRestore(revsPerKey int, b *testing.B) {
+	var i fakeConsistentIndex
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(be, &lease.FakeLessor{}, &i)
+	// use closure to capture 's' to pick up the reassignment
+	defer func() { cleanup(s, be, tmpPath) }()
+
+	// arbitrary number of bytes
+	bytesN := 64
+	keys := createBytesSlice(bytesN, b.N)
+	vals := createBytesSlice(bytesN, b.N)
+
+	for i := 0; i < b.N; i++ {
+		for j := 0; j < revsPerKey; j++ {
+			txn := s.Write()
+			txn.Put(keys[i], vals[i], lease.NoLease)
+			txn.End()
+		}
+	}
+	s.Close()
+
+	b.ReportAllocs()
+	b.ResetTimer()
+	s = NewStore(be, &lease.FakeLessor{}, &i)
+}
+
+func BenchmarkStoreRestoreRevs1(b *testing.B) {
+	benchmarkStoreRestore(1, b)
+}
+
+func BenchmarkStoreRestoreRevs10(b *testing.B) {
+	benchmarkStoreRestore(10, b)
+}
+
+func BenchmarkStoreRestoreRevs20(b *testing.B) {
+	benchmarkStoreRestore(20, b)
+}
diff --git a/internal/mvcc/kvstore_compaction.go b/internal/mvcc/kvstore_compaction.go
new file mode 100644
index 0000000..1726490
--- /dev/null
+++ b/internal/mvcc/kvstore_compaction.go
@@ -0,0 +1,69 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"encoding/binary"
+	"time"
+)
+
+func (s *store) scheduleCompaction(compactMainRev int64, keep map[revision]struct{}) bool {
+	totalStart := time.Now()
+	defer dbCompactionTotalDurations.Observe(float64(time.Since(totalStart) / time.Millisecond))
+	keyCompactions := 0
+	defer func() { dbCompactionKeysCounter.Add(float64(keyCompactions)) }()
+
+	end := make([]byte, 8)
+	binary.BigEndian.PutUint64(end, uint64(compactMainRev+1))
+
+	batchsize := int64(10000)
+	last := make([]byte, 8+1+8)
+	for {
+		var rev revision
+
+		start := time.Now()
+		tx := s.b.BatchTx()
+		tx.Lock()
+
+		keys, _ := tx.UnsafeRange(keyBucketName, last, end, batchsize)
+		for _, key := range keys {
+			rev = bytesToRev(key)
+			if _, ok := keep[rev]; !ok {
+				tx.UnsafeDelete(keyBucketName, key)
+				keyCompactions++
+			}
+		}
+
+		if len(keys) < int(batchsize) {
+			rbytes := make([]byte, 8+1+8)
+			revToBytes(revision{main: compactMainRev}, rbytes)
+			tx.UnsafePut(metaBucketName, finishedCompactKeyName, rbytes)
+			tx.Unlock()
+			plog.Printf("finished scheduled compaction at %d (took %v)", compactMainRev, time.Since(totalStart))
+			return true
+		}
+
+		// update last
+		revToBytes(revision{main: rev.main, sub: rev.sub + 1}, last)
+		tx.Unlock()
+		dbCompactionPauseDurations.Observe(float64(time.Since(start) / time.Millisecond))
+
+		select {
+		case <-time.After(100 * time.Millisecond):
+		case <-s.stopc:
+			return false
+		}
+	}
+}
diff --git a/internal/mvcc/kvstore_compaction_test.go b/internal/mvcc/kvstore_compaction_test.go
new file mode 100644
index 0000000..1dc9e08
--- /dev/null
+++ b/internal/mvcc/kvstore_compaction_test.go
@@ -0,0 +1,135 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"os"
+	"reflect"
+	"testing"
+	"time"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+)
+
+func TestScheduleCompaction(t *testing.T) {
+	revs := []revision{{1, 0}, {2, 0}, {3, 0}}
+
+	tests := []struct {
+		rev   int64
+		keep  map[revision]struct{}
+		wrevs []revision
+	}{
+		// compact at 1 and discard all history
+		{
+			1,
+			nil,
+			revs[1:],
+		},
+		// compact at 3 and discard all history
+		{
+			3,
+			nil,
+			nil,
+		},
+		// compact at 1 and keeps history one step earlier
+		{
+			1,
+			map[revision]struct{}{
+				{main: 1}: {},
+			},
+			revs,
+		},
+		// compact at 1 and keeps history two steps earlier
+		{
+			3,
+			map[revision]struct{}{
+				{main: 2}: {},
+				{main: 3}: {},
+			},
+			revs[1:],
+		},
+	}
+	for i, tt := range tests {
+		b, tmpPath := backend.NewDefaultTmpBackend()
+		s := NewStore(b, &lease.FakeLessor{}, nil)
+		tx := s.b.BatchTx()
+
+		tx.Lock()
+		ibytes := newRevBytes()
+		for _, rev := range revs {
+			revToBytes(rev, ibytes)
+			tx.UnsafePut(keyBucketName, ibytes, []byte("bar"))
+		}
+		tx.Unlock()
+
+		s.scheduleCompaction(tt.rev, tt.keep)
+
+		tx.Lock()
+		for _, rev := range tt.wrevs {
+			revToBytes(rev, ibytes)
+			keys, _ := tx.UnsafeRange(keyBucketName, ibytes, nil, 0)
+			if len(keys) != 1 {
+				t.Errorf("#%d: range on %v = %d, want 1", i, rev, len(keys))
+			}
+		}
+		_, vals := tx.UnsafeRange(metaBucketName, finishedCompactKeyName, nil, 0)
+		revToBytes(revision{main: tt.rev}, ibytes)
+		if w := [][]byte{ibytes}; !reflect.DeepEqual(vals, w) {
+			t.Errorf("#%d: vals on %v = %+v, want %+v", i, finishedCompactKeyName, vals, w)
+		}
+		tx.Unlock()
+
+		cleanup(s, b, tmpPath)
+	}
+}
+
+func TestCompactAllAndRestore(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s0 := NewStore(b, &lease.FakeLessor{}, nil)
+	defer os.Remove(tmpPath)
+
+	s0.Put([]byte("foo"), []byte("bar"), lease.NoLease)
+	s0.Put([]byte("foo"), []byte("bar1"), lease.NoLease)
+	s0.Put([]byte("foo"), []byte("bar2"), lease.NoLease)
+	s0.DeleteRange([]byte("foo"), nil)
+
+	rev := s0.Rev()
+	// compact all keys
+	done, err := s0.Compact(rev)
+	if err != nil {
+		t.Fatal(err)
+	}
+
+	select {
+	case <-done:
+	case <-time.After(10 * time.Second):
+		t.Fatal("timeout waiting for compaction to finish")
+	}
+
+	err = s0.Close()
+	if err != nil {
+		t.Fatal(err)
+	}
+
+	s1 := NewStore(b, &lease.FakeLessor{}, nil)
+	if s1.Rev() != rev {
+		t.Errorf("rev = %v, want %v", s1.Rev(), rev)
+	}
+	_, err = s1.Range([]byte("foo"), nil, RangeOptions{})
+	if err != nil {
+		t.Errorf("unexpect range error %v", err)
+	}
+}
diff --git a/internal/mvcc/kvstore_test.go b/internal/mvcc/kvstore_test.go
new file mode 100644
index 0000000..91950ec
--- /dev/null
+++ b/internal/mvcc/kvstore_test.go
@@ -0,0 +1,829 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"crypto/rand"
+	"encoding/binary"
+	"fmt"
+	"math"
+	mrand "math/rand"
+	"os"
+	"reflect"
+	"sync"
+	"testing"
+	"time"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+	"github.com/coreos/etcd/pkg/schedule"
+	"github.com/coreos/etcd/pkg/testutil"
+)
+
+func TestStoreRev(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer s.Close()
+	defer os.Remove(tmpPath)
+
+	for i := 1; i <= 3; i++ {
+		s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
+		if r := s.Rev(); r != int64(i+1) {
+			t.Errorf("#%d: rev = %d, want %d", i, r, i+1)
+		}
+	}
+}
+
+func TestStorePut(t *testing.T) {
+	kv := mvccpb.KeyValue{
+		Key:            []byte("foo"),
+		Value:          []byte("bar"),
+		CreateRevision: 1,
+		ModRevision:    2,
+		Version:        1,
+	}
+	kvb, err := kv.Marshal()
+	if err != nil {
+		t.Fatal(err)
+	}
+
+	tests := []struct {
+		rev revision
+		r   indexGetResp
+		rr  *rangeResp
+
+		wrev    revision
+		wkey    []byte
+		wkv     mvccpb.KeyValue
+		wputrev revision
+	}{
+		{
+			revision{1, 0},
+			indexGetResp{revision{}, revision{}, 0, ErrRevisionNotFound},
+			nil,
+
+			revision{2, 0},
+			newTestKeyBytes(revision{2, 0}, false),
+			mvccpb.KeyValue{
+				Key:            []byte("foo"),
+				Value:          []byte("bar"),
+				CreateRevision: 2,
+				ModRevision:    2,
+				Version:        1,
+				Lease:          1,
+			},
+			revision{2, 0},
+		},
+		{
+			revision{1, 1},
+			indexGetResp{revision{2, 0}, revision{2, 0}, 1, nil},
+			&rangeResp{[][]byte{newTestKeyBytes(revision{2, 1}, false)}, [][]byte{kvb}},
+
+			revision{2, 0},
+			newTestKeyBytes(revision{2, 0}, false),
+			mvccpb.KeyValue{
+				Key:            []byte("foo"),
+				Value:          []byte("bar"),
+				CreateRevision: 2,
+				ModRevision:    2,
+				Version:        2,
+				Lease:          2,
+			},
+			revision{2, 0},
+		},
+		{
+			revision{2, 0},
+			indexGetResp{revision{2, 1}, revision{2, 0}, 2, nil},
+			&rangeResp{[][]byte{newTestKeyBytes(revision{2, 1}, false)}, [][]byte{kvb}},
+
+			revision{3, 0},
+			newTestKeyBytes(revision{3, 0}, false),
+			mvccpb.KeyValue{
+				Key:            []byte("foo"),
+				Value:          []byte("bar"),
+				CreateRevision: 2,
+				ModRevision:    3,
+				Version:        3,
+				Lease:          3,
+			},
+			revision{3, 0},
+		},
+	}
+	for i, tt := range tests {
+		s := newFakeStore()
+		b := s.b.(*fakeBackend)
+		fi := s.kvindex.(*fakeIndex)
+
+		s.currentRev = tt.rev.main
+		fi.indexGetRespc <- tt.r
+		if tt.rr != nil {
+			b.tx.rangeRespc <- *tt.rr
+		}
+
+		s.Put([]byte("foo"), []byte("bar"), lease.LeaseID(i+1))
+
+		data, err := tt.wkv.Marshal()
+		if err != nil {
+			t.Errorf("#%d: marshal err = %v, want nil", i, err)
+		}
+
+		wact := []testutil.Action{
+			{Name: "seqput", Params: []interface{}{keyBucketName, tt.wkey, data}},
+		}
+
+		if tt.rr != nil {
+			wact = []testutil.Action{
+				{Name: "seqput", Params: []interface{}{keyBucketName, tt.wkey, data}},
+			}
+		}
+
+		if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
+			t.Errorf("#%d: tx action = %+v, want %+v", i, g, wact)
+		}
+		wact = []testutil.Action{
+			{Name: "get", Params: []interface{}{[]byte("foo"), tt.wputrev.main}},
+			{Name: "put", Params: []interface{}{[]byte("foo"), tt.wputrev}},
+		}
+		if g := fi.Action(); !reflect.DeepEqual(g, wact) {
+			t.Errorf("#%d: index action = %+v, want %+v", i, g, wact)
+		}
+		if s.currentRev != tt.wrev.main {
+			t.Errorf("#%d: rev = %+v, want %+v", i, s.currentRev, tt.wrev)
+		}
+
+		s.Close()
+	}
+}
+
+func TestStoreRange(t *testing.T) {
+	key := newTestKeyBytes(revision{2, 0}, false)
+	kv := mvccpb.KeyValue{
+		Key:            []byte("foo"),
+		Value:          []byte("bar"),
+		CreateRevision: 1,
+		ModRevision:    2,
+		Version:        1,
+	}
+	kvb, err := kv.Marshal()
+	if err != nil {
+		t.Fatal(err)
+	}
+	wrev := int64(2)
+
+	tests := []struct {
+		idxr indexRangeResp
+		r    rangeResp
+	}{
+		{
+			indexRangeResp{[][]byte{[]byte("foo")}, []revision{{2, 0}}},
+			rangeResp{[][]byte{key}, [][]byte{kvb}},
+		},
+		{
+			indexRangeResp{[][]byte{[]byte("foo"), []byte("foo1")}, []revision{{2, 0}, {3, 0}}},
+			rangeResp{[][]byte{key}, [][]byte{kvb}},
+		},
+	}
+
+	ro := RangeOptions{Limit: 1, Rev: 0, Count: false}
+	for i, tt := range tests {
+		s := newFakeStore()
+		b := s.b.(*fakeBackend)
+		fi := s.kvindex.(*fakeIndex)
+
+		s.currentRev = 2
+		b.tx.rangeRespc <- tt.r
+		fi.indexRangeRespc <- tt.idxr
+
+		ret, err := s.Range([]byte("foo"), []byte("goo"), ro)
+		if err != nil {
+			t.Errorf("#%d: err = %v, want nil", i, err)
+		}
+		if w := []mvccpb.KeyValue{kv}; !reflect.DeepEqual(ret.KVs, w) {
+			t.Errorf("#%d: kvs = %+v, want %+v", i, ret.KVs, w)
+		}
+		if ret.Rev != wrev {
+			t.Errorf("#%d: rev = %d, want %d", i, ret.Rev, wrev)
+		}
+
+		wstart := newRevBytes()
+		revToBytes(tt.idxr.revs[0], wstart)
+		wact := []testutil.Action{
+			{Name: "range", Params: []interface{}{keyBucketName, wstart, []byte(nil), int64(0)}},
+		}
+		if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
+			t.Errorf("#%d: tx action = %+v, want %+v", i, g, wact)
+		}
+		wact = []testutil.Action{
+			{Name: "range", Params: []interface{}{[]byte("foo"), []byte("goo"), wrev}},
+		}
+		if g := fi.Action(); !reflect.DeepEqual(g, wact) {
+			t.Errorf("#%d: index action = %+v, want %+v", i, g, wact)
+		}
+		if s.currentRev != 2 {
+			t.Errorf("#%d: current rev = %+v, want %+v", i, s.currentRev, 2)
+		}
+
+		s.Close()
+	}
+}
+
+func TestStoreDeleteRange(t *testing.T) {
+	key := newTestKeyBytes(revision{2, 0}, false)
+	kv := mvccpb.KeyValue{
+		Key:            []byte("foo"),
+		Value:          []byte("bar"),
+		CreateRevision: 1,
+		ModRevision:    2,
+		Version:        1,
+	}
+	kvb, err := kv.Marshal()
+	if err != nil {
+		t.Fatal(err)
+	}
+
+	tests := []struct {
+		rev revision
+		r   indexRangeResp
+		rr  rangeResp
+
+		wkey    []byte
+		wrev    revision
+		wrrev   int64
+		wdelrev revision
+	}{
+		{
+			revision{2, 0},
+			indexRangeResp{[][]byte{[]byte("foo")}, []revision{{2, 0}}},
+			rangeResp{[][]byte{key}, [][]byte{kvb}},
+
+			newTestKeyBytes(revision{3, 0}, true),
+			revision{3, 0},
+			2,
+			revision{3, 0},
+		},
+	}
+	for i, tt := range tests {
+		s := newFakeStore()
+		b := s.b.(*fakeBackend)
+		fi := s.kvindex.(*fakeIndex)
+
+		s.currentRev = tt.rev.main
+		fi.indexRangeRespc <- tt.r
+		b.tx.rangeRespc <- tt.rr
+
+		n, _ := s.DeleteRange([]byte("foo"), []byte("goo"))
+		if n != 1 {
+			t.Errorf("#%d: n = %d, want 1", i, n)
+		}
+
+		data, err := (&mvccpb.KeyValue{
+			Key: []byte("foo"),
+		}).Marshal()
+		if err != nil {
+			t.Errorf("#%d: marshal err = %v, want nil", i, err)
+		}
+		wact := []testutil.Action{
+			{Name: "seqput", Params: []interface{}{keyBucketName, tt.wkey, data}},
+		}
+		if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
+			t.Errorf("#%d: tx action = %+v, want %+v", i, g, wact)
+		}
+		wact = []testutil.Action{
+			{Name: "range", Params: []interface{}{[]byte("foo"), []byte("goo"), tt.wrrev}},
+			{Name: "tombstone", Params: []interface{}{[]byte("foo"), tt.wdelrev}},
+		}
+		if g := fi.Action(); !reflect.DeepEqual(g, wact) {
+			t.Errorf("#%d: index action = %+v, want %+v", i, g, wact)
+		}
+		if s.currentRev != tt.wrev.main {
+			t.Errorf("#%d: rev = %+v, want %+v", i, s.currentRev, tt.wrev)
+		}
+	}
+}
+
+func TestStoreCompact(t *testing.T) {
+	s := newFakeStore()
+	defer s.Close()
+	b := s.b.(*fakeBackend)
+	fi := s.kvindex.(*fakeIndex)
+
+	s.currentRev = 3
+	fi.indexCompactRespc <- map[revision]struct{}{{1, 0}: {}}
+	key1 := newTestKeyBytes(revision{1, 0}, false)
+	key2 := newTestKeyBytes(revision{2, 0}, false)
+	b.tx.rangeRespc <- rangeResp{[][]byte{key1, key2}, nil}
+
+	s.Compact(3)
+	s.fifoSched.WaitFinish(1)
+
+	if s.compactMainRev != 3 {
+		t.Errorf("compact main rev = %d, want 3", s.compactMainRev)
+	}
+	end := make([]byte, 8)
+	binary.BigEndian.PutUint64(end, uint64(4))
+	wact := []testutil.Action{
+		{Name: "put", Params: []interface{}{metaBucketName, scheduledCompactKeyName, newTestRevBytes(revision{3, 0})}},
+		{Name: "range", Params: []interface{}{keyBucketName, make([]byte, 17), end, int64(10000)}},
+		{Name: "delete", Params: []interface{}{keyBucketName, key2}},
+		{Name: "put", Params: []interface{}{metaBucketName, finishedCompactKeyName, newTestRevBytes(revision{3, 0})}},
+	}
+	if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
+		t.Errorf("tx actions = %+v, want %+v", g, wact)
+	}
+	wact = []testutil.Action{
+		{Name: "compact", Params: []interface{}{int64(3)}},
+	}
+	if g := fi.Action(); !reflect.DeepEqual(g, wact) {
+		t.Errorf("index action = %+v, want %+v", g, wact)
+	}
+}
+
+func TestStoreRestore(t *testing.T) {
+	s := newFakeStore()
+	b := s.b.(*fakeBackend)
+	fi := s.kvindex.(*fakeIndex)
+
+	putkey := newTestKeyBytes(revision{3, 0}, false)
+	putkv := mvccpb.KeyValue{
+		Key:            []byte("foo"),
+		Value:          []byte("bar"),
+		CreateRevision: 4,
+		ModRevision:    4,
+		Version:        1,
+	}
+	putkvb, err := putkv.Marshal()
+	if err != nil {
+		t.Fatal(err)
+	}
+	delkey := newTestKeyBytes(revision{5, 0}, true)
+	delkv := mvccpb.KeyValue{
+		Key: []byte("foo"),
+	}
+	delkvb, err := delkv.Marshal()
+	if err != nil {
+		t.Fatal(err)
+	}
+	b.tx.rangeRespc <- rangeResp{[][]byte{finishedCompactKeyName}, [][]byte{newTestRevBytes(revision{3, 0})}}
+	b.tx.rangeRespc <- rangeResp{[][]byte{scheduledCompactKeyName}, [][]byte{newTestRevBytes(revision{3, 0})}}
+
+	b.tx.rangeRespc <- rangeResp{[][]byte{putkey, delkey}, [][]byte{putkvb, delkvb}}
+	b.tx.rangeRespc <- rangeResp{nil, nil}
+
+	s.restore()
+
+	if s.compactMainRev != 3 {
+		t.Errorf("compact rev = %d, want 5", s.compactMainRev)
+	}
+	if s.currentRev != 5 {
+		t.Errorf("current rev = %v, want 5", s.currentRev)
+	}
+	wact := []testutil.Action{
+		{Name: "range", Params: []interface{}{metaBucketName, finishedCompactKeyName, []byte(nil), int64(0)}},
+		{Name: "range", Params: []interface{}{metaBucketName, scheduledCompactKeyName, []byte(nil), int64(0)}},
+		{Name: "range", Params: []interface{}{keyBucketName, newTestRevBytes(revision{1, 0}), newTestRevBytes(revision{math.MaxInt64, math.MaxInt64}), int64(restoreChunkKeys)}},
+	}
+	if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
+		t.Errorf("tx actions = %+v, want %+v", g, wact)
+	}
+
+	gens := []generation{
+		{created: revision{4, 0}, ver: 2, revs: []revision{{3, 0}, {5, 0}}},
+		{created: revision{0, 0}, ver: 0, revs: nil},
+	}
+	ki := &keyIndex{key: []byte("foo"), modified: revision{5, 0}, generations: gens}
+	wact = []testutil.Action{
+		{Name: "keyIndex", Params: []interface{}{ki}},
+		{Name: "insert", Params: []interface{}{ki}},
+	}
+	if g := fi.Action(); !reflect.DeepEqual(g, wact) {
+		t.Errorf("index action = %+v, want %+v", g, wact)
+	}
+}
+
+func TestRestoreDelete(t *testing.T) {
+	oldChunk := restoreChunkKeys
+	restoreChunkKeys = mrand.Intn(3) + 2
+	defer func() { restoreChunkKeys = oldChunk }()
+
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer os.Remove(tmpPath)
+
+	keys := make(map[string]struct{})
+	for i := 0; i < 20; i++ {
+		ks := fmt.Sprintf("foo-%d", i)
+		k := []byte(ks)
+		s.Put(k, []byte("bar"), lease.NoLease)
+		keys[ks] = struct{}{}
+		switch mrand.Intn(3) {
+		case 0:
+			// put random key from past via random range on map
+			ks = fmt.Sprintf("foo-%d", mrand.Intn(i+1))
+			s.Put([]byte(ks), []byte("baz"), lease.NoLease)
+			keys[ks] = struct{}{}
+		case 1:
+			// delete random key via random range on map
+			for k := range keys {
+				s.DeleteRange([]byte(k), nil)
+				delete(keys, k)
+				break
+			}
+		}
+	}
+	s.Close()
+
+	s = NewStore(b, &lease.FakeLessor{}, nil)
+	defer s.Close()
+	for i := 0; i < 20; i++ {
+		ks := fmt.Sprintf("foo-%d", i)
+		r, err := s.Range([]byte(ks), nil, RangeOptions{})
+		if err != nil {
+			t.Fatal(err)
+		}
+		if _, ok := keys[ks]; ok {
+			if len(r.KVs) == 0 {
+				t.Errorf("#%d: expected %q, got deleted", i, ks)
+			}
+		} else if len(r.KVs) != 0 {
+			t.Errorf("#%d: expected deleted, got %q", i, ks)
+		}
+	}
+}
+
+func TestRestoreContinueUnfinishedCompaction(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s0 := NewStore(b, &lease.FakeLessor{}, nil)
+	defer os.Remove(tmpPath)
+
+	s0.Put([]byte("foo"), []byte("bar"), lease.NoLease)
+	s0.Put([]byte("foo"), []byte("bar1"), lease.NoLease)
+	s0.Put([]byte("foo"), []byte("bar2"), lease.NoLease)
+
+	// write scheduled compaction, but not do compaction
+	rbytes := newRevBytes()
+	revToBytes(revision{main: 2}, rbytes)
+	tx := s0.b.BatchTx()
+	tx.Lock()
+	tx.UnsafePut(metaBucketName, scheduledCompactKeyName, rbytes)
+	tx.Unlock()
+
+	s0.Close()
+
+	s1 := NewStore(b, &lease.FakeLessor{}, nil)
+
+	// wait for scheduled compaction to be finished
+	time.Sleep(100 * time.Millisecond)
+
+	if _, err := s1.Range([]byte("foo"), nil, RangeOptions{Rev: 1}); err != ErrCompacted {
+		t.Errorf("range on compacted rev error = %v, want %v", err, ErrCompacted)
+	}
+	// check the key in backend is deleted
+	revbytes := newRevBytes()
+	revToBytes(revision{main: 1}, revbytes)
+
+	// The disk compaction is done asynchronously and requires more time on slow disk.
+	// try 5 times for CI with slow IO.
+	for i := 0; i < 5; i++ {
+		tx = s1.b.BatchTx()
+		tx.Lock()
+		ks, _ := tx.UnsafeRange(keyBucketName, revbytes, nil, 0)
+		tx.Unlock()
+		if len(ks) != 0 {
+			time.Sleep(100 * time.Millisecond)
+			continue
+		}
+		return
+	}
+
+	t.Errorf("key for rev %+v still exists, want deleted", bytesToRev(revbytes))
+}
+
+type hashKVResult struct {
+	hash       uint32
+	compactRev int64
+}
+
+// TestHashKVWhenCompacting ensures that HashKV returns correct hash when compacting.
+func TestHashKVWhenCompacting(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer os.Remove(tmpPath)
+
+	rev := 10000
+	for i := 2; i <= rev; i++ {
+		s.Put([]byte("foo"), []byte(fmt.Sprintf("bar%d", i)), lease.NoLease)
+	}
+
+	hashCompactc := make(chan hashKVResult, 1)
+
+	donec := make(chan struct{})
+	var wg sync.WaitGroup
+	for i := 0; i < 10; i++ {
+		wg.Add(1)
+		go func() {
+			defer wg.Done()
+			for {
+				hash, _, compactRev, err := s.HashByRev(int64(rev))
+				if err != nil {
+					t.Fatal(err)
+				}
+				select {
+				case <-donec:
+					return
+				case hashCompactc <- hashKVResult{hash, compactRev}:
+				}
+			}
+		}()
+	}
+
+	go func() {
+		defer close(donec)
+		revHash := make(map[int64]uint32)
+		for round := 0; round < 1000; round++ {
+			r := <-hashCompactc
+			if revHash[r.compactRev] == 0 {
+				revHash[r.compactRev] = r.hash
+			}
+			if r.hash != revHash[r.compactRev] {
+				t.Fatalf("Hashes differ (current %v) != (saved %v)", r.hash, revHash[r.compactRev])
+			}
+		}
+	}()
+
+	wg.Add(1)
+	go func() {
+		defer wg.Done()
+		for i := 100; i >= 0; i-- {
+			_, err := s.Compact(int64(rev - 1 - i))
+			if err != nil {
+				t.Fatal(err)
+			}
+			time.Sleep(10 * time.Millisecond)
+		}
+	}()
+
+	select {
+	case <-donec:
+		wg.Wait()
+	case <-time.After(10 * time.Second):
+		testutil.FatalStack(t, "timeout")
+	}
+}
+
+// TestHashKVZeroRevision ensures that "HashByRev(0)" computes
+// correct hash value with latest revision.
+func TestHashKVZeroRevision(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer os.Remove(tmpPath)
+
+	rev := 1000
+	for i := 2; i <= rev; i++ {
+		s.Put([]byte("foo"), []byte(fmt.Sprintf("bar%d", i)), lease.NoLease)
+	}
+	if _, err := s.Compact(int64(rev / 2)); err != nil {
+		t.Fatal(err)
+	}
+
+	hash1, _, _, err := s.HashByRev(int64(rev))
+	if err != nil {
+		t.Fatal(err)
+	}
+	var hash2 uint32
+	hash2, _, _, err = s.HashByRev(0)
+	if err != nil {
+		t.Fatal(err)
+	}
+	if hash1 != hash2 {
+		t.Errorf("hash %d (rev %d) != hash %d (rev 0)", hash1, rev, hash2)
+	}
+}
+
+func TestTxnPut(t *testing.T) {
+	// assign arbitrary size
+	bytesN := 30
+	sliceN := 100
+	keys := createBytesSlice(bytesN, sliceN)
+	vals := createBytesSlice(bytesN, sliceN)
+
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	for i := 0; i < sliceN; i++ {
+		txn := s.Write()
+		base := int64(i + 2)
+		if rev := txn.Put(keys[i], vals[i], lease.NoLease); rev != base {
+			t.Errorf("#%d: rev = %d, want %d", i, rev, base)
+		}
+		txn.End()
+	}
+}
+
+func TestTxnBlockBackendForceCommit(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(b, &lease.FakeLessor{}, nil)
+	defer os.Remove(tmpPath)
+
+	txn := s.Read()
+
+	done := make(chan struct{})
+	go func() {
+		s.b.ForceCommit()
+		done <- struct{}{}
+	}()
+	select {
+	case <-done:
+		t.Fatalf("failed to block ForceCommit")
+	case <-time.After(100 * time.Millisecond):
+	}
+
+	txn.End()
+	select {
+	case <-done:
+	case <-time.After(5 * time.Second): // wait 5 seconds for CI with slow IO
+		testutil.FatalStack(t, "failed to execute ForceCommit")
+	}
+}
+
+// TODO: test attach key to lessor
+
+func newTestRevBytes(rev revision) []byte {
+	bytes := newRevBytes()
+	revToBytes(rev, bytes)
+	return bytes
+}
+
+func newTestKeyBytes(rev revision, tombstone bool) []byte {
+	bytes := newRevBytes()
+	revToBytes(rev, bytes)
+	if tombstone {
+		bytes = appendMarkTombstone(bytes)
+	}
+	return bytes
+}
+
+func newFakeStore() *store {
+	b := &fakeBackend{&fakeBatchTx{
+		Recorder:   &testutil.RecorderBuffered{},
+		rangeRespc: make(chan rangeResp, 5)}}
+	fi := &fakeIndex{
+		Recorder:              &testutil.RecorderBuffered{},
+		indexGetRespc:         make(chan indexGetResp, 1),
+		indexRangeRespc:       make(chan indexRangeResp, 1),
+		indexRangeEventsRespc: make(chan indexRangeEventsResp, 1),
+		indexCompactRespc:     make(chan map[revision]struct{}, 1),
+	}
+	s := &store{
+		b:              b,
+		le:             &lease.FakeLessor{},
+		kvindex:        fi,
+		currentRev:     0,
+		compactMainRev: -1,
+		fifoSched:      schedule.NewFIFOScheduler(),
+		stopc:          make(chan struct{}),
+	}
+	s.ReadView, s.WriteView = &readView{s}, &writeView{s}
+	return s
+}
+
+type rangeResp struct {
+	keys [][]byte
+	vals [][]byte
+}
+
+type fakeBatchTx struct {
+	testutil.Recorder
+	rangeRespc chan rangeResp
+}
+
+func (b *fakeBatchTx) Lock()                          {}
+func (b *fakeBatchTx) Unlock()                        {}
+func (b *fakeBatchTx) UnsafeCreateBucket(name []byte) {}
+func (b *fakeBatchTx) UnsafePut(bucketName []byte, key []byte, value []byte) {
+	b.Recorder.Record(testutil.Action{Name: "put", Params: []interface{}{bucketName, key, value}})
+}
+func (b *fakeBatchTx) UnsafeSeqPut(bucketName []byte, key []byte, value []byte) {
+	b.Recorder.Record(testutil.Action{Name: "seqput", Params: []interface{}{bucketName, key, value}})
+}
+func (b *fakeBatchTx) UnsafeRange(bucketName []byte, key, endKey []byte, limit int64) (keys [][]byte, vals [][]byte) {
+	b.Recorder.Record(testutil.Action{Name: "range", Params: []interface{}{bucketName, key, endKey, limit}})
+	r := <-b.rangeRespc
+	return r.keys, r.vals
+}
+func (b *fakeBatchTx) UnsafeDelete(bucketName []byte, key []byte) {
+	b.Recorder.Record(testutil.Action{Name: "delete", Params: []interface{}{bucketName, key}})
+}
+func (b *fakeBatchTx) UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error {
+	return nil
+}
+func (b *fakeBatchTx) Commit()        {}
+func (b *fakeBatchTx) CommitAndStop() {}
+
+type fakeBackend struct {
+	tx *fakeBatchTx
+}
+
+func (b *fakeBackend) BatchTx() backend.BatchTx                                    { return b.tx }
+func (b *fakeBackend) ReadTx() backend.ReadTx                                      { return b.tx }
+func (b *fakeBackend) Hash(ignores map[backend.IgnoreKey]struct{}) (uint32, error) { return 0, nil }
+func (b *fakeBackend) Size() int64                                                 { return 0 }
+func (b *fakeBackend) Snapshot() backend.Snapshot                                  { return nil }
+func (b *fakeBackend) ForceCommit()                                                {}
+func (b *fakeBackend) Defrag() error                                               { return nil }
+func (b *fakeBackend) Close() error                                                { return nil }
+
+type indexGetResp struct {
+	rev     revision
+	created revision
+	ver     int64
+	err     error
+}
+
+type indexRangeResp struct {
+	keys [][]byte
+	revs []revision
+}
+
+type indexRangeEventsResp struct {
+	revs []revision
+}
+
+type fakeIndex struct {
+	testutil.Recorder
+	indexGetRespc         chan indexGetResp
+	indexRangeRespc       chan indexRangeResp
+	indexRangeEventsRespc chan indexRangeEventsResp
+	indexCompactRespc     chan map[revision]struct{}
+}
+
+func (i *fakeIndex) Revisions(key, end []byte, atRev int64) []revision {
+	_, rev := i.Range(key, end, atRev)
+	return rev
+}
+
+func (i *fakeIndex) Get(key []byte, atRev int64) (rev, created revision, ver int64, err error) {
+	i.Recorder.Record(testutil.Action{Name: "get", Params: []interface{}{key, atRev}})
+	r := <-i.indexGetRespc
+	return r.rev, r.created, r.ver, r.err
+}
+func (i *fakeIndex) Range(key, end []byte, atRev int64) ([][]byte, []revision) {
+	i.Recorder.Record(testutil.Action{Name: "range", Params: []interface{}{key, end, atRev}})
+	r := <-i.indexRangeRespc
+	return r.keys, r.revs
+}
+func (i *fakeIndex) Put(key []byte, rev revision) {
+	i.Recorder.Record(testutil.Action{Name: "put", Params: []interface{}{key, rev}})
+}
+func (i *fakeIndex) Tombstone(key []byte, rev revision) error {
+	i.Recorder.Record(testutil.Action{Name: "tombstone", Params: []interface{}{key, rev}})
+	return nil
+}
+func (i *fakeIndex) RangeSince(key, end []byte, rev int64) []revision {
+	i.Recorder.Record(testutil.Action{Name: "rangeEvents", Params: []interface{}{key, end, rev}})
+	r := <-i.indexRangeEventsRespc
+	return r.revs
+}
+func (i *fakeIndex) Compact(rev int64) map[revision]struct{} {
+	i.Recorder.Record(testutil.Action{Name: "compact", Params: []interface{}{rev}})
+	return <-i.indexCompactRespc
+}
+func (i *fakeIndex) Keep(rev int64) map[revision]struct{} {
+	i.Recorder.Record(testutil.Action{Name: "keep", Params: []interface{}{rev}})
+	return <-i.indexCompactRespc
+}
+func (i *fakeIndex) Equal(b index) bool { return false }
+
+func (i *fakeIndex) Insert(ki *keyIndex) {
+	i.Recorder.Record(testutil.Action{Name: "insert", Params: []interface{}{ki}})
+}
+
+func (i *fakeIndex) KeyIndex(ki *keyIndex) *keyIndex {
+	i.Recorder.Record(testutil.Action{Name: "keyIndex", Params: []interface{}{ki}})
+	return nil
+}
+
+func createBytesSlice(bytesN, sliceN int) [][]byte {
+	rs := [][]byte{}
+	for len(rs) != sliceN {
+		v := make([]byte, bytesN)
+		if _, err := rand.Read(v); err != nil {
+			panic(err)
+		}
+		rs = append(rs, v)
+	}
+	return rs
+}
diff --git a/internal/mvcc/kvstore_txn.go b/internal/mvcc/kvstore_txn.go
new file mode 100644
index 0000000..6d839a1
--- /dev/null
+++ b/internal/mvcc/kvstore_txn.go
@@ -0,0 +1,253 @@
+// Copyright 2017 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+)
+
+type storeTxnRead struct {
+	s  *store
+	tx backend.ReadTx
+
+	firstRev int64
+	rev      int64
+}
+
+func (s *store) Read() TxnRead {
+	s.mu.RLock()
+	tx := s.b.ReadTx()
+	s.revMu.RLock()
+	tx.Lock()
+	firstRev, rev := s.compactMainRev, s.currentRev
+	s.revMu.RUnlock()
+	return newMetricsTxnRead(&storeTxnRead{s, tx, firstRev, rev})
+}
+
+func (tr *storeTxnRead) FirstRev() int64 { return tr.firstRev }
+func (tr *storeTxnRead) Rev() int64      { return tr.rev }
+
+func (tr *storeTxnRead) Range(key, end []byte, ro RangeOptions) (r *RangeResult, err error) {
+	return tr.rangeKeys(key, end, tr.Rev(), ro)
+}
+
+func (tr *storeTxnRead) End() {
+	tr.tx.Unlock()
+	tr.s.mu.RUnlock()
+}
+
+type storeTxnWrite struct {
+	storeTxnRead
+	tx backend.BatchTx
+	// beginRev is the revision where the txn begins; it will write to the next revision.
+	beginRev int64
+	changes  []mvccpb.KeyValue
+}
+
+func (s *store) Write() TxnWrite {
+	s.mu.RLock()
+	tx := s.b.BatchTx()
+	tx.Lock()
+	tw := &storeTxnWrite{
+		storeTxnRead: storeTxnRead{s, tx, 0, 0},
+		tx:           tx,
+		beginRev:     s.currentRev,
+		changes:      make([]mvccpb.KeyValue, 0, 4),
+	}
+	return newMetricsTxnWrite(tw)
+}
+
+func (tw *storeTxnWrite) Rev() int64 { return tw.beginRev }
+
+func (tw *storeTxnWrite) Range(key, end []byte, ro RangeOptions) (r *RangeResult, err error) {
+	rev := tw.beginRev
+	if len(tw.changes) > 0 {
+		rev++
+	}
+	return tw.rangeKeys(key, end, rev, ro)
+}
+
+func (tw *storeTxnWrite) DeleteRange(key, end []byte) (int64, int64) {
+	if n := tw.deleteRange(key, end); n != 0 || len(tw.changes) > 0 {
+		return n, int64(tw.beginRev + 1)
+	}
+	return 0, int64(tw.beginRev)
+}
+
+func (tw *storeTxnWrite) Put(key, value []byte, lease lease.LeaseID) int64 {
+	tw.put(key, value, lease)
+	return int64(tw.beginRev + 1)
+}
+
+func (tw *storeTxnWrite) End() {
+	// only update index if the txn modifies the mvcc state.
+	if len(tw.changes) != 0 {
+		tw.s.saveIndex(tw.tx)
+		// hold revMu lock to prevent new read txns from opening until writeback.
+		tw.s.revMu.Lock()
+		tw.s.currentRev++
+	}
+	tw.tx.Unlock()
+	if len(tw.changes) != 0 {
+		tw.s.revMu.Unlock()
+	}
+	tw.s.mu.RUnlock()
+}
+
+func (tr *storeTxnRead) rangeKeys(key, end []byte, curRev int64, ro RangeOptions) (*RangeResult, error) {
+	rev := ro.Rev
+	if rev > curRev {
+		return &RangeResult{KVs: nil, Count: -1, Rev: curRev}, ErrFutureRev
+	}
+	if rev <= 0 {
+		rev = curRev
+	}
+	if rev < tr.s.compactMainRev {
+		return &RangeResult{KVs: nil, Count: -1, Rev: 0}, ErrCompacted
+	}
+
+	revpairs := tr.s.kvindex.Revisions(key, end, int64(rev))
+	if len(revpairs) == 0 {
+		return &RangeResult{KVs: nil, Count: 0, Rev: curRev}, nil
+	}
+	if ro.Count {
+		return &RangeResult{KVs: nil, Count: len(revpairs), Rev: curRev}, nil
+	}
+
+	limit := int(ro.Limit)
+	if limit <= 0 || limit > len(revpairs) {
+		limit = len(revpairs)
+	}
+
+	kvs := make([]mvccpb.KeyValue, limit)
+	revBytes := newRevBytes()
+	for i, revpair := range revpairs[:len(kvs)] {
+		revToBytes(revpair, revBytes)
+		_, vs := tr.tx.UnsafeRange(keyBucketName, revBytes, nil, 0)
+		if len(vs) != 1 {
+			plog.Fatalf("range cannot find rev (%d,%d)", revpair.main, revpair.sub)
+		}
+		if err := kvs[i].Unmarshal(vs[0]); err != nil {
+			plog.Fatalf("cannot unmarshal event: %v", err)
+		}
+	}
+	return &RangeResult{KVs: kvs, Count: len(revpairs), Rev: curRev}, nil
+}
+
+func (tw *storeTxnWrite) put(key, value []byte, leaseID lease.LeaseID) {
+	rev := tw.beginRev + 1
+	c := rev
+	oldLease := lease.NoLease
+
+	// if the key exists before, use its previous created and
+	// get its previous leaseID
+	_, created, ver, err := tw.s.kvindex.Get(key, rev)
+	if err == nil {
+		c = created.main
+		oldLease = tw.s.le.GetLease(lease.LeaseItem{Key: string(key)})
+	}
+
+	ibytes := newRevBytes()
+	idxRev := revision{main: rev, sub: int64(len(tw.changes))}
+	revToBytes(idxRev, ibytes)
+
+	ver = ver + 1
+	kv := mvccpb.KeyValue{
+		Key:            key,
+		Value:          value,
+		CreateRevision: c,
+		ModRevision:    rev,
+		Version:        ver,
+		Lease:          int64(leaseID),
+	}
+
+	d, err := kv.Marshal()
+	if err != nil {
+		plog.Fatalf("cannot marshal event: %v", err)
+	}
+
+	tw.tx.UnsafeSeqPut(keyBucketName, ibytes, d)
+	tw.s.kvindex.Put(key, idxRev)
+	tw.changes = append(tw.changes, kv)
+
+	if oldLease != lease.NoLease {
+		if tw.s.le == nil {
+			panic("no lessor to detach lease")
+		}
+		err = tw.s.le.Detach(oldLease, []lease.LeaseItem{{Key: string(key)}})
+		if err != nil {
+			plog.Errorf("unexpected error from lease detach: %v", err)
+		}
+	}
+	if leaseID != lease.NoLease {
+		if tw.s.le == nil {
+			panic("no lessor to attach lease")
+		}
+		err = tw.s.le.Attach(leaseID, []lease.LeaseItem{{Key: string(key)}})
+		if err != nil {
+			panic("unexpected error from lease Attach")
+		}
+	}
+}
+
+func (tw *storeTxnWrite) deleteRange(key, end []byte) int64 {
+	rrev := tw.beginRev
+	if len(tw.changes) > 0 {
+		rrev += 1
+	}
+	keys, revs := tw.s.kvindex.Range(key, end, rrev)
+	if len(keys) == 0 {
+		return 0
+	}
+	for i, key := range keys {
+		tw.delete(key, revs[i])
+	}
+	return int64(len(keys))
+}
+
+func (tw *storeTxnWrite) delete(key []byte, rev revision) {
+	ibytes := newRevBytes()
+	idxRev := revision{main: tw.beginRev + 1, sub: int64(len(tw.changes))}
+	revToBytes(idxRev, ibytes)
+	ibytes = appendMarkTombstone(ibytes)
+
+	kv := mvccpb.KeyValue{Key: key}
+
+	d, err := kv.Marshal()
+	if err != nil {
+		plog.Fatalf("cannot marshal event: %v", err)
+	}
+
+	tw.tx.UnsafeSeqPut(keyBucketName, ibytes, d)
+	err = tw.s.kvindex.Tombstone(key, idxRev)
+	if err != nil {
+		plog.Fatalf("cannot tombstone an existing key (%s): %v", string(key), err)
+	}
+	tw.changes = append(tw.changes, kv)
+
+	item := lease.LeaseItem{Key: string(key)}
+	leaseID := tw.s.le.GetLease(item)
+
+	if leaseID != lease.NoLease {
+		err = tw.s.le.Detach(leaseID, []lease.LeaseItem{item})
+		if err != nil {
+			plog.Errorf("cannot detach %v", err)
+		}
+	}
+}
+
+func (tw *storeTxnWrite) Changes() []mvccpb.KeyValue { return tw.changes }
diff --git a/internal/mvcc/metrics.go b/internal/mvcc/metrics.go
new file mode 100644
index 0000000..e44eb12
--- /dev/null
+++ b/internal/mvcc/metrics.go
@@ -0,0 +1,183 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"sync"
+
+	"github.com/prometheus/client_golang/prometheus"
+)
+
+var (
+	rangeCounter = prometheus.NewCounter(
+		prometheus.CounterOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "range_total",
+			Help:      "Total number of ranges seen by this member.",
+		})
+
+	putCounter = prometheus.NewCounter(
+		prometheus.CounterOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "put_total",
+			Help:      "Total number of puts seen by this member.",
+		})
+
+	deleteCounter = prometheus.NewCounter(
+		prometheus.CounterOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "delete_total",
+			Help:      "Total number of deletes seen by this member.",
+		})
+
+	txnCounter = prometheus.NewCounter(
+		prometheus.CounterOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "txn_total",
+			Help:      "Total number of txns seen by this member.",
+		})
+
+	keysGauge = prometheus.NewGauge(
+		prometheus.GaugeOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "keys_total",
+			Help:      "Total number of keys.",
+		})
+
+	watchStreamGauge = prometheus.NewGauge(
+		prometheus.GaugeOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "watch_stream_total",
+			Help:      "Total number of watch streams.",
+		})
+
+	watcherGauge = prometheus.NewGauge(
+		prometheus.GaugeOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "watcher_total",
+			Help:      "Total number of watchers.",
+		})
+
+	slowWatcherGauge = prometheus.NewGauge(
+		prometheus.GaugeOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "slow_watcher_total",
+			Help:      "Total number of unsynced slow watchers.",
+		})
+
+	totalEventsCounter = prometheus.NewCounter(
+		prometheus.CounterOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "events_total",
+			Help:      "Total number of events sent by this member.",
+		})
+
+	pendingEventsGauge = prometheus.NewGauge(
+		prometheus.GaugeOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "pending_events_total",
+			Help:      "Total number of pending events to be sent.",
+		})
+
+	indexCompactionPauseDurations = prometheus.NewHistogram(
+		prometheus.HistogramOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "index_compaction_pause_duration_milliseconds",
+			Help:      "Bucketed histogram of index compaction pause duration.",
+			// 0.5ms -> 1second
+			Buckets: prometheus.ExponentialBuckets(0.5, 2, 12),
+		})
+
+	dbCompactionPauseDurations = prometheus.NewHistogram(
+		prometheus.HistogramOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "db_compaction_pause_duration_milliseconds",
+			Help:      "Bucketed histogram of db compaction pause duration.",
+			// 1ms -> 4second
+			Buckets: prometheus.ExponentialBuckets(1, 2, 13),
+		})
+
+	dbCompactionTotalDurations = prometheus.NewHistogram(
+		prometheus.HistogramOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "db_compaction_total_duration_milliseconds",
+			Help:      "Bucketed histogram of db compaction total duration.",
+			// 100ms -> 800second
+			Buckets: prometheus.ExponentialBuckets(100, 2, 14),
+		})
+
+	dbCompactionKeysCounter = prometheus.NewCounter(
+		prometheus.CounterOpts{
+			Namespace: "etcd_debugging",
+			Subsystem: "mvcc",
+			Name:      "db_compaction_keys_total",
+			Help:      "Total number of db keys compacted.",
+		})
+
+	dbTotalSize = prometheus.NewGaugeFunc(prometheus.GaugeOpts{
+		Namespace: "etcd_debugging",
+		Subsystem: "mvcc",
+		Name:      "db_total_size_in_bytes",
+		Help:      "Total size of the underlying database in bytes.",
+	},
+		func() float64 {
+			reportDbTotalSizeInBytesMu.RLock()
+			defer reportDbTotalSizeInBytesMu.RUnlock()
+			return reportDbTotalSizeInBytes()
+		},
+	)
+	// overridden by mvcc initialization
+	reportDbTotalSizeInBytesMu sync.RWMutex
+	reportDbTotalSizeInBytes   func() float64 = func() float64 { return 0 }
+)
+
+func init() {
+	prometheus.MustRegister(rangeCounter)
+	prometheus.MustRegister(putCounter)
+	prometheus.MustRegister(deleteCounter)
+	prometheus.MustRegister(txnCounter)
+	prometheus.MustRegister(keysGauge)
+	prometheus.MustRegister(watchStreamGauge)
+	prometheus.MustRegister(watcherGauge)
+	prometheus.MustRegister(slowWatcherGauge)
+	prometheus.MustRegister(totalEventsCounter)
+	prometheus.MustRegister(pendingEventsGauge)
+	prometheus.MustRegister(indexCompactionPauseDurations)
+	prometheus.MustRegister(dbCompactionPauseDurations)
+	prometheus.MustRegister(dbCompactionTotalDurations)
+	prometheus.MustRegister(dbCompactionKeysCounter)
+	prometheus.MustRegister(dbTotalSize)
+}
+
+// ReportEventReceived reports that an event is received.
+// This function should be called when the external systems received an
+// event from mvcc.Watcher.
+func ReportEventReceived(n int) {
+	pendingEventsGauge.Sub(float64(n))
+	totalEventsCounter.Add(float64(n))
+}
diff --git a/internal/mvcc/metrics_txn.go b/internal/mvcc/metrics_txn.go
new file mode 100644
index 0000000..8f81f45
--- /dev/null
+++ b/internal/mvcc/metrics_txn.go
@@ -0,0 +1,59 @@
+// Copyright 2017 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"github.com/coreos/etcd/internal/lease"
+)
+
+type metricsTxnWrite struct {
+	TxnWrite
+	ranges  uint
+	puts    uint
+	deletes uint
+}
+
+func newMetricsTxnRead(tr TxnRead) TxnRead {
+	return &metricsTxnWrite{&txnReadWrite{tr}, 0, 0, 0}
+}
+
+func newMetricsTxnWrite(tw TxnWrite) TxnWrite {
+	return &metricsTxnWrite{tw, 0, 0, 0}
+}
+
+func (tw *metricsTxnWrite) Range(key, end []byte, ro RangeOptions) (*RangeResult, error) {
+	tw.ranges++
+	return tw.TxnWrite.Range(key, end, ro)
+}
+
+func (tw *metricsTxnWrite) DeleteRange(key, end []byte) (n, rev int64) {
+	tw.deletes++
+	return tw.TxnWrite.DeleteRange(key, end)
+}
+
+func (tw *metricsTxnWrite) Put(key, value []byte, lease lease.LeaseID) (rev int64) {
+	tw.puts++
+	return tw.TxnWrite.Put(key, value, lease)
+}
+
+func (tw *metricsTxnWrite) End() {
+	defer tw.TxnWrite.End()
+	if sum := tw.ranges + tw.puts + tw.deletes; sum > 1 {
+		txnCounter.Inc()
+	}
+	rangeCounter.Add(float64(tw.ranges))
+	putCounter.Add(float64(tw.puts))
+	deleteCounter.Add(float64(tw.deletes))
+}
diff --git a/internal/mvcc/mvccpb/kv.pb.go b/internal/mvcc/mvccpb/kv.pb.go
new file mode 100644
index 0000000..23fe337
--- /dev/null
+++ b/internal/mvcc/mvccpb/kv.pb.go
@@ -0,0 +1,718 @@
+// Code generated by protoc-gen-gogo. DO NOT EDIT.
+// source: kv.proto
+
+/*
+	Package mvccpb is a generated protocol buffer package.
+
+	It is generated from these files:
+		kv.proto
+
+	It has these top-level messages:
+		KeyValue
+		Event
+*/
+package mvccpb
+
+import (
+	"fmt"
+
+	proto "github.com/golang/protobuf/proto"
+
+	math "math"
+
+	_ "github.com/gogo/protobuf/gogoproto"
+
+	io "io"
+)
+
+// Reference imports to suppress errors if they are not otherwise used.
+var _ = proto.Marshal
+var _ = fmt.Errorf
+var _ = math.Inf
+
+// This is a compile-time assertion to ensure that this generated file
+// is compatible with the proto package it is being compiled against.
+// A compilation error at this line likely means your copy of the
+// proto package needs to be updated.
+const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package
+
+type Event_EventType int32
+
+const (
+	PUT    Event_EventType = 0
+	DELETE Event_EventType = 1
+)
+
+var Event_EventType_name = map[int32]string{
+	0: "PUT",
+	1: "DELETE",
+}
+var Event_EventType_value = map[string]int32{
+	"PUT":    0,
+	"DELETE": 1,
+}
+
+func (x Event_EventType) String() string {
+	return proto.EnumName(Event_EventType_name, int32(x))
+}
+func (Event_EventType) EnumDescriptor() ([]byte, []int) { return fileDescriptorKv, []int{1, 0} }
+
+type KeyValue struct {
+	// key is the key in bytes. An empty key is not allowed.
+	Key []byte `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
+	// create_revision is the revision of last creation on this key.
+	CreateRevision int64 `protobuf:"varint,2,opt,name=create_revision,json=createRevision,proto3" json:"create_revision,omitempty"`
+	// mod_revision is the revision of last modification on this key.
+	ModRevision int64 `protobuf:"varint,3,opt,name=mod_revision,json=modRevision,proto3" json:"mod_revision,omitempty"`
+	// version is the version of the key. A deletion resets
+	// the version to zero and any modification of the key
+	// increases its version.
+	Version int64 `protobuf:"varint,4,opt,name=version,proto3" json:"version,omitempty"`
+	// value is the value held by the key, in bytes.
+	Value []byte `protobuf:"bytes,5,opt,name=value,proto3" json:"value,omitempty"`
+	// lease is the ID of the lease that attached to key.
+	// When the attached lease expires, the key will be deleted.
+	// If lease is 0, then no lease is attached to the key.
+	Lease int64 `protobuf:"varint,6,opt,name=lease,proto3" json:"lease,omitempty"`
+}
+
+func (m *KeyValue) Reset()                    { *m = KeyValue{} }
+func (m *KeyValue) String() string            { return proto.CompactTextString(m) }
+func (*KeyValue) ProtoMessage()               {}
+func (*KeyValue) Descriptor() ([]byte, []int) { return fileDescriptorKv, []int{0} }
+
+type Event struct {
+	// type is the kind of event. If type is a PUT, it indicates
+	// new data has been stored to the key. If type is a DELETE,
+	// it indicates the key was deleted.
+	Type Event_EventType `protobuf:"varint,1,opt,name=type,proto3,enum=mvccpb.Event_EventType" json:"type,omitempty"`
+	// kv holds the KeyValue for the event.
+	// A PUT event contains current kv pair.
+	// A PUT event with kv.Version=1 indicates the creation of a key.
+	// A DELETE/EXPIRE event contains the deleted key with
+	// its modification revision set to the revision of deletion.
+	Kv *KeyValue `protobuf:"bytes,2,opt,name=kv" json:"kv,omitempty"`
+	// prev_kv holds the key-value pair before the event happens.
+	PrevKv *KeyValue `protobuf:"bytes,3,opt,name=prev_kv,json=prevKv" json:"prev_kv,omitempty"`
+}
+
+func (m *Event) Reset()                    { *m = Event{} }
+func (m *Event) String() string            { return proto.CompactTextString(m) }
+func (*Event) ProtoMessage()               {}
+func (*Event) Descriptor() ([]byte, []int) { return fileDescriptorKv, []int{1} }
+
+func init() {
+	proto.RegisterType((*KeyValue)(nil), "mvccpb.KeyValue")
+	proto.RegisterType((*Event)(nil), "mvccpb.Event")
+	proto.RegisterEnum("mvccpb.Event_EventType", Event_EventType_name, Event_EventType_value)
+}
+func (m *KeyValue) Marshal() (dAtA []byte, err error) {
+	size := m.Size()
+	dAtA = make([]byte, size)
+	n, err := m.MarshalTo(dAtA)
+	if err != nil {
+		return nil, err
+	}
+	return dAtA[:n], nil
+}
+
+func (m *KeyValue) MarshalTo(dAtA []byte) (int, error) {
+	var i int
+	_ = i
+	var l int
+	_ = l
+	if len(m.Key) > 0 {
+		dAtA[i] = 0xa
+		i++
+		i = encodeVarintKv(dAtA, i, uint64(len(m.Key)))
+		i += copy(dAtA[i:], m.Key)
+	}
+	if m.CreateRevision != 0 {
+		dAtA[i] = 0x10
+		i++
+		i = encodeVarintKv(dAtA, i, uint64(m.CreateRevision))
+	}
+	if m.ModRevision != 0 {
+		dAtA[i] = 0x18
+		i++
+		i = encodeVarintKv(dAtA, i, uint64(m.ModRevision))
+	}
+	if m.Version != 0 {
+		dAtA[i] = 0x20
+		i++
+		i = encodeVarintKv(dAtA, i, uint64(m.Version))
+	}
+	if len(m.Value) > 0 {
+		dAtA[i] = 0x2a
+		i++
+		i = encodeVarintKv(dAtA, i, uint64(len(m.Value)))
+		i += copy(dAtA[i:], m.Value)
+	}
+	if m.Lease != 0 {
+		dAtA[i] = 0x30
+		i++
+		i = encodeVarintKv(dAtA, i, uint64(m.Lease))
+	}
+	return i, nil
+}
+
+func (m *Event) Marshal() (dAtA []byte, err error) {
+	size := m.Size()
+	dAtA = make([]byte, size)
+	n, err := m.MarshalTo(dAtA)
+	if err != nil {
+		return nil, err
+	}
+	return dAtA[:n], nil
+}
+
+func (m *Event) MarshalTo(dAtA []byte) (int, error) {
+	var i int
+	_ = i
+	var l int
+	_ = l
+	if m.Type != 0 {
+		dAtA[i] = 0x8
+		i++
+		i = encodeVarintKv(dAtA, i, uint64(m.Type))
+	}
+	if m.Kv != nil {
+		dAtA[i] = 0x12
+		i++
+		i = encodeVarintKv(dAtA, i, uint64(m.Kv.Size()))
+		n1, err := m.Kv.MarshalTo(dAtA[i:])
+		if err != nil {
+			return 0, err
+		}
+		i += n1
+	}
+	if m.PrevKv != nil {
+		dAtA[i] = 0x1a
+		i++
+		i = encodeVarintKv(dAtA, i, uint64(m.PrevKv.Size()))
+		n2, err := m.PrevKv.MarshalTo(dAtA[i:])
+		if err != nil {
+			return 0, err
+		}
+		i += n2
+	}
+	return i, nil
+}
+
+func encodeVarintKv(dAtA []byte, offset int, v uint64) int {
+	for v >= 1<<7 {
+		dAtA[offset] = uint8(v&0x7f | 0x80)
+		v >>= 7
+		offset++
+	}
+	dAtA[offset] = uint8(v)
+	return offset + 1
+}
+func (m *KeyValue) Size() (n int) {
+	var l int
+	_ = l
+	l = len(m.Key)
+	if l > 0 {
+		n += 1 + l + sovKv(uint64(l))
+	}
+	if m.CreateRevision != 0 {
+		n += 1 + sovKv(uint64(m.CreateRevision))
+	}
+	if m.ModRevision != 0 {
+		n += 1 + sovKv(uint64(m.ModRevision))
+	}
+	if m.Version != 0 {
+		n += 1 + sovKv(uint64(m.Version))
+	}
+	l = len(m.Value)
+	if l > 0 {
+		n += 1 + l + sovKv(uint64(l))
+	}
+	if m.Lease != 0 {
+		n += 1 + sovKv(uint64(m.Lease))
+	}
+	return n
+}
+
+func (m *Event) Size() (n int) {
+	var l int
+	_ = l
+	if m.Type != 0 {
+		n += 1 + sovKv(uint64(m.Type))
+	}
+	if m.Kv != nil {
+		l = m.Kv.Size()
+		n += 1 + l + sovKv(uint64(l))
+	}
+	if m.PrevKv != nil {
+		l = m.PrevKv.Size()
+		n += 1 + l + sovKv(uint64(l))
+	}
+	return n
+}
+
+func sovKv(x uint64) (n int) {
+	for {
+		n++
+		x >>= 7
+		if x == 0 {
+			break
+		}
+	}
+	return n
+}
+func sozKv(x uint64) (n int) {
+	return sovKv(uint64((x << 1) ^ uint64((int64(x) >> 63))))
+}
+func (m *KeyValue) Unmarshal(dAtA []byte) error {
+	l := len(dAtA)
+	iNdEx := 0
+	for iNdEx < l {
+		preIndex := iNdEx
+		var wire uint64
+		for shift := uint(0); ; shift += 7 {
+			if shift >= 64 {
+				return ErrIntOverflowKv
+			}
+			if iNdEx >= l {
+				return io.ErrUnexpectedEOF
+			}
+			b := dAtA[iNdEx]
+			iNdEx++
+			wire |= (uint64(b) & 0x7F) << shift
+			if b < 0x80 {
+				break
+			}
+		}
+		fieldNum := int32(wire >> 3)
+		wireType := int(wire & 0x7)
+		if wireType == 4 {
+			return fmt.Errorf("proto: KeyValue: wiretype end group for non-group")
+		}
+		if fieldNum <= 0 {
+			return fmt.Errorf("proto: KeyValue: illegal tag %d (wire type %d)", fieldNum, wire)
+		}
+		switch fieldNum {
+		case 1:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
+			}
+			var byteLen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				byteLen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if byteLen < 0 {
+				return ErrInvalidLengthKv
+			}
+			postIndex := iNdEx + byteLen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			m.Key = append(m.Key[:0], dAtA[iNdEx:postIndex]...)
+			if m.Key == nil {
+				m.Key = []byte{}
+			}
+			iNdEx = postIndex
+		case 2:
+			if wireType != 0 {
+				return fmt.Errorf("proto: wrong wireType = %d for field CreateRevision", wireType)
+			}
+			m.CreateRevision = 0
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				m.CreateRevision |= (int64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+		case 3:
+			if wireType != 0 {
+				return fmt.Errorf("proto: wrong wireType = %d for field ModRevision", wireType)
+			}
+			m.ModRevision = 0
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				m.ModRevision |= (int64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+		case 4:
+			if wireType != 0 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Version", wireType)
+			}
+			m.Version = 0
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				m.Version |= (int64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+		case 5:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Value", wireType)
+			}
+			var byteLen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				byteLen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if byteLen < 0 {
+				return ErrInvalidLengthKv
+			}
+			postIndex := iNdEx + byteLen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			m.Value = append(m.Value[:0], dAtA[iNdEx:postIndex]...)
+			if m.Value == nil {
+				m.Value = []byte{}
+			}
+			iNdEx = postIndex
+		case 6:
+			if wireType != 0 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Lease", wireType)
+			}
+			m.Lease = 0
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				m.Lease |= (int64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+		default:
+			iNdEx = preIndex
+			skippy, err := skipKv(dAtA[iNdEx:])
+			if err != nil {
+				return err
+			}
+			if skippy < 0 {
+				return ErrInvalidLengthKv
+			}
+			if (iNdEx + skippy) > l {
+				return io.ErrUnexpectedEOF
+			}
+			iNdEx += skippy
+		}
+	}
+
+	if iNdEx > l {
+		return io.ErrUnexpectedEOF
+	}
+	return nil
+}
+func (m *Event) Unmarshal(dAtA []byte) error {
+	l := len(dAtA)
+	iNdEx := 0
+	for iNdEx < l {
+		preIndex := iNdEx
+		var wire uint64
+		for shift := uint(0); ; shift += 7 {
+			if shift >= 64 {
+				return ErrIntOverflowKv
+			}
+			if iNdEx >= l {
+				return io.ErrUnexpectedEOF
+			}
+			b := dAtA[iNdEx]
+			iNdEx++
+			wire |= (uint64(b) & 0x7F) << shift
+			if b < 0x80 {
+				break
+			}
+		}
+		fieldNum := int32(wire >> 3)
+		wireType := int(wire & 0x7)
+		if wireType == 4 {
+			return fmt.Errorf("proto: Event: wiretype end group for non-group")
+		}
+		if fieldNum <= 0 {
+			return fmt.Errorf("proto: Event: illegal tag %d (wire type %d)", fieldNum, wire)
+		}
+		switch fieldNum {
+		case 1:
+			if wireType != 0 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
+			}
+			m.Type = 0
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				m.Type |= (Event_EventType(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+		case 2:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Kv", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthKv
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			if m.Kv == nil {
+				m.Kv = &KeyValue{}
+			}
+			if err := m.Kv.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
+			iNdEx = postIndex
+		case 3:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field PrevKv", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthKv
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			if m.PrevKv == nil {
+				m.PrevKv = &KeyValue{}
+			}
+			if err := m.PrevKv.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
+			iNdEx = postIndex
+		default:
+			iNdEx = preIndex
+			skippy, err := skipKv(dAtA[iNdEx:])
+			if err != nil {
+				return err
+			}
+			if skippy < 0 {
+				return ErrInvalidLengthKv
+			}
+			if (iNdEx + skippy) > l {
+				return io.ErrUnexpectedEOF
+			}
+			iNdEx += skippy
+		}
+	}
+
+	if iNdEx > l {
+		return io.ErrUnexpectedEOF
+	}
+	return nil
+}
+func skipKv(dAtA []byte) (n int, err error) {
+	l := len(dAtA)
+	iNdEx := 0
+	for iNdEx < l {
+		var wire uint64
+		for shift := uint(0); ; shift += 7 {
+			if shift >= 64 {
+				return 0, ErrIntOverflowKv
+			}
+			if iNdEx >= l {
+				return 0, io.ErrUnexpectedEOF
+			}
+			b := dAtA[iNdEx]
+			iNdEx++
+			wire |= (uint64(b) & 0x7F) << shift
+			if b < 0x80 {
+				break
+			}
+		}
+		wireType := int(wire & 0x7)
+		switch wireType {
+		case 0:
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return 0, ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return 0, io.ErrUnexpectedEOF
+				}
+				iNdEx++
+				if dAtA[iNdEx-1] < 0x80 {
+					break
+				}
+			}
+			return iNdEx, nil
+		case 1:
+			iNdEx += 8
+			return iNdEx, nil
+		case 2:
+			var length int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return 0, ErrIntOverflowKv
+				}
+				if iNdEx >= l {
+					return 0, io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				length |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			iNdEx += length
+			if length < 0 {
+				return 0, ErrInvalidLengthKv
+			}
+			return iNdEx, nil
+		case 3:
+			for {
+				var innerWire uint64
+				var start int = iNdEx
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return 0, ErrIntOverflowKv
+					}
+					if iNdEx >= l {
+						return 0, io.ErrUnexpectedEOF
+					}
+					b := dAtA[iNdEx]
+					iNdEx++
+					innerWire |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
+					}
+				}
+				innerWireType := int(innerWire & 0x7)
+				if innerWireType == 4 {
+					break
+				}
+				next, err := skipKv(dAtA[start:])
+				if err != nil {
+					return 0, err
+				}
+				iNdEx = start + next
+			}
+			return iNdEx, nil
+		case 4:
+			return iNdEx, nil
+		case 5:
+			iNdEx += 4
+			return iNdEx, nil
+		default:
+			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
+		}
+	}
+	panic("unreachable")
+}
+
+var (
+	ErrInvalidLengthKv = fmt.Errorf("proto: negative length found during unmarshaling")
+	ErrIntOverflowKv   = fmt.Errorf("proto: integer overflow")
+)
+
+func init() { proto.RegisterFile("kv.proto", fileDescriptorKv) }
+
+var fileDescriptorKv = []byte{
+	// 303 bytes of a gzipped FileDescriptorProto
+	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x6c, 0x90, 0x41, 0x4e, 0xc2, 0x40,
+	0x14, 0x86, 0x3b, 0x14, 0x0a, 0x3e, 0x08, 0x36, 0x13, 0x12, 0x27, 0x2e, 0x26, 0x95, 0x8d, 0x18,
+	0x13, 0x4c, 0xf0, 0x06, 0xc6, 0xae, 0x70, 0x61, 0x1a, 0x74, 0x4b, 0x4a, 0x79, 0x21, 0xa4, 0x94,
+	0x69, 0x4a, 0x9d, 0xa4, 0x37, 0x71, 0xef, 0xde, 0x73, 0xb0, 0xe4, 0x08, 0x52, 0x2f, 0x62, 0xfa,
+	0xc6, 0xe2, 0xc6, 0xcd, 0xe4, 0xfd, 0xff, 0xff, 0x65, 0xe6, 0x7f, 0x03, 0x9d, 0x58, 0x8f, 0xd3,
+	0x4c, 0xe5, 0x8a, 0x3b, 0x89, 0x8e, 0xa2, 0x74, 0x71, 0x39, 0x58, 0xa9, 0x95, 0x22, 0xeb, 0xae,
+	0x9a, 0x4c, 0x3a, 0xfc, 0x64, 0xd0, 0x99, 0x62, 0xf1, 0x1a, 0x6e, 0xde, 0x90, 0xbb, 0x60, 0xc7,
+	0x58, 0x08, 0xe6, 0xb1, 0x51, 0x2f, 0xa8, 0x46, 0x7e, 0x0d, 0xe7, 0x51, 0x86, 0x61, 0x8e, 0xf3,
+	0x0c, 0xf5, 0x7a, 0xb7, 0x56, 0x5b, 0xd1, 0xf0, 0xd8, 0xc8, 0x0e, 0xfa, 0xc6, 0x0e, 0x7e, 0x5d,
+	0x7e, 0x05, 0xbd, 0x44, 0x2d, 0xff, 0x28, 0x9b, 0xa8, 0x6e, 0xa2, 0x96, 0x27, 0x44, 0x40, 0x5b,
+	0x63, 0x46, 0x69, 0x93, 0xd2, 0x5a, 0xf2, 0x01, 0xb4, 0x74, 0x55, 0x40, 0xb4, 0xe8, 0x65, 0x23,
+	0x2a, 0x77, 0x83, 0xe1, 0x0e, 0x85, 0x43, 0xb4, 0x11, 0xc3, 0x0f, 0x06, 0x2d, 0x5f, 0xe3, 0x36,
+	0xe7, 0xb7, 0xd0, 0xcc, 0x8b, 0x14, 0xa9, 0x6e, 0x7f, 0x72, 0x31, 0x36, 0x7b, 0x8e, 0x29, 0x34,
+	0xe7, 0xac, 0x48, 0x31, 0x20, 0x88, 0x7b, 0xd0, 0x88, 0x35, 0x75, 0xef, 0x4e, 0xdc, 0x1a, 0xad,
+	0x17, 0x0f, 0x1a, 0xb1, 0xe6, 0x37, 0xd0, 0x4e, 0x33, 0xd4, 0xf3, 0x58, 0x53, 0xf9, 0xff, 0x30,
+	0xa7, 0x02, 0xa6, 0x7a, 0xe8, 0xc1, 0xd9, 0xe9, 0x7e, 0xde, 0x06, 0xfb, 0xf9, 0x65, 0xe6, 0x5a,
+	0x1c, 0xc0, 0x79, 0xf4, 0x9f, 0xfc, 0x99, 0xef, 0xb2, 0x07, 0xb1, 0x3f, 0x4a, 0xeb, 0x70, 0x94,
+	0xd6, 0xbe, 0x94, 0xec, 0x50, 0x4a, 0xf6, 0x55, 0x4a, 0xf6, 0xfe, 0x2d, 0xad, 0x85, 0x43, 0xff,
+	0x7e, 0xff, 0x13, 0x00, 0x00, 0xff, 0xff, 0xb5, 0x45, 0x92, 0x5d, 0xa1, 0x01, 0x00, 0x00,
+}
diff --git a/internal/mvcc/mvccpb/kv.proto b/internal/mvcc/mvccpb/kv.proto
new file mode 100644
index 0000000..23c911b
--- /dev/null
+++ b/internal/mvcc/mvccpb/kv.proto
@@ -0,0 +1,49 @@
+syntax = "proto3";
+package mvccpb;
+
+import "gogoproto/gogo.proto";
+
+option (gogoproto.marshaler_all) = true;
+option (gogoproto.sizer_all) = true;
+option (gogoproto.unmarshaler_all) = true;
+option (gogoproto.goproto_getters_all) = false;
+option (gogoproto.goproto_enum_prefix_all) = false;
+
+message KeyValue {
+  // key is the key in bytes. An empty key is not allowed.
+  bytes key = 1;
+  // create_revision is the revision of last creation on this key.
+  int64 create_revision = 2;
+  // mod_revision is the revision of last modification on this key.
+  int64 mod_revision = 3;
+  // version is the version of the key. A deletion resets
+  // the version to zero and any modification of the key
+  // increases its version.
+  int64 version = 4;
+  // value is the value held by the key, in bytes.
+  bytes value = 5;
+  // lease is the ID of the lease that attached to key.
+  // When the attached lease expires, the key will be deleted.
+  // If lease is 0, then no lease is attached to the key.
+  int64 lease = 6;
+}
+
+message Event {
+  enum EventType {
+    PUT = 0;
+    DELETE = 1;
+  }
+  // type is the kind of event. If type is a PUT, it indicates
+  // new data has been stored to the key. If type is a DELETE,
+  // it indicates the key was deleted.
+  EventType type = 1;
+  // kv holds the KeyValue for the event.
+  // A PUT event contains current kv pair.
+  // A PUT event with kv.Version=1 indicates the creation of a key.
+  // A DELETE/EXPIRE event contains the deleted key with
+  // its modification revision set to the revision of deletion.
+  KeyValue kv = 2;
+
+  // prev_kv holds the key-value pair before the event happens.
+  KeyValue prev_kv = 3;
+}
diff --git a/internal/mvcc/revision.go b/internal/mvcc/revision.go
new file mode 100644
index 0000000..5fa35a1
--- /dev/null
+++ b/internal/mvcc/revision.go
@@ -0,0 +1,67 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import "encoding/binary"
+
+// revBytesLen is the byte length of a normal revision.
+// First 8 bytes is the revision.main in big-endian format. The 9th byte
+// is a '_'. The last 8 bytes is the revision.sub in big-endian format.
+const revBytesLen = 8 + 1 + 8
+
+// A revision indicates modification of the key-value space.
+// The set of changes that share same main revision changes the key-value space atomically.
+type revision struct {
+	// main is the main revision of a set of changes that happen atomically.
+	main int64
+
+	// sub is the the sub revision of a change in a set of changes that happen
+	// atomically. Each change has different increasing sub revision in that
+	// set.
+	sub int64
+}
+
+func (a revision) GreaterThan(b revision) bool {
+	if a.main > b.main {
+		return true
+	}
+	if a.main < b.main {
+		return false
+	}
+	return a.sub > b.sub
+}
+
+func newRevBytes() []byte {
+	return make([]byte, revBytesLen, markedRevBytesLen)
+}
+
+func revToBytes(rev revision, bytes []byte) {
+	binary.BigEndian.PutUint64(bytes, uint64(rev.main))
+	bytes[8] = '_'
+	binary.BigEndian.PutUint64(bytes[9:], uint64(rev.sub))
+}
+
+func bytesToRev(bytes []byte) revision {
+	return revision{
+		main: int64(binary.BigEndian.Uint64(bytes[0:8])),
+		sub:  int64(binary.BigEndian.Uint64(bytes[9:])),
+	}
+}
+
+type revisions []revision
+
+func (a revisions) Len() int           { return len(a) }
+func (a revisions) Less(i, j int) bool { return a[j].GreaterThan(a[i]) }
+func (a revisions) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }
diff --git a/internal/mvcc/revision_test.go b/internal/mvcc/revision_test.go
new file mode 100644
index 0000000..46fcb48
--- /dev/null
+++ b/internal/mvcc/revision_test.go
@@ -0,0 +1,53 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"bytes"
+	"math"
+	"reflect"
+	"testing"
+)
+
+// TestRevision tests that revision could be encoded to and decoded from
+// bytes slice. Moreover, the lexicographical order of its byte slice representation
+// follows the order of (main, sub).
+func TestRevision(t *testing.T) {
+	tests := []revision{
+		// order in (main, sub)
+		{},
+		{main: 1, sub: 0},
+		{main: 1, sub: 1},
+		{main: 2, sub: 0},
+		{main: math.MaxInt64, sub: math.MaxInt64},
+	}
+
+	bs := make([][]byte, len(tests))
+	for i, tt := range tests {
+		b := newRevBytes()
+		revToBytes(tt, b)
+		bs[i] = b
+
+		if grev := bytesToRev(b); !reflect.DeepEqual(grev, tt) {
+			t.Errorf("#%d: revision = %+v, want %+v", i, grev, tt)
+		}
+	}
+
+	for i := 0; i < len(tests)-1; i++ {
+		if bytes.Compare(bs[i], bs[i+1]) >= 0 {
+			t.Errorf("#%d: %v (%+v) should be smaller than %v (%+v)", i, bs[i], tests[i], bs[i+1], tests[i+1])
+		}
+	}
+}
diff --git a/internal/mvcc/util.go b/internal/mvcc/util.go
new file mode 100644
index 0000000..1eb0500
--- /dev/null
+++ b/internal/mvcc/util.go
@@ -0,0 +1,56 @@
+// Copyright 2016 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"encoding/binary"
+
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+)
+
+func UpdateConsistentIndex(be backend.Backend, index uint64) {
+	tx := be.BatchTx()
+	tx.Lock()
+	defer tx.Unlock()
+
+	var oldi uint64
+	_, vs := tx.UnsafeRange(metaBucketName, consistentIndexKeyName, nil, 0)
+	if len(vs) != 0 {
+		oldi = binary.BigEndian.Uint64(vs[0])
+	}
+
+	if index <= oldi {
+		return
+	}
+
+	bs := make([]byte, 8)
+	binary.BigEndian.PutUint64(bs, index)
+	tx.UnsafePut(metaBucketName, consistentIndexKeyName, bs)
+}
+
+func WriteKV(be backend.Backend, kv mvccpb.KeyValue) {
+	ibytes := newRevBytes()
+	revToBytes(revision{main: kv.ModRevision}, ibytes)
+
+	d, err := kv.Marshal()
+	if err != nil {
+		plog.Fatalf("cannot marshal event: %v", err)
+	}
+
+	be.BatchTx().Lock()
+	be.BatchTx().UnsafePut(keyBucketName, ibytes, d)
+	be.BatchTx().Unlock()
+}
diff --git a/internal/mvcc/watchable_store.go b/internal/mvcc/watchable_store.go
new file mode 100644
index 0000000..34d4d32
--- /dev/null
+++ b/internal/mvcc/watchable_store.go
@@ -0,0 +1,525 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"sync"
+	"time"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+)
+
+// non-const so modifiable by tests
+var (
+	// chanBufLen is the length of the buffered chan
+	// for sending out watched events.
+	// TODO: find a good buf value. 1024 is just a random one that
+	// seems to be reasonable.
+	chanBufLen = 1024
+
+	// maxWatchersPerSync is the number of watchers to sync in a single batch
+	maxWatchersPerSync = 512
+)
+
+type watchable interface {
+	watch(key, end []byte, startRev int64, id WatchID, ch chan<- WatchResponse, fcs ...FilterFunc) (*watcher, cancelFunc)
+	progress(w *watcher)
+	rev() int64
+}
+
+type watchableStore struct {
+	*store
+
+	// mu protects watcher groups and batches. It should never be locked
+	// before locking store.mu to avoid deadlock.
+	mu sync.RWMutex
+
+	// victims are watcher batches that were blocked on the watch channel
+	victims []watcherBatch
+	victimc chan struct{}
+
+	// contains all unsynced watchers that needs to sync with events that have happened
+	unsynced watcherGroup
+
+	// contains all synced watchers that are in sync with the progress of the store.
+	// The key of the map is the key that the watcher watches on.
+	synced watcherGroup
+
+	stopc chan struct{}
+	wg    sync.WaitGroup
+}
+
+// cancelFunc updates unsynced and synced maps when running
+// cancel operations.
+type cancelFunc func()
+
+func New(b backend.Backend, le lease.Lessor, ig ConsistentIndexGetter) ConsistentWatchableKV {
+	return newWatchableStore(b, le, ig)
+}
+
+func newWatchableStore(b backend.Backend, le lease.Lessor, ig ConsistentIndexGetter) *watchableStore {
+	s := &watchableStore{
+		store:    NewStore(b, le, ig),
+		victimc:  make(chan struct{}, 1),
+		unsynced: newWatcherGroup(),
+		synced:   newWatcherGroup(),
+		stopc:    make(chan struct{}),
+	}
+	s.store.ReadView = &readView{s}
+	s.store.WriteView = &writeView{s}
+	if s.le != nil {
+		// use this store as the deleter so revokes trigger watch events
+		s.le.SetRangeDeleter(func() lease.TxnDelete { return s.Write() })
+	}
+	s.wg.Add(2)
+	go s.syncWatchersLoop()
+	go s.syncVictimsLoop()
+	return s
+}
+
+func (s *watchableStore) Close() error {
+	close(s.stopc)
+	s.wg.Wait()
+	return s.store.Close()
+}
+
+func (s *watchableStore) NewWatchStream() WatchStream {
+	watchStreamGauge.Inc()
+	return &watchStream{
+		watchable: s,
+		ch:        make(chan WatchResponse, chanBufLen),
+		cancels:   make(map[WatchID]cancelFunc),
+		watchers:  make(map[WatchID]*watcher),
+	}
+}
+
+func (s *watchableStore) watch(key, end []byte, startRev int64, id WatchID, ch chan<- WatchResponse, fcs ...FilterFunc) (*watcher, cancelFunc) {
+	wa := &watcher{
+		key:    key,
+		end:    end,
+		minRev: startRev,
+		id:     id,
+		ch:     ch,
+		fcs:    fcs,
+	}
+
+	s.mu.Lock()
+	s.revMu.RLock()
+	synced := startRev > s.store.currentRev || startRev == 0
+	if synced {
+		wa.minRev = s.store.currentRev + 1
+		if startRev > wa.minRev {
+			wa.minRev = startRev
+		}
+	}
+	if synced {
+		s.synced.add(wa)
+	} else {
+		slowWatcherGauge.Inc()
+		s.unsynced.add(wa)
+	}
+	s.revMu.RUnlock()
+	s.mu.Unlock()
+
+	watcherGauge.Inc()
+
+	return wa, func() { s.cancelWatcher(wa) }
+}
+
+// cancelWatcher removes references of the watcher from the watchableStore
+func (s *watchableStore) cancelWatcher(wa *watcher) {
+	for {
+		s.mu.Lock()
+		if s.unsynced.delete(wa) {
+			slowWatcherGauge.Dec()
+			break
+		} else if s.synced.delete(wa) {
+			break
+		} else if wa.compacted {
+			break
+		} else if wa.ch == nil {
+			// already canceled (e.g., cancel/close race)
+			break
+		}
+
+		if !wa.victim {
+			panic("watcher not victim but not in watch groups")
+		}
+
+		var victimBatch watcherBatch
+		for _, wb := range s.victims {
+			if wb[wa] != nil {
+				victimBatch = wb
+				break
+			}
+		}
+		if victimBatch != nil {
+			slowWatcherGauge.Dec()
+			delete(victimBatch, wa)
+			break
+		}
+
+		// victim being processed so not accessible; retry
+		s.mu.Unlock()
+		time.Sleep(time.Millisecond)
+	}
+
+	watcherGauge.Dec()
+	wa.ch = nil
+	s.mu.Unlock()
+}
+
+func (s *watchableStore) Restore(b backend.Backend) error {
+	s.mu.Lock()
+	defer s.mu.Unlock()
+	err := s.store.Restore(b)
+	if err != nil {
+		return err
+	}
+
+	for wa := range s.synced.watchers {
+		s.unsynced.watchers.add(wa)
+	}
+	s.synced = newWatcherGroup()
+	return nil
+}
+
+// syncWatchersLoop syncs the watcher in the unsynced map every 100ms.
+func (s *watchableStore) syncWatchersLoop() {
+	defer s.wg.Done()
+
+	for {
+		s.mu.RLock()
+		st := time.Now()
+		lastUnsyncedWatchers := s.unsynced.size()
+		s.mu.RUnlock()
+
+		unsyncedWatchers := 0
+		if lastUnsyncedWatchers > 0 {
+			unsyncedWatchers = s.syncWatchers()
+		}
+		syncDuration := time.Since(st)
+
+		waitDuration := 100 * time.Millisecond
+		// more work pending?
+		if unsyncedWatchers != 0 && lastUnsyncedWatchers > unsyncedWatchers {
+			// be fair to other store operations by yielding time taken
+			waitDuration = syncDuration
+		}
+
+		select {
+		case <-time.After(waitDuration):
+		case <-s.stopc:
+			return
+		}
+	}
+}
+
+// syncVictimsLoop tries to write precomputed watcher responses to
+// watchers that had a blocked watcher channel
+func (s *watchableStore) syncVictimsLoop() {
+	defer s.wg.Done()
+
+	for {
+		for s.moveVictims() != 0 {
+			// try to update all victim watchers
+		}
+		s.mu.RLock()
+		isEmpty := len(s.victims) == 0
+		s.mu.RUnlock()
+
+		var tickc <-chan time.Time
+		if !isEmpty {
+			tickc = time.After(10 * time.Millisecond)
+		}
+
+		select {
+		case <-tickc:
+		case <-s.victimc:
+		case <-s.stopc:
+			return
+		}
+	}
+}
+
+// moveVictims tries to update watches with already pending event data
+func (s *watchableStore) moveVictims() (moved int) {
+	s.mu.Lock()
+	victims := s.victims
+	s.victims = nil
+	s.mu.Unlock()
+
+	var newVictim watcherBatch
+	for _, wb := range victims {
+		// try to send responses again
+		for w, eb := range wb {
+			// watcher has observed the store up to, but not including, w.minRev
+			rev := w.minRev - 1
+			if w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: rev}) {
+				pendingEventsGauge.Add(float64(len(eb.evs)))
+			} else {
+				if newVictim == nil {
+					newVictim = make(watcherBatch)
+				}
+				newVictim[w] = eb
+				continue
+			}
+			moved++
+		}
+
+		// assign completed victim watchers to unsync/sync
+		s.mu.Lock()
+		s.store.revMu.RLock()
+		curRev := s.store.currentRev
+		for w, eb := range wb {
+			if newVictim != nil && newVictim[w] != nil {
+				// couldn't send watch response; stays victim
+				continue
+			}
+			w.victim = false
+			if eb.moreRev != 0 {
+				w.minRev = eb.moreRev
+			}
+			if w.minRev <= curRev {
+				s.unsynced.add(w)
+			} else {
+				slowWatcherGauge.Dec()
+				s.synced.add(w)
+			}
+		}
+		s.store.revMu.RUnlock()
+		s.mu.Unlock()
+	}
+
+	if len(newVictim) > 0 {
+		s.mu.Lock()
+		s.victims = append(s.victims, newVictim)
+		s.mu.Unlock()
+	}
+
+	return moved
+}
+
+// syncWatchers syncs unsynced watchers by:
+//	1. choose a set of watchers from the unsynced watcher group
+//	2. iterate over the set to get the minimum revision and remove compacted watchers
+//	3. use minimum revision to get all key-value pairs and send those events to watchers
+//	4. remove synced watchers in set from unsynced group and move to synced group
+func (s *watchableStore) syncWatchers() int {
+	s.mu.Lock()
+	defer s.mu.Unlock()
+
+	if s.unsynced.size() == 0 {
+		return 0
+	}
+
+	s.store.revMu.RLock()
+	defer s.store.revMu.RUnlock()
+
+	// in order to find key-value pairs from unsynced watchers, we need to
+	// find min revision index, and these revisions can be used to
+	// query the backend store of key-value pairs
+	curRev := s.store.currentRev
+	compactionRev := s.store.compactMainRev
+
+	wg, minRev := s.unsynced.choose(maxWatchersPerSync, curRev, compactionRev)
+	minBytes, maxBytes := newRevBytes(), newRevBytes()
+	revToBytes(revision{main: minRev}, minBytes)
+	revToBytes(revision{main: curRev + 1}, maxBytes)
+
+	// UnsafeRange returns keys and values. And in boltdb, keys are revisions.
+	// values are actual key-value pairs in backend.
+	tx := s.store.b.ReadTx()
+	tx.Lock()
+	revs, vs := tx.UnsafeRange(keyBucketName, minBytes, maxBytes, 0)
+	evs := kvsToEvents(wg, revs, vs)
+	tx.Unlock()
+
+	var victims watcherBatch
+	wb := newWatcherBatch(wg, evs)
+	for w := range wg.watchers {
+		w.minRev = curRev + 1
+
+		eb, ok := wb[w]
+		if !ok {
+			// bring un-notified watcher to synced
+			s.synced.add(w)
+			s.unsynced.delete(w)
+			continue
+		}
+
+		if eb.moreRev != 0 {
+			w.minRev = eb.moreRev
+		}
+
+		if w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: curRev}) {
+			pendingEventsGauge.Add(float64(len(eb.evs)))
+		} else {
+			if victims == nil {
+				victims = make(watcherBatch)
+			}
+			w.victim = true
+		}
+
+		if w.victim {
+			victims[w] = eb
+		} else {
+			if eb.moreRev != 0 {
+				// stay unsynced; more to read
+				continue
+			}
+			s.synced.add(w)
+		}
+		s.unsynced.delete(w)
+	}
+	s.addVictim(victims)
+
+	vsz := 0
+	for _, v := range s.victims {
+		vsz += len(v)
+	}
+	slowWatcherGauge.Set(float64(s.unsynced.size() + vsz))
+
+	return s.unsynced.size()
+}
+
+// kvsToEvents gets all events for the watchers from all key-value pairs
+func kvsToEvents(wg *watcherGroup, revs, vals [][]byte) (evs []mvccpb.Event) {
+	for i, v := range vals {
+		var kv mvccpb.KeyValue
+		if err := kv.Unmarshal(v); err != nil {
+			plog.Panicf("cannot unmarshal event: %v", err)
+		}
+
+		if !wg.contains(string(kv.Key)) {
+			continue
+		}
+
+		ty := mvccpb.PUT
+		if isTombstone(revs[i]) {
+			ty = mvccpb.DELETE
+			// patch in mod revision so watchers won't skip
+			kv.ModRevision = bytesToRev(revs[i]).main
+		}
+		evs = append(evs, mvccpb.Event{Kv: &kv, Type: ty})
+	}
+	return evs
+}
+
+// notify notifies the fact that given event at the given rev just happened to
+// watchers that watch on the key of the event.
+func (s *watchableStore) notify(rev int64, evs []mvccpb.Event) {
+	var victim watcherBatch
+	for w, eb := range newWatcherBatch(&s.synced, evs) {
+		if eb.revs != 1 {
+			plog.Panicf("unexpected multiple revisions in notification")
+		}
+		if w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: rev}) {
+			pendingEventsGauge.Add(float64(len(eb.evs)))
+		} else {
+			// move slow watcher to victims
+			w.minRev = rev + 1
+			if victim == nil {
+				victim = make(watcherBatch)
+			}
+			w.victim = true
+			victim[w] = eb
+			s.synced.delete(w)
+			slowWatcherGauge.Inc()
+		}
+	}
+	s.addVictim(victim)
+}
+
+func (s *watchableStore) addVictim(victim watcherBatch) {
+	if victim == nil {
+		return
+	}
+	s.victims = append(s.victims, victim)
+	select {
+	case s.victimc <- struct{}{}:
+	default:
+	}
+}
+
+func (s *watchableStore) rev() int64 { return s.store.Rev() }
+
+func (s *watchableStore) progress(w *watcher) {
+	s.mu.RLock()
+	defer s.mu.RUnlock()
+
+	if _, ok := s.synced.watchers[w]; ok {
+		w.send(WatchResponse{WatchID: w.id, Revision: s.rev()})
+		// If the ch is full, this watcher is receiving events.
+		// We do not need to send progress at all.
+	}
+}
+
+type watcher struct {
+	// the watcher key
+	key []byte
+	// end indicates the end of the range to watch.
+	// If end is set, the watcher is on a range.
+	end []byte
+
+	// victim is set when ch is blocked and undergoing victim processing
+	victim bool
+
+	// compacted is set when the watcher is removed because of compaction
+	compacted bool
+
+	// minRev is the minimum revision update the watcher will accept
+	minRev int64
+	id     WatchID
+
+	fcs []FilterFunc
+	// a chan to send out the watch response.
+	// The chan might be shared with other watchers.
+	ch chan<- WatchResponse
+}
+
+func (w *watcher) send(wr WatchResponse) bool {
+	progressEvent := len(wr.Events) == 0
+
+	if len(w.fcs) != 0 {
+		ne := make([]mvccpb.Event, 0, len(wr.Events))
+		for i := range wr.Events {
+			filtered := false
+			for _, filter := range w.fcs {
+				if filter(wr.Events[i]) {
+					filtered = true
+					break
+				}
+			}
+			if !filtered {
+				ne = append(ne, wr.Events[i])
+			}
+		}
+		wr.Events = ne
+	}
+
+	// if all events are filtered out, we should send nothing.
+	if !progressEvent && len(wr.Events) == 0 {
+		return true
+	}
+	select {
+	case w.ch <- wr:
+		return true
+	default:
+		return false
+	}
+}
diff --git a/internal/mvcc/watchable_store_bench_test.go b/internal/mvcc/watchable_store_bench_test.go
new file mode 100644
index 0000000..65807ab
--- /dev/null
+++ b/internal/mvcc/watchable_store_bench_test.go
@@ -0,0 +1,200 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"math/rand"
+	"os"
+	"testing"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+)
+
+func BenchmarkWatchableStorePut(b *testing.B) {
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := New(be, &lease.FakeLessor{}, nil)
+	defer cleanup(s, be, tmpPath)
+
+	// arbitrary number of bytes
+	bytesN := 64
+	keys := createBytesSlice(bytesN, b.N)
+	vals := createBytesSlice(bytesN, b.N)
+
+	b.ResetTimer()
+	b.ReportAllocs()
+	for i := 0; i < b.N; i++ {
+		s.Put(keys[i], vals[i], lease.NoLease)
+	}
+}
+
+// BenchmarkWatchableStoreTxnPut benchmarks the Put operation
+// with transaction begin and end, where transaction involves
+// some synchronization operations, such as mutex locking.
+func BenchmarkWatchableStoreTxnPut(b *testing.B) {
+	var i fakeConsistentIndex
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := New(be, &lease.FakeLessor{}, &i)
+	defer cleanup(s, be, tmpPath)
+
+	// arbitrary number of bytes
+	bytesN := 64
+	keys := createBytesSlice(bytesN, b.N)
+	vals := createBytesSlice(bytesN, b.N)
+
+	b.ResetTimer()
+	b.ReportAllocs()
+	for i := 0; i < b.N; i++ {
+		txn := s.Write()
+		txn.Put(keys[i], vals[i], lease.NoLease)
+		txn.End()
+	}
+}
+
+// BenchmarkWatchableStoreWatchSyncPut benchmarks the case of
+// many synced watchers receiving a Put notification.
+func BenchmarkWatchableStoreWatchSyncPut(b *testing.B) {
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(be, &lease.FakeLessor{}, nil)
+	defer cleanup(s, be, tmpPath)
+
+	k := []byte("testkey")
+	v := []byte("testval")
+
+	w := s.NewWatchStream()
+	defer w.Close()
+	watchIDs := make([]WatchID, b.N)
+	for i := range watchIDs {
+		// non-0 value to keep watchers in unsynced
+		watchIDs[i], _ = w.Watch(0, k, nil, 1)
+	}
+
+	b.ResetTimer()
+	b.ReportAllocs()
+
+	// trigger watchers
+	s.Put(k, v, lease.NoLease)
+	for range watchIDs {
+		<-w.Chan()
+	}
+	select {
+	case wc := <-w.Chan():
+		b.Fatalf("unexpected data %v", wc)
+	default:
+	}
+}
+
+// Benchmarks on cancel function performance for unsynced watchers
+// in a WatchableStore. It creates k*N watchers to populate unsynced
+// with a reasonably large number of watchers. And measures the time it
+// takes to cancel N watchers out of k*N watchers. The performance is
+// expected to differ depending on the unsynced member implementation.
+// TODO: k is an arbitrary constant. We need to figure out what factor
+// we should put to simulate the real-world use cases.
+func BenchmarkWatchableStoreUnsyncedCancel(b *testing.B) {
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := NewStore(be, &lease.FakeLessor{}, nil)
+
+	// manually create watchableStore instead of newWatchableStore
+	// because newWatchableStore periodically calls syncWatchersLoop
+	// method to sync watchers in unsynced map. We want to keep watchers
+	// in unsynced for this benchmark.
+	ws := &watchableStore{
+		store:    s,
+		unsynced: newWatcherGroup(),
+
+		// to make the test not crash from assigning to nil map.
+		// 'synced' doesn't get populated in this test.
+		synced: newWatcherGroup(),
+	}
+
+	defer func() {
+		ws.store.Close()
+		os.Remove(tmpPath)
+	}()
+
+	// Put a key so that we can spawn watchers on that key
+	// (testKey in this test). This increases the rev to 1,
+	// and later we can we set the watcher's startRev to 1,
+	// and force watchers to be in unsynced.
+	testKey := []byte("foo")
+	testValue := []byte("bar")
+	s.Put(testKey, testValue, lease.NoLease)
+
+	w := ws.NewWatchStream()
+
+	const k int = 2
+	benchSampleN := b.N
+	watcherN := k * benchSampleN
+
+	watchIDs := make([]WatchID, watcherN)
+	for i := 0; i < watcherN; i++ {
+		// non-0 value to keep watchers in unsynced
+		watchIDs[i], _ = w.Watch(0, testKey, nil, 1)
+	}
+
+	// random-cancel N watchers to make it not biased towards
+	// data structures with an order, such as slice.
+	ix := rand.Perm(watcherN)
+
+	b.ResetTimer()
+	b.ReportAllocs()
+
+	// cancel N watchers
+	for _, idx := range ix[:benchSampleN] {
+		if err := w.Cancel(watchIDs[idx]); err != nil {
+			b.Error(err)
+		}
+	}
+}
+
+func BenchmarkWatchableStoreSyncedCancel(b *testing.B) {
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(be, &lease.FakeLessor{}, nil)
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+
+	// Put a key so that we can spawn watchers on that key
+	testKey := []byte("foo")
+	testValue := []byte("bar")
+	s.Put(testKey, testValue, lease.NoLease)
+
+	w := s.NewWatchStream()
+
+	// put 1 million watchers on the same key
+	const watcherN = 1000000
+
+	watchIDs := make([]WatchID, watcherN)
+	for i := 0; i < watcherN; i++ {
+		// 0 for startRev to keep watchers in synced
+		watchIDs[i], _ = w.Watch(0, testKey, nil, 0)
+	}
+
+	// randomly cancel watchers to make it not biased towards
+	// data structures with an order, such as slice.
+	ix := rand.Perm(watcherN)
+
+	b.ResetTimer()
+	b.ReportAllocs()
+
+	for _, idx := range ix {
+		if err := w.Cancel(watchIDs[idx]); err != nil {
+			b.Error(err)
+		}
+	}
+}
diff --git a/internal/mvcc/watchable_store_test.go b/internal/mvcc/watchable_store_test.go
new file mode 100644
index 0000000..aa0e299
--- /dev/null
+++ b/internal/mvcc/watchable_store_test.go
@@ -0,0 +1,587 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"bytes"
+	"fmt"
+	"os"
+	"reflect"
+	"sync"
+	"testing"
+	"time"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+)
+
+func TestWatch(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+
+	testKey := []byte("foo")
+	testValue := []byte("bar")
+	s.Put(testKey, testValue, lease.NoLease)
+
+	w := s.NewWatchStream()
+	w.Watch(0, testKey, nil, 0)
+
+	if !s.synced.contains(string(testKey)) {
+		// the key must have had an entry in synced
+		t.Errorf("existence = false, want true")
+	}
+}
+
+func TestNewWatcherCancel(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+	testKey := []byte("foo")
+	testValue := []byte("bar")
+	s.Put(testKey, testValue, lease.NoLease)
+
+	w := s.NewWatchStream()
+	wt, _ := w.Watch(0, testKey, nil, 0)
+
+	if err := w.Cancel(wt); err != nil {
+		t.Error(err)
+	}
+
+	if s.synced.contains(string(testKey)) {
+		// the key shoud have been deleted
+		t.Errorf("existence = true, want false")
+	}
+}
+
+// TestCancelUnsynced tests if running CancelFunc removes watchers from unsynced.
+func TestCancelUnsynced(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+
+	// manually create watchableStore instead of newWatchableStore
+	// because newWatchableStore automatically calls syncWatchers
+	// method to sync watchers in unsynced map. We want to keep watchers
+	// in unsynced to test if syncWatchers works as expected.
+	s := &watchableStore{
+		store:    NewStore(b, &lease.FakeLessor{}, nil),
+		unsynced: newWatcherGroup(),
+
+		// to make the test not crash from assigning to nil map.
+		// 'synced' doesn't get populated in this test.
+		synced: newWatcherGroup(),
+	}
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+
+	// Put a key so that we can spawn watchers on that key.
+	// (testKey in this test). This increases the rev to 1,
+	// and later we can we set the watcher's startRev to 1,
+	// and force watchers to be in unsynced.
+	testKey := []byte("foo")
+	testValue := []byte("bar")
+	s.Put(testKey, testValue, lease.NoLease)
+
+	w := s.NewWatchStream()
+
+	// arbitrary number for watchers
+	watcherN := 100
+
+	// create watcherN of watch ids to cancel
+	watchIDs := make([]WatchID, watcherN)
+	for i := 0; i < watcherN; i++ {
+		// use 1 to keep watchers in unsynced
+		watchIDs[i], _ = w.Watch(0, testKey, nil, 1)
+	}
+
+	for _, idx := range watchIDs {
+		if err := w.Cancel(idx); err != nil {
+			t.Error(err)
+		}
+	}
+
+	// After running CancelFunc
+	//
+	// unsynced should be empty
+	// because cancel removes watcher from unsynced
+	if size := s.unsynced.size(); size != 0 {
+		t.Errorf("unsynced size = %d, want 0", size)
+	}
+}
+
+// TestSyncWatchers populates unsynced watcher map and tests syncWatchers
+// method to see if it correctly sends events to channel of unsynced watchers
+// and moves these watchers to synced.
+func TestSyncWatchers(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+
+	s := &watchableStore{
+		store:    NewStore(b, &lease.FakeLessor{}, nil),
+		unsynced: newWatcherGroup(),
+		synced:   newWatcherGroup(),
+	}
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+
+	testKey := []byte("foo")
+	testValue := []byte("bar")
+	s.Put(testKey, testValue, lease.NoLease)
+
+	w := s.NewWatchStream()
+
+	// arbitrary number for watchers
+	watcherN := 100
+
+	for i := 0; i < watcherN; i++ {
+		// specify rev as 1 to keep watchers in unsynced
+		w.Watch(0, testKey, nil, 1)
+	}
+
+	// Before running s.syncWatchers() synced should be empty because we manually
+	// populate unsynced only
+	sws := s.synced.watcherSetByKey(string(testKey))
+	uws := s.unsynced.watcherSetByKey(string(testKey))
+
+	if len(sws) != 0 {
+		t.Fatalf("synced[string(testKey)] size = %d, want 0", len(sws))
+	}
+	// unsynced should not be empty because we manually populated unsynced only
+	if len(uws) != watcherN {
+		t.Errorf("unsynced size = %d, want %d", len(uws), watcherN)
+	}
+
+	// this should move all unsynced watchers to synced ones
+	s.syncWatchers()
+
+	sws = s.synced.watcherSetByKey(string(testKey))
+	uws = s.unsynced.watcherSetByKey(string(testKey))
+
+	// After running s.syncWatchers(), synced should not be empty because syncwatchers
+	// populates synced in this test case
+	if len(sws) != watcherN {
+		t.Errorf("synced[string(testKey)] size = %d, want %d", len(sws), watcherN)
+	}
+
+	// unsynced should be empty because syncwatchers is expected to move all watchers
+	// from unsynced to synced in this test case
+	if len(uws) != 0 {
+		t.Errorf("unsynced size = %d, want 0", len(uws))
+	}
+
+	for w := range sws {
+		if w.minRev != s.Rev()+1 {
+			t.Errorf("w.minRev = %d, want %d", w.minRev, s.Rev()+1)
+		}
+	}
+
+	if len(w.(*watchStream).ch) != watcherN {
+		t.Errorf("watched event size = %d, want %d", len(w.(*watchStream).ch), watcherN)
+	}
+
+	evs := (<-w.(*watchStream).ch).Events
+	if len(evs) != 1 {
+		t.Errorf("len(evs) got = %d, want = 1", len(evs))
+	}
+	if evs[0].Type != mvccpb.PUT {
+		t.Errorf("got = %v, want = %v", evs[0].Type, mvccpb.PUT)
+	}
+	if !bytes.Equal(evs[0].Kv.Key, testKey) {
+		t.Errorf("got = %s, want = %s", evs[0].Kv.Key, testKey)
+	}
+	if !bytes.Equal(evs[0].Kv.Value, testValue) {
+		t.Errorf("got = %s, want = %s", evs[0].Kv.Value, testValue)
+	}
+}
+
+// TestWatchCompacted tests a watcher that watches on a compacted revision.
+func TestWatchCompacted(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+	testKey := []byte("foo")
+	testValue := []byte("bar")
+
+	maxRev := 10
+	compactRev := int64(5)
+	for i := 0; i < maxRev; i++ {
+		s.Put(testKey, testValue, lease.NoLease)
+	}
+	_, err := s.Compact(compactRev)
+	if err != nil {
+		t.Fatalf("failed to compact kv (%v)", err)
+	}
+
+	w := s.NewWatchStream()
+	wt, _ := w.Watch(0, testKey, nil, compactRev-1)
+
+	select {
+	case resp := <-w.Chan():
+		if resp.WatchID != wt {
+			t.Errorf("resp.WatchID = %x, want %x", resp.WatchID, wt)
+		}
+		if resp.CompactRevision == 0 {
+			t.Errorf("resp.Compacted = %v, want %v", resp.CompactRevision, compactRev)
+		}
+	case <-time.After(1 * time.Second):
+		t.Fatalf("failed to receive response (timeout)")
+	}
+}
+
+func TestWatchFutureRev(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+
+	testKey := []byte("foo")
+	testValue := []byte("bar")
+
+	w := s.NewWatchStream()
+	wrev := int64(10)
+	w.Watch(0, testKey, nil, wrev)
+
+	for i := 0; i < 10; i++ {
+		rev := s.Put(testKey, testValue, lease.NoLease)
+		if rev >= wrev {
+			break
+		}
+	}
+
+	select {
+	case resp := <-w.Chan():
+		if resp.Revision != wrev {
+			t.Fatalf("rev = %d, want %d", resp.Revision, wrev)
+		}
+		if len(resp.Events) != 1 {
+			t.Fatalf("failed to get events from the response")
+		}
+		if resp.Events[0].Kv.ModRevision != wrev {
+			t.Fatalf("kv.rev = %d, want %d", resp.Events[0].Kv.ModRevision, wrev)
+		}
+	case <-time.After(time.Second):
+		t.Fatal("failed to receive event in 1 second.")
+	}
+}
+
+func TestWatchRestore(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
+	defer cleanup(s, b, tmpPath)
+
+	testKey := []byte("foo")
+	testValue := []byte("bar")
+	rev := s.Put(testKey, testValue, lease.NoLease)
+
+	newBackend, newPath := backend.NewDefaultTmpBackend()
+	newStore := newWatchableStore(newBackend, &lease.FakeLessor{}, nil)
+	defer cleanup(newStore, newBackend, newPath)
+
+	w := newStore.NewWatchStream()
+	w.Watch(0, testKey, nil, rev-1)
+
+	newStore.Restore(b)
+	select {
+	case resp := <-w.Chan():
+		if resp.Revision != rev {
+			t.Fatalf("rev = %d, want %d", resp.Revision, rev)
+		}
+		if len(resp.Events) != 1 {
+			t.Fatalf("failed to get events from the response")
+		}
+		if resp.Events[0].Kv.ModRevision != rev {
+			t.Fatalf("kv.rev = %d, want %d", resp.Events[0].Kv.ModRevision, rev)
+		}
+	case <-time.After(time.Second):
+		t.Fatal("failed to receive event in 1 second.")
+	}
+}
+
+// TestWatchBatchUnsynced tests batching on unsynced watchers
+func TestWatchBatchUnsynced(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
+
+	oldMaxRevs := watchBatchMaxRevs
+	defer func() {
+		watchBatchMaxRevs = oldMaxRevs
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+	batches := 3
+	watchBatchMaxRevs = 4
+
+	v := []byte("foo")
+	for i := 0; i < watchBatchMaxRevs*batches; i++ {
+		s.Put(v, v, lease.NoLease)
+	}
+
+	w := s.NewWatchStream()
+	w.Watch(0, v, nil, 1)
+	for i := 0; i < batches; i++ {
+		if resp := <-w.Chan(); len(resp.Events) != watchBatchMaxRevs {
+			t.Fatalf("len(events) = %d, want %d", len(resp.Events), watchBatchMaxRevs)
+		}
+	}
+
+	s.store.revMu.Lock()
+	defer s.store.revMu.Unlock()
+	if size := s.synced.size(); size != 1 {
+		t.Errorf("synced size = %d, want 1", size)
+	}
+}
+
+func TestNewMapwatcherToEventMap(t *testing.T) {
+	k0, k1, k2 := []byte("foo0"), []byte("foo1"), []byte("foo2")
+	v0, v1, v2 := []byte("bar0"), []byte("bar1"), []byte("bar2")
+
+	ws := []*watcher{{key: k0}, {key: k1}, {key: k2}}
+
+	evs := []mvccpb.Event{
+		{
+			Type: mvccpb.PUT,
+			Kv:   &mvccpb.KeyValue{Key: k0, Value: v0},
+		},
+		{
+			Type: mvccpb.PUT,
+			Kv:   &mvccpb.KeyValue{Key: k1, Value: v1},
+		},
+		{
+			Type: mvccpb.PUT,
+			Kv:   &mvccpb.KeyValue{Key: k2, Value: v2},
+		},
+	}
+
+	tests := []struct {
+		sync []*watcher
+		evs  []mvccpb.Event
+
+		wwe map[*watcher][]mvccpb.Event
+	}{
+		// no watcher in sync, some events should return empty wwe
+		{
+			nil,
+			evs,
+			map[*watcher][]mvccpb.Event{},
+		},
+
+		// one watcher in sync, one event that does not match the key of that
+		// watcher should return empty wwe
+		{
+			[]*watcher{ws[2]},
+			evs[:1],
+			map[*watcher][]mvccpb.Event{},
+		},
+
+		// one watcher in sync, one event that matches the key of that
+		// watcher should return wwe with that matching watcher
+		{
+			[]*watcher{ws[1]},
+			evs[1:2],
+			map[*watcher][]mvccpb.Event{
+				ws[1]: evs[1:2],
+			},
+		},
+
+		// two watchers in sync that watches two different keys, one event
+		// that matches the key of only one of the watcher should return wwe
+		// with the matching watcher
+		{
+			[]*watcher{ws[0], ws[2]},
+			evs[2:],
+			map[*watcher][]mvccpb.Event{
+				ws[2]: evs[2:],
+			},
+		},
+
+		// two watchers in sync that watches the same key, two events that
+		// match the keys should return wwe with those two watchers
+		{
+			[]*watcher{ws[0], ws[1]},
+			evs[:2],
+			map[*watcher][]mvccpb.Event{
+				ws[0]: evs[:1],
+				ws[1]: evs[1:2],
+			},
+		},
+	}
+
+	for i, tt := range tests {
+		wg := newWatcherGroup()
+		for _, w := range tt.sync {
+			wg.add(w)
+		}
+
+		gwe := newWatcherBatch(&wg, tt.evs)
+		if len(gwe) != len(tt.wwe) {
+			t.Errorf("#%d: len(gwe) got = %d, want = %d", i, len(gwe), len(tt.wwe))
+		}
+		// compare gwe and tt.wwe
+		for w, eb := range gwe {
+			if len(eb.evs) != len(tt.wwe[w]) {
+				t.Errorf("#%d: len(eb.evs) got = %d, want = %d", i, len(eb.evs), len(tt.wwe[w]))
+			}
+			if !reflect.DeepEqual(eb.evs, tt.wwe[w]) {
+				t.Errorf("#%d: reflect.DeepEqual events got = %v, want = true", i, false)
+			}
+		}
+	}
+}
+
+// TestWatchVictims tests that watchable store delivers watch events
+// when the watch channel is temporarily clogged with too many events.
+func TestWatchVictims(t *testing.T) {
+	oldChanBufLen, oldMaxWatchersPerSync := chanBufLen, maxWatchersPerSync
+
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+		chanBufLen, maxWatchersPerSync = oldChanBufLen, oldMaxWatchersPerSync
+	}()
+
+	chanBufLen, maxWatchersPerSync = 1, 2
+	numPuts := chanBufLen * 64
+	testKey, testValue := []byte("foo"), []byte("bar")
+
+	var wg sync.WaitGroup
+	numWatches := maxWatchersPerSync * 128
+	errc := make(chan error, numWatches)
+	wg.Add(numWatches)
+	for i := 0; i < numWatches; i++ {
+		go func() {
+			w := s.NewWatchStream()
+			w.Watch(0, testKey, nil, 1)
+			defer func() {
+				w.Close()
+				wg.Done()
+			}()
+			tc := time.After(10 * time.Second)
+			evs, nextRev := 0, int64(2)
+			for evs < numPuts {
+				select {
+				case <-tc:
+					errc <- fmt.Errorf("time out")
+					return
+				case wr := <-w.Chan():
+					evs += len(wr.Events)
+					for _, ev := range wr.Events {
+						if ev.Kv.ModRevision != nextRev {
+							errc <- fmt.Errorf("expected rev=%d, got %d", nextRev, ev.Kv.ModRevision)
+							return
+						}
+						nextRev++
+					}
+					time.Sleep(time.Millisecond)
+				}
+			}
+			if evs != numPuts {
+				errc <- fmt.Errorf("expected %d events, got %d", numPuts, evs)
+				return
+			}
+			select {
+			case <-w.Chan():
+				errc <- fmt.Errorf("unexpected response")
+			default:
+			}
+		}()
+		time.Sleep(time.Millisecond)
+	}
+
+	var wgPut sync.WaitGroup
+	wgPut.Add(numPuts)
+	for i := 0; i < numPuts; i++ {
+		go func() {
+			defer wgPut.Done()
+			s.Put(testKey, testValue, lease.NoLease)
+		}()
+	}
+	wgPut.Wait()
+
+	wg.Wait()
+	select {
+	case err := <-errc:
+		t.Fatal(err)
+	default:
+	}
+}
+
+// TestStressWatchCancelClose tests closing a watch stream while
+// canceling its watches.
+func TestStressWatchCancelClose(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+
+	testKey, testValue := []byte("foo"), []byte("bar")
+	var wg sync.WaitGroup
+	readyc := make(chan struct{})
+	wg.Add(100)
+	for i := 0; i < 100; i++ {
+		go func() {
+			defer wg.Done()
+			w := s.NewWatchStream()
+			ids := make([]WatchID, 10)
+			for i := range ids {
+				ids[i], _ = w.Watch(0, testKey, nil, 0)
+			}
+			<-readyc
+			wg.Add(1 + len(ids)/2)
+			for i := range ids[:len(ids)/2] {
+				go func(n int) {
+					defer wg.Done()
+					w.Cancel(ids[n])
+				}(i)
+			}
+			go func() {
+				defer wg.Done()
+				w.Close()
+			}()
+		}()
+	}
+
+	close(readyc)
+	for i := 0; i < 100; i++ {
+		s.Put(testKey, testValue, lease.NoLease)
+	}
+
+	wg.Wait()
+}
diff --git a/internal/mvcc/watchable_store_txn.go b/internal/mvcc/watchable_store_txn.go
new file mode 100644
index 0000000..9c66e53
--- /dev/null
+++ b/internal/mvcc/watchable_store_txn.go
@@ -0,0 +1,51 @@
+// Copyright 2017 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import "github.com/coreos/etcd/internal/mvcc/mvccpb"
+
+func (tw *watchableStoreTxnWrite) End() {
+	changes := tw.Changes()
+	if len(changes) == 0 {
+		tw.TxnWrite.End()
+		return
+	}
+
+	rev := tw.Rev() + 1
+	evs := make([]mvccpb.Event, len(changes))
+	for i, change := range changes {
+		evs[i].Kv = &changes[i]
+		if change.CreateRevision == 0 {
+			evs[i].Type = mvccpb.DELETE
+			evs[i].Kv.ModRevision = rev
+		} else {
+			evs[i].Type = mvccpb.PUT
+		}
+	}
+
+	// end write txn under watchable store lock so the updates are visible
+	// when asynchronous event posting checks the current store revision
+	tw.s.mu.Lock()
+	tw.s.notify(rev, evs)
+	tw.TxnWrite.End()
+	tw.s.mu.Unlock()
+}
+
+type watchableStoreTxnWrite struct {
+	TxnWrite
+	s *watchableStore
+}
+
+func (s *watchableStore) Write() TxnWrite { return &watchableStoreTxnWrite{s.store.Write(), s} }
diff --git a/internal/mvcc/watcher.go b/internal/mvcc/watcher.go
new file mode 100644
index 0000000..9b79aa8
--- /dev/null
+++ b/internal/mvcc/watcher.go
@@ -0,0 +1,193 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"bytes"
+	"errors"
+	"sync"
+
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+)
+
+// AutoWatchID is the watcher ID passed in WatchStream.Watch when no
+// user-provided ID is available. If pass, an ID will automatically be assigned.
+const AutoWatchID WatchID = 0
+
+var (
+	ErrWatcherNotExist    = errors.New("mvcc: watcher does not exist")
+	ErrEmptyWatcherRange  = errors.New("mvcc: watcher range is empty")
+	ErrWatcherDuplicateID = errors.New("mvcc: duplicate watch ID provided on the WatchStream")
+)
+
+type WatchID int64
+
+// FilterFunc returns true if the given event should be filtered out.
+type FilterFunc func(e mvccpb.Event) bool
+
+type WatchStream interface {
+	// Watch creates a watcher. The watcher watches the events happening or
+	// happened on the given key or range [key, end) from the given startRev.
+	//
+	// The whole event history can be watched unless compacted.
+	// If "startRev" <=0, watch observes events after currentRev.
+	//
+	// The returned "id" is the ID of this watcher. It appears as WatchID
+	// in events that are sent to the created watcher through stream channel.
+	// The watch ID is used when it's not equal to AutoWatchID. Otherwise,
+	// an auto-generated watch ID is returned.
+	Watch(id WatchID, key, end []byte, startRev int64, fcs ...FilterFunc) (WatchID, error)
+
+	// Chan returns a chan. All watch response will be sent to the returned chan.
+	Chan() <-chan WatchResponse
+
+	// RequestProgress requests the progress of the watcher with given ID. The response
+	// will only be sent if the watcher is currently synced.
+	// The responses will be sent through the WatchRespone Chan attached
+	// with this stream to ensure correct ordering.
+	// The responses contains no events. The revision in the response is the progress
+	// of the watchers since the watcher is currently synced.
+	RequestProgress(id WatchID)
+
+	// Cancel cancels a watcher by giving its ID. If watcher does not exist, an error will be
+	// returned.
+	Cancel(id WatchID) error
+
+	// Close closes Chan and release all related resources.
+	Close()
+
+	// Rev returns the current revision of the KV the stream watches on.
+	Rev() int64
+}
+
+type WatchResponse struct {
+	// WatchID is the WatchID of the watcher this response sent to.
+	WatchID WatchID
+
+	// Events contains all the events that needs to send.
+	Events []mvccpb.Event
+
+	// Revision is the revision of the KV when the watchResponse is created.
+	// For a normal response, the revision should be the same as the last
+	// modified revision inside Events. For a delayed response to a unsynced
+	// watcher, the revision is greater than the last modified revision
+	// inside Events.
+	Revision int64
+
+	// CompactRevision is set when the watcher is cancelled due to compaction.
+	CompactRevision int64
+}
+
+// watchStream contains a collection of watchers that share
+// one streaming chan to send out watched events and other control events.
+type watchStream struct {
+	watchable watchable
+	ch        chan WatchResponse
+
+	mu sync.Mutex // guards fields below it
+	// nextID is the ID pre-allocated for next new watcher in this stream
+	nextID   WatchID
+	closed   bool
+	cancels  map[WatchID]cancelFunc
+	watchers map[WatchID]*watcher
+}
+
+// Watch creates a new watcher in the stream and returns its WatchID.
+func (ws *watchStream) Watch(id WatchID, key, end []byte, startRev int64, fcs ...FilterFunc) (WatchID, error) {
+	// prevent wrong range where key >= end lexicographically
+	// watch request with 'WithFromKey' has empty-byte range end
+	if len(end) != 0 && bytes.Compare(key, end) != -1 {
+		return -1, ErrEmptyWatcherRange
+	}
+
+	ws.mu.Lock()
+	defer ws.mu.Unlock()
+	if ws.closed {
+		return -1, ErrEmptyWatcherRange
+	}
+
+	if id == AutoWatchID {
+		for ws.watchers[ws.nextID] != nil {
+			ws.nextID++
+		}
+		id = ws.nextID
+		ws.nextID++
+	} else if _, ok := ws.watchers[id]; ok {
+		return -1, ErrWatcherDuplicateID
+	}
+
+	w, c := ws.watchable.watch(key, end, startRev, id, ws.ch, fcs...)
+
+	ws.cancels[id] = c
+	ws.watchers[id] = w
+	return id, nil
+}
+
+func (ws *watchStream) Chan() <-chan WatchResponse {
+	return ws.ch
+}
+
+func (ws *watchStream) Cancel(id WatchID) error {
+	ws.mu.Lock()
+	cancel, ok := ws.cancels[id]
+	w := ws.watchers[id]
+	ok = ok && !ws.closed
+	ws.mu.Unlock()
+
+	if !ok {
+		return ErrWatcherNotExist
+	}
+	cancel()
+
+	ws.mu.Lock()
+	// The watch isn't removed until cancel so that if Close() is called,
+	// it will wait for the cancel. Otherwise, Close() could close the
+	// watch channel while the store is still posting events.
+	if ww := ws.watchers[id]; ww == w {
+		delete(ws.cancels, id)
+		delete(ws.watchers, id)
+	}
+	ws.mu.Unlock()
+
+	return nil
+}
+
+func (ws *watchStream) Close() {
+	ws.mu.Lock()
+	defer ws.mu.Unlock()
+
+	for _, cancel := range ws.cancels {
+		cancel()
+	}
+	ws.closed = true
+	close(ws.ch)
+	watchStreamGauge.Dec()
+}
+
+func (ws *watchStream) Rev() int64 {
+	ws.mu.Lock()
+	defer ws.mu.Unlock()
+	return ws.watchable.rev()
+}
+
+func (ws *watchStream) RequestProgress(id WatchID) {
+	ws.mu.Lock()
+	w, ok := ws.watchers[id]
+	ws.mu.Unlock()
+	if !ok {
+		return
+	}
+	ws.watchable.progress(w)
+}
diff --git a/internal/mvcc/watcher_bench_test.go b/internal/mvcc/watcher_bench_test.go
new file mode 100644
index 0000000..72264cb
--- /dev/null
+++ b/internal/mvcc/watcher_bench_test.go
@@ -0,0 +1,38 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"fmt"
+	"testing"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+)
+
+func BenchmarkKVWatcherMemoryUsage(b *testing.B) {
+	be, tmpPath := backend.NewDefaultTmpBackend()
+	watchable := newWatchableStore(be, &lease.FakeLessor{}, nil)
+
+	defer cleanup(watchable, be, tmpPath)
+
+	w := watchable.NewWatchStream()
+
+	b.ReportAllocs()
+	b.StartTimer()
+	for i := 0; i < b.N; i++ {
+		w.Watch(0, []byte(fmt.Sprint("foo", i)), nil, 0)
+	}
+}
diff --git a/internal/mvcc/watcher_group.go b/internal/mvcc/watcher_group.go
new file mode 100644
index 0000000..d56daff
--- /dev/null
+++ b/internal/mvcc/watcher_group.go
@@ -0,0 +1,283 @@
+// Copyright 2016 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"math"
+
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+	"github.com/coreos/etcd/pkg/adt"
+)
+
+var (
+	// watchBatchMaxRevs is the maximum distinct revisions that
+	// may be sent to an unsynced watcher at a time. Declared as
+	// var instead of const for testing purposes.
+	watchBatchMaxRevs = 1000
+)
+
+type eventBatch struct {
+	// evs is a batch of revision-ordered events
+	evs []mvccpb.Event
+	// revs is the minimum unique revisions observed for this batch
+	revs int
+	// moreRev is first revision with more events following this batch
+	moreRev int64
+}
+
+func (eb *eventBatch) add(ev mvccpb.Event) {
+	if eb.revs > watchBatchMaxRevs {
+		// maxed out batch size
+		return
+	}
+
+	if len(eb.evs) == 0 {
+		// base case
+		eb.revs = 1
+		eb.evs = append(eb.evs, ev)
+		return
+	}
+
+	// revision accounting
+	ebRev := eb.evs[len(eb.evs)-1].Kv.ModRevision
+	evRev := ev.Kv.ModRevision
+	if evRev > ebRev {
+		eb.revs++
+		if eb.revs > watchBatchMaxRevs {
+			eb.moreRev = evRev
+			return
+		}
+	}
+
+	eb.evs = append(eb.evs, ev)
+}
+
+type watcherBatch map[*watcher]*eventBatch
+
+func (wb watcherBatch) add(w *watcher, ev mvccpb.Event) {
+	eb := wb[w]
+	if eb == nil {
+		eb = &eventBatch{}
+		wb[w] = eb
+	}
+	eb.add(ev)
+}
+
+// newWatcherBatch maps watchers to their matched events. It enables quick
+// events look up by watcher.
+func newWatcherBatch(wg *watcherGroup, evs []mvccpb.Event) watcherBatch {
+	if len(wg.watchers) == 0 {
+		return nil
+	}
+
+	wb := make(watcherBatch)
+	for _, ev := range evs {
+		for w := range wg.watcherSetByKey(string(ev.Kv.Key)) {
+			if ev.Kv.ModRevision >= w.minRev {
+				// don't double notify
+				wb.add(w, ev)
+			}
+		}
+	}
+	return wb
+}
+
+type watcherSet map[*watcher]struct{}
+
+func (w watcherSet) add(wa *watcher) {
+	if _, ok := w[wa]; ok {
+		panic("add watcher twice!")
+	}
+	w[wa] = struct{}{}
+}
+
+func (w watcherSet) union(ws watcherSet) {
+	for wa := range ws {
+		w.add(wa)
+	}
+}
+
+func (w watcherSet) delete(wa *watcher) {
+	if _, ok := w[wa]; !ok {
+		panic("removing missing watcher!")
+	}
+	delete(w, wa)
+}
+
+type watcherSetByKey map[string]watcherSet
+
+func (w watcherSetByKey) add(wa *watcher) {
+	set := w[string(wa.key)]
+	if set == nil {
+		set = make(watcherSet)
+		w[string(wa.key)] = set
+	}
+	set.add(wa)
+}
+
+func (w watcherSetByKey) delete(wa *watcher) bool {
+	k := string(wa.key)
+	if v, ok := w[k]; ok {
+		if _, ok := v[wa]; ok {
+			delete(v, wa)
+			if len(v) == 0 {
+				// remove the set; nothing left
+				delete(w, k)
+			}
+			return true
+		}
+	}
+	return false
+}
+
+// watcherGroup is a collection of watchers organized by their ranges
+type watcherGroup struct {
+	// keyWatchers has the watchers that watch on a single key
+	keyWatchers watcherSetByKey
+	// ranges has the watchers that watch a range; it is sorted by interval
+	ranges adt.IntervalTree
+	// watchers is the set of all watchers
+	watchers watcherSet
+}
+
+func newWatcherGroup() watcherGroup {
+	return watcherGroup{
+		keyWatchers: make(watcherSetByKey),
+		watchers:    make(watcherSet),
+	}
+}
+
+// add puts a watcher in the group.
+func (wg *watcherGroup) add(wa *watcher) {
+	wg.watchers.add(wa)
+	if wa.end == nil {
+		wg.keyWatchers.add(wa)
+		return
+	}
+
+	// interval already registered?
+	ivl := adt.NewStringAffineInterval(string(wa.key), string(wa.end))
+	if iv := wg.ranges.Find(ivl); iv != nil {
+		iv.Val.(watcherSet).add(wa)
+		return
+	}
+
+	// not registered, put in interval tree
+	ws := make(watcherSet)
+	ws.add(wa)
+	wg.ranges.Insert(ivl, ws)
+}
+
+// contains is whether the given key has a watcher in the group.
+func (wg *watcherGroup) contains(key string) bool {
+	_, ok := wg.keyWatchers[key]
+	return ok || wg.ranges.Intersects(adt.NewStringAffinePoint(key))
+}
+
+// size gives the number of unique watchers in the group.
+func (wg *watcherGroup) size() int { return len(wg.watchers) }
+
+// delete removes a watcher from the group.
+func (wg *watcherGroup) delete(wa *watcher) bool {
+	if _, ok := wg.watchers[wa]; !ok {
+		return false
+	}
+	wg.watchers.delete(wa)
+	if wa.end == nil {
+		wg.keyWatchers.delete(wa)
+		return true
+	}
+
+	ivl := adt.NewStringAffineInterval(string(wa.key), string(wa.end))
+	iv := wg.ranges.Find(ivl)
+	if iv == nil {
+		return false
+	}
+
+	ws := iv.Val.(watcherSet)
+	delete(ws, wa)
+	if len(ws) == 0 {
+		// remove interval missing watchers
+		if ok := wg.ranges.Delete(ivl); !ok {
+			panic("could not remove watcher from interval tree")
+		}
+	}
+
+	return true
+}
+
+// choose selects watchers from the watcher group to update
+func (wg *watcherGroup) choose(maxWatchers int, curRev, compactRev int64) (*watcherGroup, int64) {
+	if len(wg.watchers) < maxWatchers {
+		return wg, wg.chooseAll(curRev, compactRev)
+	}
+	ret := newWatcherGroup()
+	for w := range wg.watchers {
+		if maxWatchers <= 0 {
+			break
+		}
+		maxWatchers--
+		ret.add(w)
+	}
+	return &ret, ret.chooseAll(curRev, compactRev)
+}
+
+func (wg *watcherGroup) chooseAll(curRev, compactRev int64) int64 {
+	minRev := int64(math.MaxInt64)
+	for w := range wg.watchers {
+		if w.minRev > curRev {
+			panic("watcher current revision should not exceed current revision")
+		}
+		if w.minRev < compactRev {
+			select {
+			case w.ch <- WatchResponse{WatchID: w.id, CompactRevision: compactRev}:
+				w.compacted = true
+				wg.delete(w)
+			default:
+				// retry next time
+			}
+			continue
+		}
+		if minRev > w.minRev {
+			minRev = w.minRev
+		}
+	}
+	return minRev
+}
+
+// watcherSetByKey gets the set of watchers that receive events on the given key.
+func (wg *watcherGroup) watcherSetByKey(key string) watcherSet {
+	wkeys := wg.keyWatchers[key]
+	wranges := wg.ranges.Stab(adt.NewStringAffinePoint(key))
+
+	// zero-copy cases
+	switch {
+	case len(wranges) == 0:
+		// no need to merge ranges or copy; reuse single-key set
+		return wkeys
+	case len(wranges) == 0 && len(wkeys) == 0:
+		return nil
+	case len(wranges) == 1 && len(wkeys) == 0:
+		return wranges[0].Val.(watcherSet)
+	}
+
+	// copy case
+	ret := make(watcherSet)
+	ret.union(wg.keyWatchers[key])
+	for _, item := range wranges {
+		ret.union(item.Val.(watcherSet))
+	}
+	return ret
+}
diff --git a/internal/mvcc/watcher_test.go b/internal/mvcc/watcher_test.go
new file mode 100644
index 0000000..c4005b0
--- /dev/null
+++ b/internal/mvcc/watcher_test.go
@@ -0,0 +1,379 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package mvcc
+
+import (
+	"bytes"
+	"fmt"
+	"os"
+	"reflect"
+	"testing"
+	"time"
+
+	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
+)
+
+// TestWatcherWatchID tests that each watcher provides unique watchID,
+// and the watched event attaches the correct watchID.
+func TestWatcherWatchID(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
+	defer cleanup(s, b, tmpPath)
+
+	w := s.NewWatchStream()
+	defer w.Close()
+
+	idm := make(map[WatchID]struct{})
+
+	for i := 0; i < 10; i++ {
+		id, _ := w.Watch(0, []byte("foo"), nil, 0)
+		if _, ok := idm[id]; ok {
+			t.Errorf("#%d: id %d exists", i, id)
+		}
+		idm[id] = struct{}{}
+
+		s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
+
+		resp := <-w.Chan()
+		if resp.WatchID != id {
+			t.Errorf("#%d: watch id in event = %d, want %d", i, resp.WatchID, id)
+		}
+
+		if err := w.Cancel(id); err != nil {
+			t.Error(err)
+		}
+	}
+
+	s.Put([]byte("foo2"), []byte("bar"), lease.NoLease)
+
+	// unsynced watchers
+	for i := 10; i < 20; i++ {
+		id, _ := w.Watch(0, []byte("foo2"), nil, 1)
+		if _, ok := idm[id]; ok {
+			t.Errorf("#%d: id %d exists", i, id)
+		}
+		idm[id] = struct{}{}
+
+		resp := <-w.Chan()
+		if resp.WatchID != id {
+			t.Errorf("#%d: watch id in event = %d, want %d", i, resp.WatchID, id)
+		}
+
+		if err := w.Cancel(id); err != nil {
+			t.Error(err)
+		}
+	}
+}
+
+func TestWatcherRequestsCustomID(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
+	defer cleanup(s, b, tmpPath)
+
+	w := s.NewWatchStream()
+	defer w.Close()
+
+	// - Request specifically ID #1
+	// - Try to duplicate it, get an error
+	// - Make sure the auto-assignment skips over things we manually assigned
+
+	tt := []struct {
+		givenID     WatchID
+		expectedID  WatchID
+		expectedErr error
+	}{
+		{1, 1, nil},
+		{1, 0, ErrWatcherDuplicateID},
+		{0, 0, nil},
+		{0, 2, nil},
+	}
+
+	for i, tcase := range tt {
+		id, err := w.Watch(tcase.givenID, []byte("foo"), nil, 0)
+		if tcase.expectedErr != nil || err != nil {
+			if err != tcase.expectedErr {
+				t.Errorf("expected get error %q in test case %q, got %q", tcase.expectedErr, i, err)
+			}
+		} else if tcase.expectedID != id {
+			t.Errorf("expected to create ID %d, got %d in test case %d", tcase.expectedID, id, i)
+		}
+	}
+}
+
+// TestWatcherWatchPrefix tests if Watch operation correctly watches
+// and returns events with matching prefixes.
+func TestWatcherWatchPrefix(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
+	defer cleanup(s, b, tmpPath)
+
+	w := s.NewWatchStream()
+	defer w.Close()
+
+	idm := make(map[WatchID]struct{})
+
+	val := []byte("bar")
+	keyWatch, keyEnd, keyPut := []byte("foo"), []byte("fop"), []byte("foobar")
+
+	for i := 0; i < 10; i++ {
+		id, _ := w.Watch(0, keyWatch, keyEnd, 0)
+		if _, ok := idm[id]; ok {
+			t.Errorf("#%d: unexpected duplicated id %x", i, id)
+		}
+		idm[id] = struct{}{}
+
+		s.Put(keyPut, val, lease.NoLease)
+
+		resp := <-w.Chan()
+		if resp.WatchID != id {
+			t.Errorf("#%d: watch id in event = %d, want %d", i, resp.WatchID, id)
+		}
+
+		if err := w.Cancel(id); err != nil {
+			t.Errorf("#%d: unexpected cancel error %v", i, err)
+		}
+
+		if len(resp.Events) != 1 {
+			t.Errorf("#%d: len(resp.Events) got = %d, want = 1", i, len(resp.Events))
+		}
+		if len(resp.Events) == 1 {
+			if !bytes.Equal(resp.Events[0].Kv.Key, keyPut) {
+				t.Errorf("#%d: resp.Events got = %s, want = %s", i, resp.Events[0].Kv.Key, keyPut)
+			}
+		}
+	}
+
+	keyWatch1, keyEnd1, keyPut1 := []byte("foo1"), []byte("foo2"), []byte("foo1bar")
+	s.Put(keyPut1, val, lease.NoLease)
+
+	// unsynced watchers
+	for i := 10; i < 15; i++ {
+		id, _ := w.Watch(0, keyWatch1, keyEnd1, 1)
+		if _, ok := idm[id]; ok {
+			t.Errorf("#%d: id %d exists", i, id)
+		}
+		idm[id] = struct{}{}
+
+		resp := <-w.Chan()
+		if resp.WatchID != id {
+			t.Errorf("#%d: watch id in event = %d, want %d", i, resp.WatchID, id)
+		}
+
+		if err := w.Cancel(id); err != nil {
+			t.Error(err)
+		}
+
+		if len(resp.Events) != 1 {
+			t.Errorf("#%d: len(resp.Events) got = %d, want = 1", i, len(resp.Events))
+		}
+		if len(resp.Events) == 1 {
+			if !bytes.Equal(resp.Events[0].Kv.Key, keyPut1) {
+				t.Errorf("#%d: resp.Events got = %s, want = %s", i, resp.Events[0].Kv.Key, keyPut1)
+			}
+		}
+	}
+}
+
+// TestWatcherWatchWrongRange ensures that watcher with wrong 'end' range
+// does not create watcher, which panics when canceling in range tree.
+func TestWatcherWatchWrongRange(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
+	defer cleanup(s, b, tmpPath)
+
+	w := s.NewWatchStream()
+	defer w.Close()
+
+	if _, err := w.Watch(0, []byte("foa"), []byte("foa"), 1); err != ErrEmptyWatcherRange {
+		t.Fatalf("key == end range given; expected ErrEmptyWatcherRange, got %+v", err)
+	}
+	if _, err := w.Watch(0, []byte("fob"), []byte("foa"), 1); err != ErrEmptyWatcherRange {
+		t.Fatalf("key > end range given; expected ErrEmptyWatcherRange, got %+v", err)
+	}
+	// watch request with 'WithFromKey' has empty-byte range end
+	if id, _ := w.Watch(0, []byte("foo"), []byte{}, 1); id != 0 {
+		t.Fatalf("\x00 is range given; id expected 0, got %d", id)
+	}
+}
+
+func TestWatchDeleteRange(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+
+	testKeyPrefix := []byte("foo")
+
+	for i := 0; i < 3; i++ {
+		s.Put([]byte(fmt.Sprintf("%s_%d", testKeyPrefix, i)), []byte("bar"), lease.NoLease)
+	}
+
+	w := s.NewWatchStream()
+	from, to := []byte(testKeyPrefix), []byte(fmt.Sprintf("%s_%d", testKeyPrefix, 99))
+	w.Watch(0, from, to, 0)
+
+	s.DeleteRange(from, to)
+
+	we := []mvccpb.Event{
+		{Type: mvccpb.DELETE, Kv: &mvccpb.KeyValue{Key: []byte("foo_0"), ModRevision: 5}},
+		{Type: mvccpb.DELETE, Kv: &mvccpb.KeyValue{Key: []byte("foo_1"), ModRevision: 5}},
+		{Type: mvccpb.DELETE, Kv: &mvccpb.KeyValue{Key: []byte("foo_2"), ModRevision: 5}},
+	}
+
+	select {
+	case r := <-w.Chan():
+		if !reflect.DeepEqual(r.Events, we) {
+			t.Errorf("event = %v, want %v", r.Events, we)
+		}
+	case <-time.After(10 * time.Second):
+		t.Fatal("failed to receive event after 10 seconds!")
+	}
+}
+
+// TestWatchStreamCancelWatcherByID ensures cancel calls the cancel func of the watcher
+// with given id inside watchStream.
+func TestWatchStreamCancelWatcherByID(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
+	defer cleanup(s, b, tmpPath)
+
+	w := s.NewWatchStream()
+	defer w.Close()
+
+	id, _ := w.Watch(0, []byte("foo"), nil, 0)
+
+	tests := []struct {
+		cancelID WatchID
+		werr     error
+	}{
+		// no error should be returned when cancel the created watcher.
+		{id, nil},
+		// not exist error should be returned when cancel again.
+		{id, ErrWatcherNotExist},
+		// not exist error should be returned when cancel a bad id.
+		{id + 1, ErrWatcherNotExist},
+	}
+
+	for i, tt := range tests {
+		gerr := w.Cancel(tt.cancelID)
+
+		if gerr != tt.werr {
+			t.Errorf("#%d: err = %v, want %v", i, gerr, tt.werr)
+		}
+	}
+
+	if l := len(w.(*watchStream).cancels); l != 0 {
+		t.Errorf("cancels = %d, want 0", l)
+	}
+}
+
+// TestWatcherRequestProgress ensures synced watcher can correctly
+// report its correct progress.
+func TestWatcherRequestProgress(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+
+	// manually create watchableStore instead of newWatchableStore
+	// because newWatchableStore automatically calls syncWatchers
+	// method to sync watchers in unsynced map. We want to keep watchers
+	// in unsynced to test if syncWatchers works as expected.
+	s := &watchableStore{
+		store:    NewStore(b, &lease.FakeLessor{}, nil),
+		unsynced: newWatcherGroup(),
+		synced:   newWatcherGroup(),
+	}
+
+	defer func() {
+		s.store.Close()
+		os.Remove(tmpPath)
+	}()
+
+	testKey := []byte("foo")
+	notTestKey := []byte("bad")
+	testValue := []byte("bar")
+	s.Put(testKey, testValue, lease.NoLease)
+
+	w := s.NewWatchStream()
+
+	badID := WatchID(1000)
+	w.RequestProgress(badID)
+	select {
+	case resp := <-w.Chan():
+		t.Fatalf("unexpected %+v", resp)
+	default:
+	}
+
+	id, _ := w.Watch(0, notTestKey, nil, 1)
+	w.RequestProgress(id)
+	select {
+	case resp := <-w.Chan():
+		t.Fatalf("unexpected %+v", resp)
+	default:
+	}
+
+	s.syncWatchers()
+
+	w.RequestProgress(id)
+	wrs := WatchResponse{WatchID: id, Revision: 2}
+	select {
+	case resp := <-w.Chan():
+		if !reflect.DeepEqual(resp, wrs) {
+			t.Fatalf("got %+v, expect %+v", resp, wrs)
+		}
+	case <-time.After(time.Second):
+		t.Fatal("failed to receive progress")
+	}
+}
+
+func TestWatcherWatchWithFilter(t *testing.T) {
+	b, tmpPath := backend.NewDefaultTmpBackend()
+	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
+	defer cleanup(s, b, tmpPath)
+
+	w := s.NewWatchStream()
+	defer w.Close()
+
+	filterPut := func(e mvccpb.Event) bool {
+		return e.Type == mvccpb.PUT
+	}
+
+	w.Watch(0, []byte("foo"), nil, 0, filterPut)
+	done := make(chan struct{})
+
+	go func() {
+		<-w.Chan()
+		done <- struct{}{}
+	}()
+
+	s.Put([]byte("foo"), []byte("bar"), 0)
+
+	select {
+	case <-done:
+		t.Fatal("failed to filter put request")
+	case <-time.After(100 * time.Millisecond):
+	}
+
+	s.DeleteRange([]byte("foo"), nil)
+
+	select {
+	case <-done:
+	case <-time.After(100 * time.Millisecond):
+		t.Fatal("failed to receive delete request")
+	}
+}
diff --git a/mvcc/backend/backend.go b/mvcc/backend/backend.go
deleted file mode 100644
index c0305cf..0000000
--- a/mvcc/backend/backend.go
+++ /dev/null
@@ -1,446 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package backend
-
-import (
-	"fmt"
-	"hash/crc32"
-	"io"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"sync"
-	"sync/atomic"
-	"time"
-
-	bolt "github.com/coreos/bbolt"
-	"github.com/coreos/pkg/capnslog"
-)
-
-var (
-	defaultBatchLimit    = 10000
-	defaultBatchInterval = 100 * time.Millisecond
-
-	defragLimit = 10000
-
-	// initialMmapSize is the initial size of the mmapped region. Setting this larger than
-	// the potential max db size can prevent writer from blocking reader.
-	// This only works for linux.
-	initialMmapSize = uint64(10 * 1024 * 1024 * 1024)
-
-	plog = capnslog.NewPackageLogger("github.com/coreos/etcd", "mvcc/backend")
-
-	// minSnapshotWarningTimeout is the minimum threshold to trigger a long running snapshot warning.
-	minSnapshotWarningTimeout = time.Duration(30 * time.Second)
-)
-
-type Backend interface {
-	ReadTx() ReadTx
-	BatchTx() BatchTx
-
-	Snapshot() Snapshot
-	Hash(ignores map[IgnoreKey]struct{}) (uint32, error)
-	// Size returns the current size of the backend.
-	Size() int64
-	Defrag() error
-	ForceCommit()
-	Close() error
-}
-
-type Snapshot interface {
-	// Size gets the size of the snapshot.
-	Size() int64
-	// WriteTo writes the snapshot into the given writer.
-	WriteTo(w io.Writer) (n int64, err error)
-	// Close closes the snapshot.
-	Close() error
-}
-
-type backend struct {
-	// size and commits are used with atomic operations so they must be
-	// 64-bit aligned, otherwise 32-bit tests will crash
-
-	// size is the number of bytes in the backend
-	size int64
-	// commits counts number of commits since start
-	commits int64
-
-	mu sync.RWMutex
-	db *bolt.DB
-
-	batchInterval time.Duration
-	batchLimit    int
-	batchTx       *batchTxBuffered
-
-	readTx *readTx
-
-	stopc chan struct{}
-	donec chan struct{}
-}
-
-type BackendConfig struct {
-	// Path is the file path to the backend file.
-	Path string
-	// BatchInterval is the maximum time before flushing the BatchTx.
-	BatchInterval time.Duration
-	// BatchLimit is the maximum puts before flushing the BatchTx.
-	BatchLimit int
-	// MmapSize is the number of bytes to mmap for the backend.
-	MmapSize uint64
-}
-
-func DefaultBackendConfig() BackendConfig {
-	return BackendConfig{
-		BatchInterval: defaultBatchInterval,
-		BatchLimit:    defaultBatchLimit,
-		MmapSize:      initialMmapSize,
-	}
-}
-
-func New(bcfg BackendConfig) Backend {
-	return newBackend(bcfg)
-}
-
-func NewDefaultBackend(path string) Backend {
-	bcfg := DefaultBackendConfig()
-	bcfg.Path = path
-	return newBackend(bcfg)
-}
-
-func newBackend(bcfg BackendConfig) *backend {
-	bopts := &bolt.Options{}
-	if boltOpenOptions != nil {
-		*bopts = *boltOpenOptions
-	}
-	bopts.InitialMmapSize = bcfg.mmapSize()
-
-	db, err := bolt.Open(bcfg.Path, 0600, bopts)
-	if err != nil {
-		plog.Panicf("cannot open database at %s (%v)", bcfg.Path, err)
-	}
-
-	// In future, may want to make buffering optional for low-concurrency systems
-	// or dynamically swap between buffered/non-buffered depending on workload.
-	b := &backend{
-		db: db,
-
-		batchInterval: bcfg.BatchInterval,
-		batchLimit:    bcfg.BatchLimit,
-
-		readTx: &readTx{
-			buf: txReadBuffer{
-				txBuffer: txBuffer{make(map[string]*bucketBuffer)},
-			},
-			buckets: make(map[string]*bolt.Bucket),
-		},
-
-		stopc: make(chan struct{}),
-		donec: make(chan struct{}),
-	}
-	b.batchTx = newBatchTxBuffered(b)
-	go b.run()
-	return b
-}
-
-// BatchTx returns the current batch tx in coalescer. The tx can be used for read and
-// write operations. The write result can be retrieved within the same tx immediately.
-// The write result is isolated with other txs until the current one get committed.
-func (b *backend) BatchTx() BatchTx {
-	return b.batchTx
-}
-
-func (b *backend) ReadTx() ReadTx { return b.readTx }
-
-// ForceCommit forces the current batching tx to commit.
-func (b *backend) ForceCommit() {
-	b.batchTx.Commit()
-}
-
-func (b *backend) Snapshot() Snapshot {
-	b.batchTx.Commit()
-
-	b.mu.RLock()
-	defer b.mu.RUnlock()
-	tx, err := b.db.Begin(false)
-	if err != nil {
-		plog.Fatalf("cannot begin tx (%s)", err)
-	}
-
-	stopc, donec := make(chan struct{}), make(chan struct{})
-	dbBytes := tx.Size()
-	go func() {
-		defer close(donec)
-		// sendRateBytes is based on transferring snapshot data over a 1 gigabit/s connection
-		// assuming a min tcp throughput of 100MB/s.
-		var sendRateBytes int64 = 100 * 1024 * 1014
-		warningTimeout := time.Duration(int64((float64(dbBytes) / float64(sendRateBytes)) * float64(time.Second)))
-		if warningTimeout < minSnapshotWarningTimeout {
-			warningTimeout = minSnapshotWarningTimeout
-		}
-		start := time.Now()
-		ticker := time.NewTicker(warningTimeout)
-		defer ticker.Stop()
-		for {
-			select {
-			case <-ticker.C:
-				plog.Warningf("snapshotting is taking more than %v seconds to finish transferring %v MB [started at %v]", time.Since(start).Seconds(), float64(dbBytes)/float64(1024*1014), start)
-			case <-stopc:
-				snapshotDurations.Observe(time.Since(start).Seconds())
-				return
-			}
-		}
-	}()
-
-	return &snapshot{tx, stopc, donec}
-}
-
-type IgnoreKey struct {
-	Bucket string
-	Key    string
-}
-
-func (b *backend) Hash(ignores map[IgnoreKey]struct{}) (uint32, error) {
-	h := crc32.New(crc32.MakeTable(crc32.Castagnoli))
-
-	b.mu.RLock()
-	defer b.mu.RUnlock()
-	err := b.db.View(func(tx *bolt.Tx) error {
-		c := tx.Cursor()
-		for next, _ := c.First(); next != nil; next, _ = c.Next() {
-			b := tx.Bucket(next)
-			if b == nil {
-				return fmt.Errorf("cannot get hash of bucket %s", string(next))
-			}
-			h.Write(next)
-			b.ForEach(func(k, v []byte) error {
-				bk := IgnoreKey{Bucket: string(next), Key: string(k)}
-				if _, ok := ignores[bk]; !ok {
-					h.Write(k)
-					h.Write(v)
-				}
-				return nil
-			})
-		}
-		return nil
-	})
-
-	if err != nil {
-		return 0, err
-	}
-
-	return h.Sum32(), nil
-}
-
-func (b *backend) Size() int64 {
-	return atomic.LoadInt64(&b.size)
-}
-
-func (b *backend) run() {
-	defer close(b.donec)
-	t := time.NewTimer(b.batchInterval)
-	defer t.Stop()
-	for {
-		select {
-		case <-t.C:
-		case <-b.stopc:
-			b.batchTx.CommitAndStop()
-			return
-		}
-		b.batchTx.Commit()
-		t.Reset(b.batchInterval)
-	}
-}
-
-func (b *backend) Close() error {
-	close(b.stopc)
-	<-b.donec
-	return b.db.Close()
-}
-
-// Commits returns total number of commits since start
-func (b *backend) Commits() int64 {
-	return atomic.LoadInt64(&b.commits)
-}
-
-func (b *backend) Defrag() error {
-	err := b.defrag()
-	if err != nil {
-		return err
-	}
-
-	// commit to update metadata like db.size
-	b.batchTx.Commit()
-
-	return nil
-}
-
-func (b *backend) defrag() error {
-	// TODO: make this non-blocking?
-	// lock batchTx to ensure nobody is using previous tx, and then
-	// close previous ongoing tx.
-	b.batchTx.Lock()
-	defer b.batchTx.Unlock()
-
-	// lock database after lock tx to avoid deadlock.
-	b.mu.Lock()
-	defer b.mu.Unlock()
-
-	// block concurrent read requests while resetting tx
-	b.readTx.mu.Lock()
-	defer b.readTx.mu.Unlock()
-
-	b.batchTx.unsafeCommit(true)
-	b.batchTx.tx = nil
-
-	tmpdb, err := bolt.Open(b.db.Path()+".tmp", 0600, boltOpenOptions)
-	if err != nil {
-		return err
-	}
-
-	err = defragdb(b.db, tmpdb, defragLimit)
-
-	if err != nil {
-		tmpdb.Close()
-		os.RemoveAll(tmpdb.Path())
-		return err
-	}
-
-	dbp := b.db.Path()
-	tdbp := tmpdb.Path()
-
-	err = b.db.Close()
-	if err != nil {
-		plog.Fatalf("cannot close database (%s)", err)
-	}
-	err = tmpdb.Close()
-	if err != nil {
-		plog.Fatalf("cannot close database (%s)", err)
-	}
-	err = os.Rename(tdbp, dbp)
-	if err != nil {
-		plog.Fatalf("cannot rename database (%s)", err)
-	}
-
-	b.db, err = bolt.Open(dbp, 0600, boltOpenOptions)
-	if err != nil {
-		plog.Panicf("cannot open database at %s (%v)", dbp, err)
-	}
-	b.batchTx.tx, err = b.db.Begin(true)
-	if err != nil {
-		plog.Fatalf("cannot begin tx (%s)", err)
-	}
-
-	b.readTx.reset()
-	b.readTx.tx = b.unsafeBegin(false)
-	atomic.StoreInt64(&b.size, b.readTx.tx.Size())
-
-	return nil
-}
-
-func defragdb(odb, tmpdb *bolt.DB, limit int) error {
-	// open a tx on tmpdb for writes
-	tmptx, err := tmpdb.Begin(true)
-	if err != nil {
-		return err
-	}
-
-	// open a tx on old db for read
-	tx, err := odb.Begin(false)
-	if err != nil {
-		return err
-	}
-	defer tx.Rollback()
-
-	c := tx.Cursor()
-
-	count := 0
-	for next, _ := c.First(); next != nil; next, _ = c.Next() {
-		b := tx.Bucket(next)
-		if b == nil {
-			return fmt.Errorf("backend: cannot defrag bucket %s", string(next))
-		}
-
-		tmpb, berr := tmptx.CreateBucketIfNotExists(next)
-		if berr != nil {
-			return berr
-		}
-		tmpb.FillPercent = 0.9 // for seq write in for each
-
-		b.ForEach(func(k, v []byte) error {
-			count++
-			if count > limit {
-				err = tmptx.Commit()
-				if err != nil {
-					return err
-				}
-				tmptx, err = tmpdb.Begin(true)
-				if err != nil {
-					return err
-				}
-				tmpb = tmptx.Bucket(next)
-				tmpb.FillPercent = 0.9 // for seq write in for each
-
-				count = 0
-			}
-			return tmpb.Put(k, v)
-		})
-	}
-
-	return tmptx.Commit()
-}
-
-func (b *backend) begin(write bool) *bolt.Tx {
-	b.mu.RLock()
-	tx := b.unsafeBegin(write)
-	b.mu.RUnlock()
-	atomic.StoreInt64(&b.size, tx.Size())
-	return tx
-}
-
-func (b *backend) unsafeBegin(write bool) *bolt.Tx {
-	tx, err := b.db.Begin(write)
-	if err != nil {
-		plog.Fatalf("cannot begin tx (%s)", err)
-	}
-	return tx
-}
-
-// NewTmpBackend creates a backend implementation for testing.
-func NewTmpBackend(batchInterval time.Duration, batchLimit int) (*backend, string) {
-	dir, err := ioutil.TempDir(os.TempDir(), "etcd_backend_test")
-	if err != nil {
-		plog.Fatal(err)
-	}
-	tmpPath := filepath.Join(dir, "database")
-	bcfg := DefaultBackendConfig()
-	bcfg.Path, bcfg.BatchInterval, bcfg.BatchLimit = tmpPath, batchInterval, batchLimit
-	return newBackend(bcfg), tmpPath
-}
-
-func NewDefaultTmpBackend() (*backend, string) {
-	return NewTmpBackend(defaultBatchInterval, defaultBatchLimit)
-}
-
-type snapshot struct {
-	*bolt.Tx
-	stopc chan struct{}
-	donec chan struct{}
-}
-
-func (s *snapshot) Close() error {
-	close(s.stopc)
-	<-s.donec
-	return s.Tx.Rollback()
-}
diff --git a/mvcc/backend/backend_bench_test.go b/mvcc/backend/backend_bench_test.go
deleted file mode 100644
index 30b4751..0000000
--- a/mvcc/backend/backend_bench_test.go
+++ /dev/null
@@ -1,50 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package backend
-
-import (
-	"crypto/rand"
-	"os"
-	"testing"
-	"time"
-)
-
-func BenchmarkBackendPut(b *testing.B) {
-	backend, tmppath := NewTmpBackend(100*time.Millisecond, 10000)
-	defer backend.Close()
-	defer os.Remove(tmppath)
-
-	// prepare keys
-	keys := make([][]byte, b.N)
-	for i := 0; i < b.N; i++ {
-		keys[i] = make([]byte, 64)
-		rand.Read(keys[i])
-	}
-	value := make([]byte, 128)
-	rand.Read(value)
-
-	batchTx := backend.BatchTx()
-
-	batchTx.Lock()
-	batchTx.UnsafeCreateBucket([]byte("test"))
-	batchTx.Unlock()
-
-	b.ResetTimer()
-	for i := 0; i < b.N; i++ {
-		batchTx.Lock()
-		batchTx.UnsafePut([]byte("test"), keys[i], value)
-		batchTx.Unlock()
-	}
-}
diff --git a/mvcc/backend/backend_test.go b/mvcc/backend/backend_test.go
deleted file mode 100644
index 9bdec5c..0000000
--- a/mvcc/backend/backend_test.go
+++ /dev/null
@@ -1,306 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package backend
-
-import (
-	"fmt"
-	"io/ioutil"
-	"os"
-	"reflect"
-	"testing"
-	"time"
-
-	bolt "github.com/coreos/bbolt"
-)
-
-func TestBackendClose(t *testing.T) {
-	b, tmpPath := NewTmpBackend(time.Hour, 10000)
-	defer os.Remove(tmpPath)
-
-	// check close could work
-	done := make(chan struct{})
-	go func() {
-		err := b.Close()
-		if err != nil {
-			t.Errorf("close error = %v, want nil", err)
-		}
-		done <- struct{}{}
-	}()
-	select {
-	case <-done:
-	case <-time.After(10 * time.Second):
-		t.Errorf("failed to close database in 10s")
-	}
-}
-
-func TestBackendSnapshot(t *testing.T) {
-	b, tmpPath := NewTmpBackend(time.Hour, 10000)
-	defer cleanup(b, tmpPath)
-
-	tx := b.BatchTx()
-	tx.Lock()
-	tx.UnsafeCreateBucket([]byte("test"))
-	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
-	tx.Unlock()
-	b.ForceCommit()
-
-	// write snapshot to a new file
-	f, err := ioutil.TempFile(os.TempDir(), "etcd_backend_test")
-	if err != nil {
-		t.Fatal(err)
-	}
-	snap := b.Snapshot()
-	defer snap.Close()
-	if _, err := snap.WriteTo(f); err != nil {
-		t.Fatal(err)
-	}
-	f.Close()
-
-	// bootstrap new backend from the snapshot
-	bcfg := DefaultBackendConfig()
-	bcfg.Path, bcfg.BatchInterval, bcfg.BatchLimit = f.Name(), time.Hour, 10000
-	nb := New(bcfg)
-	defer cleanup(nb, f.Name())
-
-	newTx := b.BatchTx()
-	newTx.Lock()
-	ks, _ := newTx.UnsafeRange([]byte("test"), []byte("foo"), []byte("goo"), 0)
-	if len(ks) != 1 {
-		t.Errorf("len(kvs) = %d, want 1", len(ks))
-	}
-	newTx.Unlock()
-}
-
-func TestBackendBatchIntervalCommit(t *testing.T) {
-	// start backend with super short batch interval so
-	// we do not need to wait long before commit to happen.
-	b, tmpPath := NewTmpBackend(time.Nanosecond, 10000)
-	defer cleanup(b, tmpPath)
-
-	pc := b.Commits()
-
-	tx := b.BatchTx()
-	tx.Lock()
-	tx.UnsafeCreateBucket([]byte("test"))
-	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
-	tx.Unlock()
-
-	for i := 0; i < 10; i++ {
-		if b.Commits() >= pc+1 {
-			break
-		}
-		time.Sleep(time.Duration(i*100) * time.Millisecond)
-	}
-
-	// check whether put happens via db view
-	b.db.View(func(tx *bolt.Tx) error {
-		bucket := tx.Bucket([]byte("test"))
-		if bucket == nil {
-			t.Errorf("bucket test does not exit")
-			return nil
-		}
-		v := bucket.Get([]byte("foo"))
-		if v == nil {
-			t.Errorf("foo key failed to written in backend")
-		}
-		return nil
-	})
-}
-
-func TestBackendDefrag(t *testing.T) {
-	b, tmpPath := NewDefaultTmpBackend()
-	defer cleanup(b, tmpPath)
-
-	tx := b.BatchTx()
-	tx.Lock()
-	tx.UnsafeCreateBucket([]byte("test"))
-	for i := 0; i < defragLimit+100; i++ {
-		tx.UnsafePut([]byte("test"), []byte(fmt.Sprintf("foo_%d", i)), []byte("bar"))
-	}
-	tx.Unlock()
-	b.ForceCommit()
-
-	// remove some keys to ensure the disk space will be reclaimed after defrag
-	tx = b.BatchTx()
-	tx.Lock()
-	for i := 0; i < 50; i++ {
-		tx.UnsafeDelete([]byte("test"), []byte(fmt.Sprintf("foo_%d", i)))
-	}
-	tx.Unlock()
-	b.ForceCommit()
-
-	size := b.Size()
-
-	// shrink and check hash
-	oh, err := b.Hash(nil)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = b.Defrag()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	nh, err := b.Hash(nil)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if oh != nh {
-		t.Errorf("hash = %v, want %v", nh, oh)
-	}
-
-	nsize := b.Size()
-	if nsize >= size {
-		t.Errorf("new size = %v, want < %d", nsize, size)
-	}
-
-	// try put more keys after shrink.
-	tx = b.BatchTx()
-	tx.Lock()
-	tx.UnsafeCreateBucket([]byte("test"))
-	tx.UnsafePut([]byte("test"), []byte("more"), []byte("bar"))
-	tx.Unlock()
-	b.ForceCommit()
-}
-
-// TestBackendWriteback ensures writes are stored to the read txn on write txn unlock.
-func TestBackendWriteback(t *testing.T) {
-	b, tmpPath := NewDefaultTmpBackend()
-	defer cleanup(b, tmpPath)
-
-	tx := b.BatchTx()
-	tx.Lock()
-	tx.UnsafeCreateBucket([]byte("key"))
-	tx.UnsafePut([]byte("key"), []byte("abc"), []byte("bar"))
-	tx.UnsafePut([]byte("key"), []byte("def"), []byte("baz"))
-	tx.UnsafePut([]byte("key"), []byte("overwrite"), []byte("1"))
-	tx.Unlock()
-
-	// overwrites should be propagated too
-	tx.Lock()
-	tx.UnsafePut([]byte("key"), []byte("overwrite"), []byte("2"))
-	tx.Unlock()
-
-	keys := []struct {
-		key   []byte
-		end   []byte
-		limit int64
-
-		wkey [][]byte
-		wval [][]byte
-	}{
-		{
-			key: []byte("abc"),
-			end: nil,
-
-			wkey: [][]byte{[]byte("abc")},
-			wval: [][]byte{[]byte("bar")},
-		},
-		{
-			key: []byte("abc"),
-			end: []byte("def"),
-
-			wkey: [][]byte{[]byte("abc")},
-			wval: [][]byte{[]byte("bar")},
-		},
-		{
-			key: []byte("abc"),
-			end: []byte("deg"),
-
-			wkey: [][]byte{[]byte("abc"), []byte("def")},
-			wval: [][]byte{[]byte("bar"), []byte("baz")},
-		},
-		{
-			key:   []byte("abc"),
-			end:   []byte("\xff"),
-			limit: 1,
-
-			wkey: [][]byte{[]byte("abc")},
-			wval: [][]byte{[]byte("bar")},
-		},
-		{
-			key: []byte("abc"),
-			end: []byte("\xff"),
-
-			wkey: [][]byte{[]byte("abc"), []byte("def"), []byte("overwrite")},
-			wval: [][]byte{[]byte("bar"), []byte("baz"), []byte("2")},
-		},
-	}
-	rtx := b.ReadTx()
-	for i, tt := range keys {
-		rtx.Lock()
-		k, v := rtx.UnsafeRange([]byte("key"), tt.key, tt.end, tt.limit)
-		rtx.Unlock()
-		if !reflect.DeepEqual(tt.wkey, k) || !reflect.DeepEqual(tt.wval, v) {
-			t.Errorf("#%d: want k=%+v, v=%+v; got k=%+v, v=%+v", i, tt.wkey, tt.wval, k, v)
-		}
-	}
-}
-
-// TestBackendWritebackForEach checks that partially written / buffered
-// data is visited in the same order as fully committed data.
-func TestBackendWritebackForEach(t *testing.T) {
-	b, tmpPath := NewTmpBackend(time.Hour, 10000)
-	defer cleanup(b, tmpPath)
-
-	tx := b.BatchTx()
-	tx.Lock()
-	tx.UnsafeCreateBucket([]byte("key"))
-	for i := 0; i < 5; i++ {
-		k := []byte(fmt.Sprintf("%04d", i))
-		tx.UnsafePut([]byte("key"), k, []byte("bar"))
-	}
-	tx.Unlock()
-
-	// writeback
-	b.ForceCommit()
-
-	tx.Lock()
-	tx.UnsafeCreateBucket([]byte("key"))
-	for i := 5; i < 20; i++ {
-		k := []byte(fmt.Sprintf("%04d", i))
-		tx.UnsafePut([]byte("key"), k, []byte("bar"))
-	}
-	tx.Unlock()
-
-	seq := ""
-	getSeq := func(k, v []byte) error {
-		seq += string(k)
-		return nil
-	}
-	rtx := b.ReadTx()
-	rtx.Lock()
-	rtx.UnsafeForEach([]byte("key"), getSeq)
-	rtx.Unlock()
-
-	partialSeq := seq
-
-	seq = ""
-	b.ForceCommit()
-
-	tx.Lock()
-	tx.UnsafeForEach([]byte("key"), getSeq)
-	tx.Unlock()
-
-	if seq != partialSeq {
-		t.Fatalf("expected %q, got %q", seq, partialSeq)
-	}
-}
-
-func cleanup(b Backend, path string) {
-	b.Close()
-	os.Remove(path)
-}
diff --git a/mvcc/backend/batch_tx.go b/mvcc/backend/batch_tx.go
deleted file mode 100644
index 43ddc71..0000000
--- a/mvcc/backend/batch_tx.go
+++ /dev/null
@@ -1,260 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package backend
-
-import (
-	"bytes"
-	"math"
-	"sync"
-	"sync/atomic"
-	"time"
-
-	bolt "github.com/coreos/bbolt"
-)
-
-type BatchTx interface {
-	ReadTx
-	UnsafeCreateBucket(name []byte)
-	UnsafePut(bucketName []byte, key []byte, value []byte)
-	UnsafeSeqPut(bucketName []byte, key []byte, value []byte)
-	UnsafeDelete(bucketName []byte, key []byte)
-	// Commit commits a previous tx and begins a new writable one.
-	Commit()
-	// CommitAndStop commits the previous tx and does not create a new one.
-	CommitAndStop()
-}
-
-type batchTx struct {
-	sync.Mutex
-	tx      *bolt.Tx
-	backend *backend
-
-	pending int
-}
-
-func (t *batchTx) UnsafeCreateBucket(name []byte) {
-	_, err := t.tx.CreateBucket(name)
-	if err != nil && err != bolt.ErrBucketExists {
-		plog.Fatalf("cannot create bucket %s (%v)", name, err)
-	}
-	t.pending++
-}
-
-// UnsafePut must be called holding the lock on the tx.
-func (t *batchTx) UnsafePut(bucketName []byte, key []byte, value []byte) {
-	t.unsafePut(bucketName, key, value, false)
-}
-
-// UnsafeSeqPut must be called holding the lock on the tx.
-func (t *batchTx) UnsafeSeqPut(bucketName []byte, key []byte, value []byte) {
-	t.unsafePut(bucketName, key, value, true)
-}
-
-func (t *batchTx) unsafePut(bucketName []byte, key []byte, value []byte, seq bool) {
-	bucket := t.tx.Bucket(bucketName)
-	if bucket == nil {
-		plog.Fatalf("bucket %s does not exist", bucketName)
-	}
-	if seq {
-		// it is useful to increase fill percent when the workloads are mostly append-only.
-		// this can delay the page split and reduce space usage.
-		bucket.FillPercent = 0.9
-	}
-	if err := bucket.Put(key, value); err != nil {
-		plog.Fatalf("cannot put key into bucket (%v)", err)
-	}
-	t.pending++
-}
-
-// UnsafeRange must be called holding the lock on the tx.
-func (t *batchTx) UnsafeRange(bucketName, key, endKey []byte, limit int64) ([][]byte, [][]byte) {
-	bucket := t.tx.Bucket(bucketName)
-	if bucket == nil {
-		plog.Fatalf("bucket %s does not exist", bucketName)
-	}
-	return unsafeRange(bucket.Cursor(), key, endKey, limit)
-}
-
-func unsafeRange(c *bolt.Cursor, key, endKey []byte, limit int64) (keys [][]byte, vs [][]byte) {
-	if limit <= 0 {
-		limit = math.MaxInt64
-	}
-	var isMatch func(b []byte) bool
-	if len(endKey) > 0 {
-		isMatch = func(b []byte) bool { return bytes.Compare(b, endKey) < 0 }
-	} else {
-		isMatch = func(b []byte) bool { return bytes.Equal(b, key) }
-		limit = 1
-	}
-	for ck, cv := c.Seek(key); ck != nil && isMatch(ck); ck, cv = c.Next() {
-		vs = append(vs, cv)
-		keys = append(keys, ck)
-		if limit == int64(len(keys)) {
-			break
-		}
-	}
-	return keys, vs
-}
-
-// UnsafeDelete must be called holding the lock on the tx.
-func (t *batchTx) UnsafeDelete(bucketName []byte, key []byte) {
-	bucket := t.tx.Bucket(bucketName)
-	if bucket == nil {
-		plog.Fatalf("bucket %s does not exist", bucketName)
-	}
-	err := bucket.Delete(key)
-	if err != nil {
-		plog.Fatalf("cannot delete key from bucket (%v)", err)
-	}
-	t.pending++
-}
-
-// UnsafeForEach must be called holding the lock on the tx.
-func (t *batchTx) UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error {
-	return unsafeForEach(t.tx, bucketName, visitor)
-}
-
-func unsafeForEach(tx *bolt.Tx, bucket []byte, visitor func(k, v []byte) error) error {
-	if b := tx.Bucket(bucket); b != nil {
-		return b.ForEach(visitor)
-	}
-	return nil
-}
-
-// Commit commits a previous tx and begins a new writable one.
-func (t *batchTx) Commit() {
-	t.Lock()
-	defer t.Unlock()
-	t.commit(false)
-}
-
-// CommitAndStop commits the previous tx and does not create a new one.
-func (t *batchTx) CommitAndStop() {
-	t.Lock()
-	defer t.Unlock()
-	t.commit(true)
-}
-
-func (t *batchTx) Unlock() {
-	if t.pending >= t.backend.batchLimit {
-		t.commit(false)
-	}
-	t.Mutex.Unlock()
-}
-
-func (t *batchTx) commit(stop bool) {
-	// commit the last tx
-	if t.tx != nil {
-		if t.pending == 0 && !stop {
-			t.backend.mu.RLock()
-			defer t.backend.mu.RUnlock()
-
-			// t.tx.DB()==nil if 'CommitAndStop' calls 'batchTx.commit(true)',
-			// which initializes *bolt.Tx.db and *bolt.Tx.meta as nil; panics t.tx.Size().
-			// Server must make sure 'batchTx.commit(false)' does not follow
-			// 'batchTx.commit(true)' (e.g. stopping backend, and inflight Hash call).
-			atomic.StoreInt64(&t.backend.size, t.tx.Size())
-			return
-		}
-
-		start := time.Now()
-		// gofail: var beforeCommit struct{}
-		err := t.tx.Commit()
-		// gofail: var afterCommit struct{}
-		commitDurations.Observe(time.Since(start).Seconds())
-		atomic.AddInt64(&t.backend.commits, 1)
-
-		t.pending = 0
-		if err != nil {
-			plog.Fatalf("cannot commit tx (%s)", err)
-		}
-	}
-	if !stop {
-		t.tx = t.backend.begin(true)
-	}
-}
-
-type batchTxBuffered struct {
-	batchTx
-	buf txWriteBuffer
-}
-
-func newBatchTxBuffered(backend *backend) *batchTxBuffered {
-	tx := &batchTxBuffered{
-		batchTx: batchTx{backend: backend},
-		buf: txWriteBuffer{
-			txBuffer: txBuffer{make(map[string]*bucketBuffer)},
-			seq:      true,
-		},
-	}
-	tx.Commit()
-	return tx
-}
-
-func (t *batchTxBuffered) Unlock() {
-	if t.pending != 0 {
-		t.backend.readTx.mu.Lock()
-		t.buf.writeback(&t.backend.readTx.buf)
-		t.backend.readTx.mu.Unlock()
-		if t.pending >= t.backend.batchLimit {
-			t.commit(false)
-		}
-	}
-	t.batchTx.Unlock()
-}
-
-func (t *batchTxBuffered) Commit() {
-	t.Lock()
-	defer t.Unlock()
-	t.commit(false)
-}
-
-func (t *batchTxBuffered) CommitAndStop() {
-	t.Lock()
-	defer t.Unlock()
-	t.commit(true)
-}
-
-func (t *batchTxBuffered) commit(stop bool) {
-	// all read txs must be closed to acquire boltdb commit rwlock
-	t.backend.readTx.mu.Lock()
-	defer t.backend.readTx.mu.Unlock()
-	t.unsafeCommit(stop)
-}
-
-func (t *batchTxBuffered) unsafeCommit(stop bool) {
-	if t.backend.readTx.tx != nil {
-		if err := t.backend.readTx.tx.Rollback(); err != nil {
-			plog.Fatalf("cannot rollback tx (%s)", err)
-		}
-		t.backend.readTx.reset()
-	}
-
-	t.batchTx.commit(stop)
-
-	if !stop {
-		t.backend.readTx.tx = t.backend.begin(false)
-	}
-}
-
-func (t *batchTxBuffered) UnsafePut(bucketName []byte, key []byte, value []byte) {
-	t.batchTx.UnsafePut(bucketName, key, value)
-	t.buf.put(bucketName, key, value)
-}
-
-func (t *batchTxBuffered) UnsafeSeqPut(bucketName []byte, key []byte, value []byte) {
-	t.batchTx.UnsafeSeqPut(bucketName, key, value)
-	t.buf.putSeq(bucketName, key, value)
-}
diff --git a/mvcc/backend/batch_tx_test.go b/mvcc/backend/batch_tx_test.go
deleted file mode 100644
index 57549b9..0000000
--- a/mvcc/backend/batch_tx_test.go
+++ /dev/null
@@ -1,197 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package backend
-
-import (
-	"reflect"
-	"testing"
-	"time"
-
-	bolt "github.com/coreos/bbolt"
-)
-
-func TestBatchTxPut(t *testing.T) {
-	b, tmpPath := NewTmpBackend(time.Hour, 10000)
-	defer cleanup(b, tmpPath)
-
-	tx := b.batchTx
-	tx.Lock()
-	defer tx.Unlock()
-
-	// create bucket
-	tx.UnsafeCreateBucket([]byte("test"))
-
-	// put
-	v := []byte("bar")
-	tx.UnsafePut([]byte("test"), []byte("foo"), v)
-
-	// check put result before and after tx is committed
-	for k := 0; k < 2; k++ {
-		_, gv := tx.UnsafeRange([]byte("test"), []byte("foo"), nil, 0)
-		if !reflect.DeepEqual(gv[0], v) {
-			t.Errorf("v = %s, want %s", string(gv[0]), string(v))
-		}
-		tx.commit(false)
-	}
-}
-
-func TestBatchTxRange(t *testing.T) {
-	b, tmpPath := NewTmpBackend(time.Hour, 10000)
-	defer cleanup(b, tmpPath)
-
-	tx := b.batchTx
-	tx.Lock()
-	defer tx.Unlock()
-
-	tx.UnsafeCreateBucket([]byte("test"))
-	// put keys
-	allKeys := [][]byte{[]byte("foo"), []byte("foo1"), []byte("foo2")}
-	allVals := [][]byte{[]byte("bar"), []byte("bar1"), []byte("bar2")}
-	for i := range allKeys {
-		tx.UnsafePut([]byte("test"), allKeys[i], allVals[i])
-	}
-
-	tests := []struct {
-		key    []byte
-		endKey []byte
-		limit  int64
-
-		wkeys [][]byte
-		wvals [][]byte
-	}{
-		// single key
-		{
-			[]byte("foo"), nil, 0,
-			allKeys[:1], allVals[:1],
-		},
-		// single key, bad
-		{
-			[]byte("doo"), nil, 0,
-			nil, nil,
-		},
-		// key range
-		{
-			[]byte("foo"), []byte("foo1"), 0,
-			allKeys[:1], allVals[:1],
-		},
-		// key range, get all keys
-		{
-			[]byte("foo"), []byte("foo3"), 0,
-			allKeys, allVals,
-		},
-		// key range, bad
-		{
-			[]byte("goo"), []byte("goo3"), 0,
-			nil, nil,
-		},
-		// key range with effective limit
-		{
-			[]byte("foo"), []byte("foo3"), 1,
-			allKeys[:1], allVals[:1],
-		},
-		// key range with limit
-		{
-			[]byte("foo"), []byte("foo3"), 4,
-			allKeys, allVals,
-		},
-	}
-	for i, tt := range tests {
-		keys, vals := tx.UnsafeRange([]byte("test"), tt.key, tt.endKey, tt.limit)
-		if !reflect.DeepEqual(keys, tt.wkeys) {
-			t.Errorf("#%d: keys = %+v, want %+v", i, keys, tt.wkeys)
-		}
-		if !reflect.DeepEqual(vals, tt.wvals) {
-			t.Errorf("#%d: vals = %+v, want %+v", i, vals, tt.wvals)
-		}
-	}
-}
-
-func TestBatchTxDelete(t *testing.T) {
-	b, tmpPath := NewTmpBackend(time.Hour, 10000)
-	defer cleanup(b, tmpPath)
-
-	tx := b.batchTx
-	tx.Lock()
-	defer tx.Unlock()
-
-	tx.UnsafeCreateBucket([]byte("test"))
-	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
-
-	tx.UnsafeDelete([]byte("test"), []byte("foo"))
-
-	// check put result before and after tx is committed
-	for k := 0; k < 2; k++ {
-		ks, _ := tx.UnsafeRange([]byte("test"), []byte("foo"), nil, 0)
-		if len(ks) != 0 {
-			t.Errorf("keys on foo = %v, want nil", ks)
-		}
-		tx.commit(false)
-	}
-}
-
-func TestBatchTxCommit(t *testing.T) {
-	b, tmpPath := NewTmpBackend(time.Hour, 10000)
-	defer cleanup(b, tmpPath)
-
-	tx := b.batchTx
-	tx.Lock()
-	tx.UnsafeCreateBucket([]byte("test"))
-	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
-	tx.Unlock()
-
-	tx.Commit()
-
-	// check whether put happens via db view
-	b.db.View(func(tx *bolt.Tx) error {
-		bucket := tx.Bucket([]byte("test"))
-		if bucket == nil {
-			t.Errorf("bucket test does not exit")
-			return nil
-		}
-		v := bucket.Get([]byte("foo"))
-		if v == nil {
-			t.Errorf("foo key failed to written in backend")
-		}
-		return nil
-	})
-}
-
-func TestBatchTxBatchLimitCommit(t *testing.T) {
-	// start backend with batch limit 1 so one write can
-	// trigger a commit
-	b, tmpPath := NewTmpBackend(time.Hour, 1)
-	defer cleanup(b, tmpPath)
-
-	tx := b.batchTx
-	tx.Lock()
-	tx.UnsafeCreateBucket([]byte("test"))
-	tx.UnsafePut([]byte("test"), []byte("foo"), []byte("bar"))
-	tx.Unlock()
-
-	// batch limit commit should have been triggered
-	// check whether put happens via db view
-	b.db.View(func(tx *bolt.Tx) error {
-		bucket := tx.Bucket([]byte("test"))
-		if bucket == nil {
-			t.Errorf("bucket test does not exit")
-			return nil
-		}
-		v := bucket.Get([]byte("foo"))
-		if v == nil {
-			t.Errorf("foo key failed to written in backend")
-		}
-		return nil
-	})
-}
diff --git a/mvcc/backend/config_default.go b/mvcc/backend/config_default.go
deleted file mode 100644
index edfed00..0000000
--- a/mvcc/backend/config_default.go
+++ /dev/null
@@ -1,23 +0,0 @@
-// Copyright 2016 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-// +build !linux,!windows
-
-package backend
-
-import bolt "github.com/coreos/bbolt"
-
-var boltOpenOptions *bolt.Options = nil
-
-func (bcfg *BackendConfig) mmapSize() int { return int(bcfg.MmapSize) }
diff --git a/mvcc/backend/config_linux.go b/mvcc/backend/config_linux.go
deleted file mode 100644
index b01785f..0000000
--- a/mvcc/backend/config_linux.go
+++ /dev/null
@@ -1,34 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package backend
-
-import (
-	"syscall"
-
-	bolt "github.com/coreos/bbolt"
-)
-
-// syscall.MAP_POPULATE on linux 2.6.23+ does sequential read-ahead
-// which can speed up entire-database read with boltdb. We want to
-// enable MAP_POPULATE for faster key-value store recovery in storage
-// package. If your kernel version is lower than 2.6.23
-// (https://github.com/torvalds/linux/releases/tag/v2.6.23), mmap might
-// silently ignore this flag. Please update your kernel to prevent this.
-var boltOpenOptions = &bolt.Options{
-	MmapFlags:      syscall.MAP_POPULATE,
-	NoFreelistSync: true,
-}
-
-func (bcfg *BackendConfig) mmapSize() int { return int(bcfg.MmapSize) }
diff --git a/mvcc/backend/config_windows.go b/mvcc/backend/config_windows.go
deleted file mode 100644
index 71d0270..0000000
--- a/mvcc/backend/config_windows.go
+++ /dev/null
@@ -1,26 +0,0 @@
-// Copyright 2017 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-// +build windows
-
-package backend
-
-import bolt "github.com/coreos/bbolt"
-
-var boltOpenOptions *bolt.Options = nil
-
-// setting mmap size != 0 on windows will allocate the entire
-// mmap size for the file, instead of growing it. So, force 0.
-
-func (bcfg *BackendConfig) mmapSize() int { return 0 }
diff --git a/mvcc/backend/doc.go b/mvcc/backend/doc.go
deleted file mode 100644
index 9cc42fa..0000000
--- a/mvcc/backend/doc.go
+++ /dev/null
@@ -1,16 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-// Package backend defines a standard interface for etcd's backend MVCC storage.
-package backend
diff --git a/mvcc/backend/metrics.go b/mvcc/backend/metrics.go
deleted file mode 100644
index 30a3880..0000000
--- a/mvcc/backend/metrics.go
+++ /dev/null
@@ -1,41 +0,0 @@
-// Copyright 2016 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package backend
-
-import "github.com/prometheus/client_golang/prometheus"
-
-var (
-	commitDurations = prometheus.NewHistogram(prometheus.HistogramOpts{
-		Namespace: "etcd",
-		Subsystem: "disk",
-		Name:      "backend_commit_duration_seconds",
-		Help:      "The latency distributions of commit called by backend.",
-		Buckets:   prometheus.ExponentialBuckets(0.001, 2, 14),
-	})
-
-	snapshotDurations = prometheus.NewHistogram(prometheus.HistogramOpts{
-		Namespace: "etcd",
-		Subsystem: "disk",
-		Name:      "backend_snapshot_duration_seconds",
-		Help:      "The latency distribution of backend snapshots.",
-		// 10 ms -> 655 seconds
-		Buckets: prometheus.ExponentialBuckets(.01, 2, 17),
-	})
-)
-
-func init() {
-	prometheus.MustRegister(commitDurations)
-	prometheus.MustRegister(snapshotDurations)
-}
diff --git a/mvcc/backend/read_tx.go b/mvcc/backend/read_tx.go
deleted file mode 100644
index 0536de7..0000000
--- a/mvcc/backend/read_tx.go
+++ /dev/null
@@ -1,120 +0,0 @@
-// Copyright 2017 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package backend
-
-import (
-	"bytes"
-	"math"
-	"sync"
-
-	bolt "github.com/coreos/bbolt"
-)
-
-// safeRangeBucket is a hack to avoid inadvertently reading duplicate keys;
-// overwrites on a bucket should only fetch with limit=1, but safeRangeBucket
-// is known to never overwrite any key so range is safe.
-var safeRangeBucket = []byte("key")
-
-type ReadTx interface {
-	Lock()
-	Unlock()
-
-	UnsafeRange(bucketName []byte, key, endKey []byte, limit int64) (keys [][]byte, vals [][]byte)
-	UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error
-}
-
-type readTx struct {
-	// mu protects accesses to the txReadBuffer
-	mu  sync.RWMutex
-	buf txReadBuffer
-
-	// txmu protects accesses to buckets and tx on Range requests.
-	txmu    sync.RWMutex
-	tx      *bolt.Tx
-	buckets map[string]*bolt.Bucket
-}
-
-func (rt *readTx) Lock()   { rt.mu.RLock() }
-func (rt *readTx) Unlock() { rt.mu.RUnlock() }
-
-func (rt *readTx) UnsafeRange(bucketName, key, endKey []byte, limit int64) ([][]byte, [][]byte) {
-	if endKey == nil {
-		// forbid duplicates for single keys
-		limit = 1
-	}
-	if limit <= 0 {
-		limit = math.MaxInt64
-	}
-	if limit > 1 && !bytes.Equal(bucketName, safeRangeBucket) {
-		panic("do not use unsafeRange on non-keys bucket")
-	}
-	keys, vals := rt.buf.Range(bucketName, key, endKey, limit)
-	if int64(len(keys)) == limit {
-		return keys, vals
-	}
-
-	// find/cache bucket
-	bn := string(bucketName)
-	rt.txmu.RLock()
-	bucket, ok := rt.buckets[bn]
-	rt.txmu.RUnlock()
-	if !ok {
-		rt.txmu.Lock()
-		bucket = rt.tx.Bucket(bucketName)
-		rt.buckets[bn] = bucket
-		rt.txmu.Unlock()
-	}
-
-	// ignore missing bucket since may have been created in this batch
-	if bucket == nil {
-		return keys, vals
-	}
-	rt.txmu.Lock()
-	c := bucket.Cursor()
-	rt.txmu.Unlock()
-
-	k2, v2 := unsafeRange(c, key, endKey, limit-int64(len(keys)))
-	return append(k2, keys...), append(v2, vals...)
-}
-
-func (rt *readTx) UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error {
-	dups := make(map[string]struct{})
-	getDups := func(k, v []byte) error {
-		dups[string(k)] = struct{}{}
-		return nil
-	}
-	visitNoDup := func(k, v []byte) error {
-		if _, ok := dups[string(k)]; ok {
-			return nil
-		}
-		return visitor(k, v)
-	}
-	if err := rt.buf.ForEach(bucketName, getDups); err != nil {
-		return err
-	}
-	rt.txmu.Lock()
-	err := unsafeForEach(rt.tx, bucketName, visitNoDup)
-	rt.txmu.Unlock()
-	if err != nil {
-		return err
-	}
-	return rt.buf.ForEach(bucketName, visitor)
-}
-
-func (rt *readTx) reset() {
-	rt.buf.reset()
-	rt.buckets = make(map[string]*bolt.Bucket)
-	rt.tx = nil
-}
diff --git a/mvcc/backend/tx_buffer.go b/mvcc/backend/tx_buffer.go
deleted file mode 100644
index 56e885d..0000000
--- a/mvcc/backend/tx_buffer.go
+++ /dev/null
@@ -1,181 +0,0 @@
-// Copyright 2017 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package backend
-
-import (
-	"bytes"
-	"sort"
-)
-
-// txBuffer handles functionality shared between txWriteBuffer and txReadBuffer.
-type txBuffer struct {
-	buckets map[string]*bucketBuffer
-}
-
-func (txb *txBuffer) reset() {
-	for k, v := range txb.buckets {
-		if v.used == 0 {
-			// demote
-			delete(txb.buckets, k)
-		}
-		v.used = 0
-	}
-}
-
-// txWriteBuffer buffers writes of pending updates that have not yet committed.
-type txWriteBuffer struct {
-	txBuffer
-	seq bool
-}
-
-func (txw *txWriteBuffer) put(bucket, k, v []byte) {
-	txw.seq = false
-	txw.putSeq(bucket, k, v)
-}
-
-func (txw *txWriteBuffer) putSeq(bucket, k, v []byte) {
-	b, ok := txw.buckets[string(bucket)]
-	if !ok {
-		b = newBucketBuffer()
-		txw.buckets[string(bucket)] = b
-	}
-	b.add(k, v)
-}
-
-func (txw *txWriteBuffer) writeback(txr *txReadBuffer) {
-	for k, wb := range txw.buckets {
-		rb, ok := txr.buckets[k]
-		if !ok {
-			delete(txw.buckets, k)
-			txr.buckets[k] = wb
-			continue
-		}
-		if !txw.seq && wb.used > 1 {
-			// assume no duplicate keys
-			sort.Sort(wb)
-		}
-		rb.merge(wb)
-	}
-	txw.reset()
-}
-
-// txReadBuffer accesses buffered updates.
-type txReadBuffer struct{ txBuffer }
-
-func (txr *txReadBuffer) Range(bucketName, key, endKey []byte, limit int64) ([][]byte, [][]byte) {
-	if b := txr.buckets[string(bucketName)]; b != nil {
-		return b.Range(key, endKey, limit)
-	}
-	return nil, nil
-}
-
-func (txr *txReadBuffer) ForEach(bucketName []byte, visitor func(k, v []byte) error) error {
-	if b := txr.buckets[string(bucketName)]; b != nil {
-		return b.ForEach(visitor)
-	}
-	return nil
-}
-
-type kv struct {
-	key []byte
-	val []byte
-}
-
-// bucketBuffer buffers key-value pairs that are pending commit.
-type bucketBuffer struct {
-	buf []kv
-	// used tracks number of elements in use so buf can be reused without reallocation.
-	used int
-}
-
-func newBucketBuffer() *bucketBuffer {
-	return &bucketBuffer{buf: make([]kv, 512), used: 0}
-}
-
-func (bb *bucketBuffer) Range(key, endKey []byte, limit int64) (keys [][]byte, vals [][]byte) {
-	f := func(i int) bool { return bytes.Compare(bb.buf[i].key, key) >= 0 }
-	idx := sort.Search(bb.used, f)
-	if idx < 0 {
-		return nil, nil
-	}
-	if len(endKey) == 0 {
-		if bytes.Equal(key, bb.buf[idx].key) {
-			keys = append(keys, bb.buf[idx].key)
-			vals = append(vals, bb.buf[idx].val)
-		}
-		return keys, vals
-	}
-	if bytes.Compare(endKey, bb.buf[idx].key) <= 0 {
-		return nil, nil
-	}
-	for i := idx; i < bb.used && int64(len(keys)) < limit; i++ {
-		if bytes.Compare(endKey, bb.buf[i].key) <= 0 {
-			break
-		}
-		keys = append(keys, bb.buf[i].key)
-		vals = append(vals, bb.buf[i].val)
-	}
-	return keys, vals
-}
-
-func (bb *bucketBuffer) ForEach(visitor func(k, v []byte) error) error {
-	for i := 0; i < bb.used; i++ {
-		if err := visitor(bb.buf[i].key, bb.buf[i].val); err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-func (bb *bucketBuffer) add(k, v []byte) {
-	bb.buf[bb.used].key, bb.buf[bb.used].val = k, v
-	bb.used++
-	if bb.used == len(bb.buf) {
-		buf := make([]kv, (3*len(bb.buf))/2)
-		copy(buf, bb.buf)
-		bb.buf = buf
-	}
-}
-
-// merge merges data from bb into bbsrc.
-func (bb *bucketBuffer) merge(bbsrc *bucketBuffer) {
-	for i := 0; i < bbsrc.used; i++ {
-		bb.add(bbsrc.buf[i].key, bbsrc.buf[i].val)
-	}
-	if bb.used == bbsrc.used {
-		return
-	}
-	if bytes.Compare(bb.buf[(bb.used-bbsrc.used)-1].key, bbsrc.buf[0].key) < 0 {
-		return
-	}
-
-	sort.Stable(bb)
-
-	// remove duplicates, using only newest update
-	widx := 0
-	for ridx := 1; ridx < bb.used; ridx++ {
-		if !bytes.Equal(bb.buf[ridx].key, bb.buf[widx].key) {
-			widx++
-		}
-		bb.buf[widx] = bb.buf[ridx]
-	}
-	bb.used = widx + 1
-}
-
-func (bb *bucketBuffer) Len() int { return bb.used }
-func (bb *bucketBuffer) Less(i, j int) bool {
-	return bytes.Compare(bb.buf[i].key, bb.buf[j].key) < 0
-}
-func (bb *bucketBuffer) Swap(i, j int) { bb.buf[i], bb.buf[j] = bb.buf[j], bb.buf[i] }
diff --git a/mvcc/doc.go b/mvcc/doc.go
deleted file mode 100644
index ad5be03..0000000
--- a/mvcc/doc.go
+++ /dev/null
@@ -1,16 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-// Package mvcc defines etcd's stable MVCC storage.
-package mvcc
diff --git a/mvcc/index.go b/mvcc/index.go
deleted file mode 100644
index b27a9e5..0000000
--- a/mvcc/index.go
+++ /dev/null
@@ -1,251 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"sort"
-	"sync"
-
-	"github.com/google/btree"
-)
-
-type index interface {
-	Get(key []byte, atRev int64) (rev, created revision, ver int64, err error)
-	Range(key, end []byte, atRev int64) ([][]byte, []revision)
-	Revisions(key, end []byte, atRev int64) []revision
-	Put(key []byte, rev revision)
-	Tombstone(key []byte, rev revision) error
-	RangeSince(key, end []byte, rev int64) []revision
-	Compact(rev int64) map[revision]struct{}
-	Keep(rev int64) map[revision]struct{}
-	Equal(b index) bool
-
-	Insert(ki *keyIndex)
-	KeyIndex(ki *keyIndex) *keyIndex
-}
-
-type treeIndex struct {
-	sync.RWMutex
-	tree *btree.BTree
-}
-
-func newTreeIndex() index {
-	return &treeIndex{
-		tree: btree.New(32),
-	}
-}
-
-func (ti *treeIndex) Put(key []byte, rev revision) {
-	keyi := &keyIndex{key: key}
-
-	ti.Lock()
-	defer ti.Unlock()
-	item := ti.tree.Get(keyi)
-	if item == nil {
-		keyi.put(rev.main, rev.sub)
-		ti.tree.ReplaceOrInsert(keyi)
-		return
-	}
-	okeyi := item.(*keyIndex)
-	okeyi.put(rev.main, rev.sub)
-}
-
-func (ti *treeIndex) Get(key []byte, atRev int64) (modified, created revision, ver int64, err error) {
-	keyi := &keyIndex{key: key}
-	ti.RLock()
-	defer ti.RUnlock()
-	if keyi = ti.keyIndex(keyi); keyi == nil {
-		return revision{}, revision{}, 0, ErrRevisionNotFound
-	}
-	return keyi.get(atRev)
-}
-
-func (ti *treeIndex) KeyIndex(keyi *keyIndex) *keyIndex {
-	ti.RLock()
-	defer ti.RUnlock()
-	return ti.keyIndex(keyi)
-}
-
-func (ti *treeIndex) keyIndex(keyi *keyIndex) *keyIndex {
-	if item := ti.tree.Get(keyi); item != nil {
-		return item.(*keyIndex)
-	}
-	return nil
-}
-
-func (ti *treeIndex) visit(key, end []byte, f func(ki *keyIndex)) {
-	keyi, endi := &keyIndex{key: key}, &keyIndex{key: end}
-
-	ti.RLock()
-	defer ti.RUnlock()
-
-	ti.tree.AscendGreaterOrEqual(keyi, func(item btree.Item) bool {
-		if len(endi.key) > 0 && !item.Less(endi) {
-			return false
-		}
-		f(item.(*keyIndex))
-		return true
-	})
-}
-
-func (ti *treeIndex) Revisions(key, end []byte, atRev int64) (revs []revision) {
-	if end == nil {
-		rev, _, _, err := ti.Get(key, atRev)
-		if err != nil {
-			return nil
-		}
-		return []revision{rev}
-	}
-	ti.visit(key, end, func(ki *keyIndex) {
-		if rev, _, _, err := ki.get(atRev); err == nil {
-			revs = append(revs, rev)
-		}
-	})
-	return revs
-}
-
-func (ti *treeIndex) Range(key, end []byte, atRev int64) (keys [][]byte, revs []revision) {
-	if end == nil {
-		rev, _, _, err := ti.Get(key, atRev)
-		if err != nil {
-			return nil, nil
-		}
-		return [][]byte{key}, []revision{rev}
-	}
-	ti.visit(key, end, func(ki *keyIndex) {
-		if rev, _, _, err := ki.get(atRev); err == nil {
-			revs = append(revs, rev)
-			keys = append(keys, ki.key)
-		}
-	})
-	return keys, revs
-}
-
-func (ti *treeIndex) Tombstone(key []byte, rev revision) error {
-	keyi := &keyIndex{key: key}
-
-	ti.Lock()
-	defer ti.Unlock()
-	item := ti.tree.Get(keyi)
-	if item == nil {
-		return ErrRevisionNotFound
-	}
-
-	ki := item.(*keyIndex)
-	return ki.tombstone(rev.main, rev.sub)
-}
-
-// RangeSince returns all revisions from key(including) to end(excluding)
-// at or after the given rev. The returned slice is sorted in the order
-// of revision.
-func (ti *treeIndex) RangeSince(key, end []byte, rev int64) []revision {
-	keyi := &keyIndex{key: key}
-
-	ti.RLock()
-	defer ti.RUnlock()
-
-	if end == nil {
-		item := ti.tree.Get(keyi)
-		if item == nil {
-			return nil
-		}
-		keyi = item.(*keyIndex)
-		return keyi.since(rev)
-	}
-
-	endi := &keyIndex{key: end}
-	var revs []revision
-	ti.tree.AscendGreaterOrEqual(keyi, func(item btree.Item) bool {
-		if len(endi.key) > 0 && !item.Less(endi) {
-			return false
-		}
-		curKeyi := item.(*keyIndex)
-		revs = append(revs, curKeyi.since(rev)...)
-		return true
-	})
-	sort.Sort(revisions(revs))
-
-	return revs
-}
-
-func (ti *treeIndex) Compact(rev int64) map[revision]struct{} {
-	available := make(map[revision]struct{})
-	var emptyki []*keyIndex
-	plog.Printf("store.index: compact %d", rev)
-	// TODO: do not hold the lock for long time?
-	// This is probably OK. Compacting 10M keys takes O(10ms).
-	ti.Lock()
-	defer ti.Unlock()
-	ti.tree.Ascend(compactIndex(rev, available, &emptyki))
-	for _, ki := range emptyki {
-		item := ti.tree.Delete(ki)
-		if item == nil {
-			plog.Panic("store.index: unexpected delete failure during compaction")
-		}
-	}
-	return available
-}
-
-// Keep finds all revisions to be kept for a Compaction at the given rev.
-func (ti *treeIndex) Keep(rev int64) map[revision]struct{} {
-	available := make(map[revision]struct{})
-	ti.RLock()
-	defer ti.RUnlock()
-	ti.tree.Ascend(func(i btree.Item) bool {
-		keyi := i.(*keyIndex)
-		keyi.keep(rev, available)
-		return true
-	})
-	return available
-}
-
-func compactIndex(rev int64, available map[revision]struct{}, emptyki *[]*keyIndex) func(i btree.Item) bool {
-	return func(i btree.Item) bool {
-		keyi := i.(*keyIndex)
-		keyi.compact(rev, available)
-		if keyi.isEmpty() {
-			*emptyki = append(*emptyki, keyi)
-		}
-		return true
-	}
-}
-
-func (ti *treeIndex) Equal(bi index) bool {
-	b := bi.(*treeIndex)
-
-	if ti.tree.Len() != b.tree.Len() {
-		return false
-	}
-
-	equal := true
-
-	ti.tree.Ascend(func(item btree.Item) bool {
-		aki := item.(*keyIndex)
-		bki := b.tree.Get(item).(*keyIndex)
-		if !aki.equal(bki) {
-			equal = false
-			return false
-		}
-		return true
-	})
-
-	return equal
-}
-
-func (ti *treeIndex) Insert(ki *keyIndex) {
-	ti.Lock()
-	defer ti.Unlock()
-	ti.tree.ReplaceOrInsert(ki)
-}
diff --git a/mvcc/index_test.go b/mvcc/index_test.go
deleted file mode 100644
index d053156..0000000
--- a/mvcc/index_test.go
+++ /dev/null
@@ -1,292 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"reflect"
-	"testing"
-
-	"github.com/google/btree"
-)
-
-func TestIndexGet(t *testing.T) {
-	ti := newTreeIndex()
-	ti.Put([]byte("foo"), revision{main: 2})
-	ti.Put([]byte("foo"), revision{main: 4})
-	ti.Tombstone([]byte("foo"), revision{main: 6})
-
-	tests := []struct {
-		rev int64
-
-		wrev     revision
-		wcreated revision
-		wver     int64
-		werr     error
-	}{
-		{0, revision{}, revision{}, 0, ErrRevisionNotFound},
-		{1, revision{}, revision{}, 0, ErrRevisionNotFound},
-		{2, revision{main: 2}, revision{main: 2}, 1, nil},
-		{3, revision{main: 2}, revision{main: 2}, 1, nil},
-		{4, revision{main: 4}, revision{main: 2}, 2, nil},
-		{5, revision{main: 4}, revision{main: 2}, 2, nil},
-		{6, revision{}, revision{}, 0, ErrRevisionNotFound},
-	}
-	for i, tt := range tests {
-		rev, created, ver, err := ti.Get([]byte("foo"), tt.rev)
-		if err != tt.werr {
-			t.Errorf("#%d: err = %v, want %v", i, err, tt.werr)
-		}
-		if rev != tt.wrev {
-			t.Errorf("#%d: rev = %+v, want %+v", i, rev, tt.wrev)
-		}
-		if created != tt.wcreated {
-			t.Errorf("#%d: created = %+v, want %+v", i, created, tt.wcreated)
-		}
-		if ver != tt.wver {
-			t.Errorf("#%d: ver = %d, want %d", i, ver, tt.wver)
-		}
-	}
-}
-
-func TestIndexRange(t *testing.T) {
-	allKeys := [][]byte{[]byte("foo"), []byte("foo1"), []byte("foo2")}
-	allRevs := []revision{{main: 1}, {main: 2}, {main: 3}}
-
-	ti := newTreeIndex()
-	for i := range allKeys {
-		ti.Put(allKeys[i], allRevs[i])
-	}
-
-	atRev := int64(3)
-	tests := []struct {
-		key, end []byte
-		wkeys    [][]byte
-		wrevs    []revision
-	}{
-		// single key that not found
-		{
-			[]byte("bar"), nil, nil, nil,
-		},
-		// single key that found
-		{
-			[]byte("foo"), nil, allKeys[:1], allRevs[:1],
-		},
-		// range keys, return first member
-		{
-			[]byte("foo"), []byte("foo1"), allKeys[:1], allRevs[:1],
-		},
-		// range keys, return first two members
-		{
-			[]byte("foo"), []byte("foo2"), allKeys[:2], allRevs[:2],
-		},
-		// range keys, return all members
-		{
-			[]byte("foo"), []byte("fop"), allKeys, allRevs,
-		},
-		// range keys, return last two members
-		{
-			[]byte("foo1"), []byte("fop"), allKeys[1:], allRevs[1:],
-		},
-		// range keys, return last member
-		{
-			[]byte("foo2"), []byte("fop"), allKeys[2:], allRevs[2:],
-		},
-		// range keys, return nothing
-		{
-			[]byte("foo3"), []byte("fop"), nil, nil,
-		},
-	}
-	for i, tt := range tests {
-		keys, revs := ti.Range(tt.key, tt.end, atRev)
-		if !reflect.DeepEqual(keys, tt.wkeys) {
-			t.Errorf("#%d: keys = %+v, want %+v", i, keys, tt.wkeys)
-		}
-		if !reflect.DeepEqual(revs, tt.wrevs) {
-			t.Errorf("#%d: revs = %+v, want %+v", i, revs, tt.wrevs)
-		}
-	}
-}
-
-func TestIndexTombstone(t *testing.T) {
-	ti := newTreeIndex()
-	ti.Put([]byte("foo"), revision{main: 1})
-
-	err := ti.Tombstone([]byte("foo"), revision{main: 2})
-	if err != nil {
-		t.Errorf("tombstone error = %v, want nil", err)
-	}
-
-	_, _, _, err = ti.Get([]byte("foo"), 2)
-	if err != ErrRevisionNotFound {
-		t.Errorf("get error = %v, want nil", err)
-	}
-	err = ti.Tombstone([]byte("foo"), revision{main: 3})
-	if err != ErrRevisionNotFound {
-		t.Errorf("tombstone error = %v, want %v", err, ErrRevisionNotFound)
-	}
-}
-
-func TestIndexRangeSince(t *testing.T) {
-	allKeys := [][]byte{[]byte("foo"), []byte("foo1"), []byte("foo2"), []byte("foo2"), []byte("foo1"), []byte("foo")}
-	allRevs := []revision{{main: 1}, {main: 2}, {main: 3}, {main: 4}, {main: 5}, {main: 6}}
-
-	ti := newTreeIndex()
-	for i := range allKeys {
-		ti.Put(allKeys[i], allRevs[i])
-	}
-
-	atRev := int64(1)
-	tests := []struct {
-		key, end []byte
-		wrevs    []revision
-	}{
-		// single key that not found
-		{
-			[]byte("bar"), nil, nil,
-		},
-		// single key that found
-		{
-			[]byte("foo"), nil, []revision{{main: 1}, {main: 6}},
-		},
-		// range keys, return first member
-		{
-			[]byte("foo"), []byte("foo1"), []revision{{main: 1}, {main: 6}},
-		},
-		// range keys, return first two members
-		{
-			[]byte("foo"), []byte("foo2"), []revision{{main: 1}, {main: 2}, {main: 5}, {main: 6}},
-		},
-		// range keys, return all members
-		{
-			[]byte("foo"), []byte("fop"), allRevs,
-		},
-		// range keys, return last two members
-		{
-			[]byte("foo1"), []byte("fop"), []revision{{main: 2}, {main: 3}, {main: 4}, {main: 5}},
-		},
-		// range keys, return last member
-		{
-			[]byte("foo2"), []byte("fop"), []revision{{main: 3}, {main: 4}},
-		},
-		// range keys, return nothing
-		{
-			[]byte("foo3"), []byte("fop"), nil,
-		},
-	}
-	for i, tt := range tests {
-		revs := ti.RangeSince(tt.key, tt.end, atRev)
-		if !reflect.DeepEqual(revs, tt.wrevs) {
-			t.Errorf("#%d: revs = %+v, want %+v", i, revs, tt.wrevs)
-		}
-	}
-}
-
-func TestIndexCompactAndKeep(t *testing.T) {
-	maxRev := int64(20)
-	tests := []struct {
-		key     []byte
-		remove  bool
-		rev     revision
-		created revision
-		ver     int64
-	}{
-		{[]byte("foo"), false, revision{main: 1}, revision{main: 1}, 1},
-		{[]byte("foo1"), false, revision{main: 2}, revision{main: 2}, 1},
-		{[]byte("foo2"), false, revision{main: 3}, revision{main: 3}, 1},
-		{[]byte("foo2"), false, revision{main: 4}, revision{main: 3}, 2},
-		{[]byte("foo"), false, revision{main: 5}, revision{main: 1}, 2},
-		{[]byte("foo1"), false, revision{main: 6}, revision{main: 2}, 2},
-		{[]byte("foo1"), true, revision{main: 7}, revision{}, 0},
-		{[]byte("foo2"), true, revision{main: 8}, revision{}, 0},
-		{[]byte("foo"), true, revision{main: 9}, revision{}, 0},
-		{[]byte("foo"), false, revision{10, 0}, revision{10, 0}, 1},
-		{[]byte("foo1"), false, revision{10, 1}, revision{10, 1}, 1},
-	}
-
-	// Continuous Compact and Keep
-	ti := newTreeIndex()
-	for _, tt := range tests {
-		if tt.remove {
-			ti.Tombstone(tt.key, tt.rev)
-		} else {
-			ti.Put(tt.key, tt.rev)
-		}
-	}
-	for i := int64(1); i < maxRev; i++ {
-		am := ti.Compact(i)
-		keep := ti.Keep(i)
-		if !(reflect.DeepEqual(am, keep)) {
-			t.Errorf("#%d: compact keep %v != Keep keep %v", i, am, keep)
-		}
-		wti := &treeIndex{tree: btree.New(32)}
-		for _, tt := range tests {
-			if _, ok := am[tt.rev]; ok || tt.rev.GreaterThan(revision{main: i}) {
-				if tt.remove {
-					wti.Tombstone(tt.key, tt.rev)
-				} else {
-					restore(wti, tt.key, tt.created, tt.rev, tt.ver)
-				}
-			}
-		}
-		if !ti.Equal(wti) {
-			t.Errorf("#%d: not equal ti", i)
-		}
-	}
-
-	// Once Compact and Keep
-	for i := int64(1); i < maxRev; i++ {
-		ti := newTreeIndex()
-		for _, tt := range tests {
-			if tt.remove {
-				ti.Tombstone(tt.key, tt.rev)
-			} else {
-				ti.Put(tt.key, tt.rev)
-			}
-		}
-		am := ti.Compact(i)
-		keep := ti.Keep(i)
-		if !(reflect.DeepEqual(am, keep)) {
-			t.Errorf("#%d: compact keep %v != Keep keep %v", i, am, keep)
-		}
-		wti := &treeIndex{tree: btree.New(32)}
-		for _, tt := range tests {
-			if _, ok := am[tt.rev]; ok || tt.rev.GreaterThan(revision{main: i}) {
-				if tt.remove {
-					wti.Tombstone(tt.key, tt.rev)
-				} else {
-					restore(wti, tt.key, tt.created, tt.rev, tt.ver)
-				}
-			}
-		}
-		if !ti.Equal(wti) {
-			t.Errorf("#%d: not equal ti", i)
-		}
-	}
-}
-
-func restore(ti *treeIndex, key []byte, created, modified revision, ver int64) {
-	keyi := &keyIndex{key: key}
-
-	ti.Lock()
-	defer ti.Unlock()
-	item := ti.tree.Get(keyi)
-	if item == nil {
-		keyi.restore(created, modified, ver)
-		ti.tree.ReplaceOrInsert(keyi)
-		return
-	}
-	okeyi := item.(*keyIndex)
-	okeyi.put(modified.main, modified.sub)
-}
diff --git a/mvcc/key_index.go b/mvcc/key_index.go
deleted file mode 100644
index 805922b..0000000
--- a/mvcc/key_index.go
+++ /dev/null
@@ -1,356 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"bytes"
-	"errors"
-	"fmt"
-
-	"github.com/google/btree"
-)
-
-var (
-	ErrRevisionNotFound = errors.New("mvcc: revision not found")
-)
-
-// keyIndex stores the revisions of a key in the backend.
-// Each keyIndex has at least one key generation.
-// Each generation might have several key versions.
-// Tombstone on a key appends an tombstone version at the end
-// of the current generation and creates a new empty generation.
-// Each version of a key has an index pointing to the backend.
-//
-// For example: put(1.0);put(2.0);tombstone(3.0);put(4.0);tombstone(5.0) on key "foo"
-// generate a keyIndex:
-// key:     "foo"
-// rev: 5
-// generations:
-//    {empty}
-//    {4.0, 5.0(t)}
-//    {1.0, 2.0, 3.0(t)}
-//
-// Compact a keyIndex removes the versions with smaller or equal to
-// rev except the largest one. If the generation becomes empty
-// during compaction, it will be removed. if all the generations get
-// removed, the keyIndex should be removed.
-//
-// For example:
-// compact(2) on the previous example
-// generations:
-//    {empty}
-//    {4.0, 5.0(t)}
-//    {2.0, 3.0(t)}
-//
-// compact(4)
-// generations:
-//    {empty}
-//    {4.0, 5.0(t)}
-//
-// compact(5):
-// generations:
-//    {empty} -> key SHOULD be removed.
-//
-// compact(6):
-// generations:
-//    {empty} -> key SHOULD be removed.
-type keyIndex struct {
-	key         []byte
-	modified    revision // the main rev of the last modification
-	generations []generation
-}
-
-// put puts a revision to the keyIndex.
-func (ki *keyIndex) put(main int64, sub int64) {
-	rev := revision{main: main, sub: sub}
-
-	if !rev.GreaterThan(ki.modified) {
-		plog.Panicf("store.keyindex: put with unexpected smaller revision [%v / %v]", rev, ki.modified)
-	}
-	if len(ki.generations) == 0 {
-		ki.generations = append(ki.generations, generation{})
-	}
-	g := &ki.generations[len(ki.generations)-1]
-	if len(g.revs) == 0 { // create a new key
-		keysGauge.Inc()
-		g.created = rev
-	}
-	g.revs = append(g.revs, rev)
-	g.ver++
-	ki.modified = rev
-}
-
-func (ki *keyIndex) restore(created, modified revision, ver int64) {
-	if len(ki.generations) != 0 {
-		plog.Panicf("store.keyindex: cannot restore non-empty keyIndex")
-	}
-
-	ki.modified = modified
-	g := generation{created: created, ver: ver, revs: []revision{modified}}
-	ki.generations = append(ki.generations, g)
-	keysGauge.Inc()
-}
-
-// tombstone puts a revision, pointing to a tombstone, to the keyIndex.
-// It also creates a new empty generation in the keyIndex.
-// It returns ErrRevisionNotFound when tombstone on an empty generation.
-func (ki *keyIndex) tombstone(main int64, sub int64) error {
-	if ki.isEmpty() {
-		plog.Panicf("store.keyindex: unexpected tombstone on empty keyIndex %s", string(ki.key))
-	}
-	if ki.generations[len(ki.generations)-1].isEmpty() {
-		return ErrRevisionNotFound
-	}
-	ki.put(main, sub)
-	ki.generations = append(ki.generations, generation{})
-	keysGauge.Dec()
-	return nil
-}
-
-// get gets the modified, created revision and version of the key that satisfies the given atRev.
-// Rev must be higher than or equal to the given atRev.
-func (ki *keyIndex) get(atRev int64) (modified, created revision, ver int64, err error) {
-	if ki.isEmpty() {
-		plog.Panicf("store.keyindex: unexpected get on empty keyIndex %s", string(ki.key))
-	}
-	g := ki.findGeneration(atRev)
-	if g.isEmpty() {
-		return revision{}, revision{}, 0, ErrRevisionNotFound
-	}
-
-	n := g.walk(func(rev revision) bool { return rev.main > atRev })
-	if n != -1 {
-		return g.revs[n], g.created, g.ver - int64(len(g.revs)-n-1), nil
-	}
-
-	return revision{}, revision{}, 0, ErrRevisionNotFound
-}
-
-// since returns revisions since the given rev. Only the revision with the
-// largest sub revision will be returned if multiple revisions have the same
-// main revision.
-func (ki *keyIndex) since(rev int64) []revision {
-	if ki.isEmpty() {
-		plog.Panicf("store.keyindex: unexpected get on empty keyIndex %s", string(ki.key))
-	}
-	since := revision{rev, 0}
-	var gi int
-	// find the generations to start checking
-	for gi = len(ki.generations) - 1; gi > 0; gi-- {
-		g := ki.generations[gi]
-		if g.isEmpty() {
-			continue
-		}
-		if since.GreaterThan(g.created) {
-			break
-		}
-	}
-
-	var revs []revision
-	var last int64
-	for ; gi < len(ki.generations); gi++ {
-		for _, r := range ki.generations[gi].revs {
-			if since.GreaterThan(r) {
-				continue
-			}
-			if r.main == last {
-				// replace the revision with a new one that has higher sub value,
-				// because the original one should not be seen by external
-				revs[len(revs)-1] = r
-				continue
-			}
-			revs = append(revs, r)
-			last = r.main
-		}
-	}
-	return revs
-}
-
-// compact compacts a keyIndex by removing the versions with smaller or equal
-// revision than the given atRev except the largest one (If the largest one is
-// a tombstone, it will not be kept).
-// If a generation becomes empty during compaction, it will be removed.
-func (ki *keyIndex) compact(atRev int64, available map[revision]struct{}) {
-	if ki.isEmpty() {
-		plog.Panicf("store.keyindex: unexpected compact on empty keyIndex %s", string(ki.key))
-	}
-
-	genIdx, revIndex := ki.doCompact(atRev, available)
-
-	g := &ki.generations[genIdx]
-	if !g.isEmpty() {
-		// remove the previous contents.
-		if revIndex != -1 {
-			g.revs = g.revs[revIndex:]
-		}
-		// remove any tombstone
-		if len(g.revs) == 1 && genIdx != len(ki.generations)-1 {
-			delete(available, g.revs[0])
-			genIdx++
-		}
-	}
-
-	// remove the previous generations.
-	ki.generations = ki.generations[genIdx:]
-}
-
-// keep finds the revision to be kept if compact is called at given atRev.
-func (ki *keyIndex) keep(atRev int64, available map[revision]struct{}) {
-	if ki.isEmpty() {
-		return
-	}
-
-	genIdx, revIndex := ki.doCompact(atRev, available)
-	g := &ki.generations[genIdx]
-	if !g.isEmpty() {
-		// remove any tombstone
-		if revIndex == len(g.revs)-1 && genIdx != len(ki.generations)-1 {
-			delete(available, g.revs[revIndex])
-		}
-	}
-}
-
-func (ki *keyIndex) doCompact(atRev int64, available map[revision]struct{}) (genIdx int, revIndex int) {
-	// walk until reaching the first revision smaller or equal to "atRev",
-	// and add the revision to the available map
-	f := func(rev revision) bool {
-		if rev.main <= atRev {
-			available[rev] = struct{}{}
-			return false
-		}
-		return true
-	}
-
-	genIdx, g := 0, &ki.generations[0]
-	// find first generation includes atRev or created after atRev
-	for genIdx < len(ki.generations)-1 {
-		if tomb := g.revs[len(g.revs)-1].main; tomb > atRev {
-			break
-		}
-		genIdx++
-		g = &ki.generations[genIdx]
-	}
-
-	revIndex = g.walk(f)
-
-	return genIdx, revIndex
-}
-
-func (ki *keyIndex) isEmpty() bool {
-	return len(ki.generations) == 1 && ki.generations[0].isEmpty()
-}
-
-// findGeneration finds out the generation of the keyIndex that the
-// given rev belongs to. If the given rev is at the gap of two generations,
-// which means that the key does not exist at the given rev, it returns nil.
-func (ki *keyIndex) findGeneration(rev int64) *generation {
-	lastg := len(ki.generations) - 1
-	cg := lastg
-
-	for cg >= 0 {
-		if len(ki.generations[cg].revs) == 0 {
-			cg--
-			continue
-		}
-		g := ki.generations[cg]
-		if cg != lastg {
-			if tomb := g.revs[len(g.revs)-1].main; tomb <= rev {
-				return nil
-			}
-		}
-		if g.revs[0].main <= rev {
-			return &ki.generations[cg]
-		}
-		cg--
-	}
-	return nil
-}
-
-func (a *keyIndex) Less(b btree.Item) bool {
-	return bytes.Compare(a.key, b.(*keyIndex).key) == -1
-}
-
-func (a *keyIndex) equal(b *keyIndex) bool {
-	if !bytes.Equal(a.key, b.key) {
-		return false
-	}
-	if a.modified != b.modified {
-		return false
-	}
-	if len(a.generations) != len(b.generations) {
-		return false
-	}
-	for i := range a.generations {
-		ag, bg := a.generations[i], b.generations[i]
-		if !ag.equal(bg) {
-			return false
-		}
-	}
-	return true
-}
-
-func (ki *keyIndex) String() string {
-	var s string
-	for _, g := range ki.generations {
-		s += g.String()
-	}
-	return s
-}
-
-// generation contains multiple revisions of a key.
-type generation struct {
-	ver     int64
-	created revision // when the generation is created (put in first revision).
-	revs    []revision
-}
-
-func (g *generation) isEmpty() bool { return g == nil || len(g.revs) == 0 }
-
-// walk walks through the revisions in the generation in descending order.
-// It passes the revision to the given function.
-// walk returns until: 1. it finishes walking all pairs 2. the function returns false.
-// walk returns the position at where it stopped. If it stopped after
-// finishing walking, -1 will be returned.
-func (g *generation) walk(f func(rev revision) bool) int {
-	l := len(g.revs)
-	for i := range g.revs {
-		ok := f(g.revs[l-i-1])
-		if !ok {
-			return l - i - 1
-		}
-	}
-	return -1
-}
-
-func (g *generation) String() string {
-	return fmt.Sprintf("g: created[%d] ver[%d], revs %#v\n", g.created, g.ver, g.revs)
-}
-
-func (a generation) equal(b generation) bool {
-	if a.ver != b.ver {
-		return false
-	}
-	if len(a.revs) != len(b.revs) {
-		return false
-	}
-
-	for i := range a.revs {
-		ar, br := a.revs[i], b.revs[i]
-		if ar != br {
-			return false
-		}
-	}
-	return true
-}
diff --git a/mvcc/key_index_test.go b/mvcc/key_index_test.go
deleted file mode 100644
index 57e6a9c..0000000
--- a/mvcc/key_index_test.go
+++ /dev/null
@@ -1,698 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"reflect"
-	"testing"
-)
-
-func TestKeyIndexGet(t *testing.T) {
-	// key: "foo"
-	// rev: 16
-	// generations:
-	//    {empty}
-	//    {{14, 0}[1], {14, 1}[2], {16, 0}(t)[3]}
-	//    {{8, 0}[1], {10, 0}[2], {12, 0}(t)[3]}
-	//    {{2, 0}[1], {4, 0}[2], {6, 0}(t)[3]}
-	ki := newTestKeyIndex()
-	ki.compact(4, make(map[revision]struct{}))
-
-	tests := []struct {
-		rev int64
-
-		wmod   revision
-		wcreat revision
-		wver   int64
-		werr   error
-	}{
-		{17, revision{}, revision{}, 0, ErrRevisionNotFound},
-		{16, revision{}, revision{}, 0, ErrRevisionNotFound},
-
-		// get on generation 3
-		{15, revision{14, 1}, revision{14, 0}, 2, nil},
-		{14, revision{14, 1}, revision{14, 0}, 2, nil},
-
-		{13, revision{}, revision{}, 0, ErrRevisionNotFound},
-		{12, revision{}, revision{}, 0, ErrRevisionNotFound},
-
-		// get on generation 2
-		{11, revision{10, 0}, revision{8, 0}, 2, nil},
-		{10, revision{10, 0}, revision{8, 0}, 2, nil},
-		{9, revision{8, 0}, revision{8, 0}, 1, nil},
-		{8, revision{8, 0}, revision{8, 0}, 1, nil},
-
-		{7, revision{}, revision{}, 0, ErrRevisionNotFound},
-		{6, revision{}, revision{}, 0, ErrRevisionNotFound},
-
-		// get on generation 1
-		{5, revision{4, 0}, revision{2, 0}, 2, nil},
-		{4, revision{4, 0}, revision{2, 0}, 2, nil},
-
-		{3, revision{}, revision{}, 0, ErrRevisionNotFound},
-		{2, revision{}, revision{}, 0, ErrRevisionNotFound},
-		{1, revision{}, revision{}, 0, ErrRevisionNotFound},
-		{0, revision{}, revision{}, 0, ErrRevisionNotFound},
-	}
-
-	for i, tt := range tests {
-		mod, creat, ver, err := ki.get(tt.rev)
-		if err != tt.werr {
-			t.Errorf("#%d: err = %v, want %v", i, err, tt.werr)
-		}
-		if mod != tt.wmod {
-			t.Errorf("#%d: modified = %+v, want %+v", i, mod, tt.wmod)
-		}
-		if creat != tt.wcreat {
-			t.Errorf("#%d: created = %+v, want %+v", i, creat, tt.wcreat)
-		}
-		if ver != tt.wver {
-			t.Errorf("#%d: version = %d, want %d", i, ver, tt.wver)
-		}
-	}
-}
-
-func TestKeyIndexSince(t *testing.T) {
-	ki := newTestKeyIndex()
-	ki.compact(4, make(map[revision]struct{}))
-
-	allRevs := []revision{{4, 0}, {6, 0}, {8, 0}, {10, 0}, {12, 0}, {14, 1}, {16, 0}}
-	tests := []struct {
-		rev int64
-
-		wrevs []revision
-	}{
-		{17, nil},
-		{16, allRevs[6:]},
-		{15, allRevs[6:]},
-		{14, allRevs[5:]},
-		{13, allRevs[5:]},
-		{12, allRevs[4:]},
-		{11, allRevs[4:]},
-		{10, allRevs[3:]},
-		{9, allRevs[3:]},
-		{8, allRevs[2:]},
-		{7, allRevs[2:]},
-		{6, allRevs[1:]},
-		{5, allRevs[1:]},
-		{4, allRevs},
-		{3, allRevs},
-		{2, allRevs},
-		{1, allRevs},
-		{0, allRevs},
-	}
-
-	for i, tt := range tests {
-		revs := ki.since(tt.rev)
-		if !reflect.DeepEqual(revs, tt.wrevs) {
-			t.Errorf("#%d: revs = %+v, want %+v", i, revs, tt.wrevs)
-		}
-	}
-}
-
-func TestKeyIndexPut(t *testing.T) {
-	ki := &keyIndex{key: []byte("foo")}
-	ki.put(5, 0)
-
-	wki := &keyIndex{
-		key:         []byte("foo"),
-		modified:    revision{5, 0},
-		generations: []generation{{created: revision{5, 0}, ver: 1, revs: []revision{{main: 5}}}},
-	}
-	if !reflect.DeepEqual(ki, wki) {
-		t.Errorf("ki = %+v, want %+v", ki, wki)
-	}
-
-	ki.put(7, 0)
-
-	wki = &keyIndex{
-		key:         []byte("foo"),
-		modified:    revision{7, 0},
-		generations: []generation{{created: revision{5, 0}, ver: 2, revs: []revision{{main: 5}, {main: 7}}}},
-	}
-	if !reflect.DeepEqual(ki, wki) {
-		t.Errorf("ki = %+v, want %+v", ki, wki)
-	}
-}
-
-func TestKeyIndexRestore(t *testing.T) {
-	ki := &keyIndex{key: []byte("foo")}
-	ki.restore(revision{5, 0}, revision{7, 0}, 2)
-
-	wki := &keyIndex{
-		key:         []byte("foo"),
-		modified:    revision{7, 0},
-		generations: []generation{{created: revision{5, 0}, ver: 2, revs: []revision{{main: 7}}}},
-	}
-	if !reflect.DeepEqual(ki, wki) {
-		t.Errorf("ki = %+v, want %+v", ki, wki)
-	}
-}
-
-func TestKeyIndexTombstone(t *testing.T) {
-	ki := &keyIndex{key: []byte("foo")}
-	ki.put(5, 0)
-
-	err := ki.tombstone(7, 0)
-	if err != nil {
-		t.Errorf("unexpected tombstone error: %v", err)
-	}
-
-	wki := &keyIndex{
-		key:         []byte("foo"),
-		modified:    revision{7, 0},
-		generations: []generation{{created: revision{5, 0}, ver: 2, revs: []revision{{main: 5}, {main: 7}}}, {}},
-	}
-	if !reflect.DeepEqual(ki, wki) {
-		t.Errorf("ki = %+v, want %+v", ki, wki)
-	}
-
-	ki.put(8, 0)
-	ki.put(9, 0)
-	err = ki.tombstone(15, 0)
-	if err != nil {
-		t.Errorf("unexpected tombstone error: %v", err)
-	}
-
-	wki = &keyIndex{
-		key:      []byte("foo"),
-		modified: revision{15, 0},
-		generations: []generation{
-			{created: revision{5, 0}, ver: 2, revs: []revision{{main: 5}, {main: 7}}},
-			{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 9}, {main: 15}}},
-			{},
-		},
-	}
-	if !reflect.DeepEqual(ki, wki) {
-		t.Errorf("ki = %+v, want %+v", ki, wki)
-	}
-
-	err = ki.tombstone(16, 0)
-	if err != ErrRevisionNotFound {
-		t.Errorf("tombstone error = %v, want %v", err, ErrRevisionNotFound)
-	}
-}
-
-func TestKeyIndexCompactAndKeep(t *testing.T) {
-	tests := []struct {
-		compact int64
-
-		wki *keyIndex
-		wam map[revision]struct{}
-	}{
-		{
-			1,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 2}, {main: 4}, {main: 6}}},
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{},
-		},
-		{
-			2,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 2}, {main: 4}, {main: 6}}},
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 2}: {},
-			},
-		},
-		{
-			3,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 2}, {main: 4}, {main: 6}}},
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 2}: {},
-			},
-		},
-		{
-			4,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 4}, {main: 6}}},
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 4}: {},
-			},
-		},
-		{
-			5,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{2, 0}, ver: 3, revs: []revision{{main: 4}, {main: 6}}},
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 4}: {},
-			},
-		},
-		{
-			6,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{},
-		},
-		{
-			7,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{},
-		},
-		{
-			8,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 8}: {},
-			},
-		},
-		{
-			9,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 8}, {main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 8}: {},
-			},
-		},
-		{
-			10,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 10}: {},
-			},
-		},
-		{
-			11,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{8, 0}, ver: 3, revs: []revision{{main: 10}, {main: 12}}},
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 10}: {},
-			},
-		},
-		{
-			12,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{},
-		},
-		{
-			13,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14}, {main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{},
-		},
-		{
-			14,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 14, sub: 1}: {},
-			},
-		},
-		{
-			15,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{created: revision{14, 0}, ver: 3, revs: []revision{{main: 14, sub: 1}, {main: 16}}},
-					{},
-				},
-			},
-			map[revision]struct{}{
-				{main: 14, sub: 1}: {},
-			},
-		},
-		{
-			16,
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{16, 0},
-				generations: []generation{
-					{},
-				},
-			},
-			map[revision]struct{}{},
-		},
-	}
-
-	// Continuous Compaction and finding Keep
-	ki := newTestKeyIndex()
-	for i, tt := range tests {
-		am := make(map[revision]struct{})
-		kiclone := cloneKeyIndex(ki)
-		ki.keep(tt.compact, am)
-		if !reflect.DeepEqual(ki, kiclone) {
-			t.Errorf("#%d: ki = %+v, want %+v", i, ki, kiclone)
-		}
-		if !reflect.DeepEqual(am, tt.wam) {
-			t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
-		}
-		am = make(map[revision]struct{})
-		ki.compact(tt.compact, am)
-		if !reflect.DeepEqual(ki, tt.wki) {
-			t.Errorf("#%d: ki = %+v, want %+v", i, ki, tt.wki)
-		}
-		if !reflect.DeepEqual(am, tt.wam) {
-			t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
-		}
-	}
-
-	// Jump Compaction and finding Keep
-	ki = newTestKeyIndex()
-	for i, tt := range tests {
-		if (i%2 == 0 && i < 6) || (i%2 == 1 && i > 6) {
-			am := make(map[revision]struct{})
-			kiclone := cloneKeyIndex(ki)
-			ki.keep(tt.compact, am)
-			if !reflect.DeepEqual(ki, kiclone) {
-				t.Errorf("#%d: ki = %+v, want %+v", i, ki, kiclone)
-			}
-			if !reflect.DeepEqual(am, tt.wam) {
-				t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
-			}
-			am = make(map[revision]struct{})
-			ki.compact(tt.compact, am)
-			if !reflect.DeepEqual(ki, tt.wki) {
-				t.Errorf("#%d: ki = %+v, want %+v", i, ki, tt.wki)
-			}
-			if !reflect.DeepEqual(am, tt.wam) {
-				t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
-			}
-		}
-	}
-
-	kiClone := newTestKeyIndex()
-	// Once Compaction and finding Keep
-	for i, tt := range tests {
-		ki := newTestKeyIndex()
-		am := make(map[revision]struct{})
-		ki.keep(tt.compact, am)
-		if !reflect.DeepEqual(ki, kiClone) {
-			t.Errorf("#%d: ki = %+v, want %+v", i, ki, kiClone)
-		}
-		if !reflect.DeepEqual(am, tt.wam) {
-			t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
-		}
-		am = make(map[revision]struct{})
-		ki.compact(tt.compact, am)
-		if !reflect.DeepEqual(ki, tt.wki) {
-			t.Errorf("#%d: ki = %+v, want %+v", i, ki, tt.wki)
-		}
-		if !reflect.DeepEqual(am, tt.wam) {
-			t.Errorf("#%d: am = %+v, want %+v", i, am, tt.wam)
-		}
-	}
-}
-
-func cloneKeyIndex(ki *keyIndex) *keyIndex {
-	generations := make([]generation, len(ki.generations))
-	for i, gen := range ki.generations {
-		generations[i] = *cloneGeneration(&gen)
-	}
-	return &keyIndex{ki.key, ki.modified, generations}
-}
-
-func cloneGeneration(g *generation) *generation {
-	if g.revs == nil {
-		return &generation{g.ver, g.created, nil}
-	}
-	tmp := make([]revision, len(g.revs))
-	copy(tmp, g.revs)
-	return &generation{g.ver, g.created, tmp}
-}
-
-// test that compact on version that higher than last modified version works well
-func TestKeyIndexCompactOnFurtherRev(t *testing.T) {
-	ki := &keyIndex{key: []byte("foo")}
-	ki.put(1, 0)
-	ki.put(2, 0)
-	am := make(map[revision]struct{})
-	ki.compact(3, am)
-
-	wki := &keyIndex{
-		key:      []byte("foo"),
-		modified: revision{2, 0},
-		generations: []generation{
-			{created: revision{1, 0}, ver: 2, revs: []revision{{main: 2}}},
-		},
-	}
-	wam := map[revision]struct{}{
-		{main: 2}: {},
-	}
-	if !reflect.DeepEqual(ki, wki) {
-		t.Errorf("ki = %+v, want %+v", ki, wki)
-	}
-	if !reflect.DeepEqual(am, wam) {
-		t.Errorf("am = %+v, want %+v", am, wam)
-	}
-}
-
-func TestKeyIndexIsEmpty(t *testing.T) {
-	tests := []struct {
-		ki *keyIndex
-		w  bool
-	}{
-		{
-			&keyIndex{
-				key:         []byte("foo"),
-				generations: []generation{{}},
-			},
-			true,
-		},
-		{
-			&keyIndex{
-				key:      []byte("foo"),
-				modified: revision{2, 0},
-				generations: []generation{
-					{created: revision{1, 0}, ver: 2, revs: []revision{{main: 2}}},
-				},
-			},
-			false,
-		},
-	}
-	for i, tt := range tests {
-		g := tt.ki.isEmpty()
-		if g != tt.w {
-			t.Errorf("#%d: isEmpty = %v, want %v", i, g, tt.w)
-		}
-	}
-}
-
-func TestKeyIndexFindGeneration(t *testing.T) {
-	ki := newTestKeyIndex()
-
-	tests := []struct {
-		rev int64
-		wg  *generation
-	}{
-		{0, nil},
-		{1, nil},
-		{2, &ki.generations[0]},
-		{3, &ki.generations[0]},
-		{4, &ki.generations[0]},
-		{5, &ki.generations[0]},
-		{6, nil},
-		{7, nil},
-		{8, &ki.generations[1]},
-		{9, &ki.generations[1]},
-		{10, &ki.generations[1]},
-		{11, &ki.generations[1]},
-		{12, nil},
-		{13, nil},
-	}
-	for i, tt := range tests {
-		g := ki.findGeneration(tt.rev)
-		if g != tt.wg {
-			t.Errorf("#%d: generation = %+v, want %+v", i, g, tt.wg)
-		}
-	}
-}
-
-func TestKeyIndexLess(t *testing.T) {
-	ki := &keyIndex{key: []byte("foo")}
-
-	tests := []struct {
-		ki *keyIndex
-		w  bool
-	}{
-		{&keyIndex{key: []byte("doo")}, false},
-		{&keyIndex{key: []byte("foo")}, false},
-		{&keyIndex{key: []byte("goo")}, true},
-	}
-	for i, tt := range tests {
-		g := ki.Less(tt.ki)
-		if g != tt.w {
-			t.Errorf("#%d: Less = %v, want %v", i, g, tt.w)
-		}
-	}
-}
-
-func TestGenerationIsEmpty(t *testing.T) {
-	tests := []struct {
-		g *generation
-		w bool
-	}{
-		{nil, true},
-		{&generation{}, true},
-		{&generation{revs: []revision{{main: 1}}}, false},
-	}
-	for i, tt := range tests {
-		g := tt.g.isEmpty()
-		if g != tt.w {
-			t.Errorf("#%d: isEmpty = %v, want %v", i, g, tt.w)
-		}
-	}
-}
-
-func TestGenerationWalk(t *testing.T) {
-	g := &generation{
-		ver:     3,
-		created: revision{2, 0},
-		revs:    []revision{{main: 2}, {main: 4}, {main: 6}},
-	}
-	tests := []struct {
-		f  func(rev revision) bool
-		wi int
-	}{
-		{func(rev revision) bool { return rev.main >= 7 }, 2},
-		{func(rev revision) bool { return rev.main >= 6 }, 1},
-		{func(rev revision) bool { return rev.main >= 5 }, 1},
-		{func(rev revision) bool { return rev.main >= 4 }, 0},
-		{func(rev revision) bool { return rev.main >= 3 }, 0},
-		{func(rev revision) bool { return rev.main >= 2 }, -1},
-	}
-	for i, tt := range tests {
-		idx := g.walk(tt.f)
-		if idx != tt.wi {
-			t.Errorf("#%d: index = %d, want %d", i, idx, tt.wi)
-		}
-	}
-}
-
-func newTestKeyIndex() *keyIndex {
-	// key: "foo"
-	// rev: 16
-	// generations:
-	//    {empty}
-	//    {{14, 0}[1], {14, 1}[2], {16, 0}(t)[3]}
-	//    {{8, 0}[1], {10, 0}[2], {12, 0}(t)[3]}
-	//    {{2, 0}[1], {4, 0}[2], {6, 0}(t)[3]}
-
-	ki := &keyIndex{key: []byte("foo")}
-	ki.put(2, 0)
-	ki.put(4, 0)
-	ki.tombstone(6, 0)
-	ki.put(8, 0)
-	ki.put(10, 0)
-	ki.tombstone(12, 0)
-	ki.put(14, 0)
-	ki.put(14, 1)
-	ki.tombstone(16, 0)
-	return ki
-}
diff --git a/mvcc/kv.go b/mvcc/kv.go
deleted file mode 100644
index b149eb5..0000000
--- a/mvcc/kv.go
+++ /dev/null
@@ -1,149 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
-)
-
-type RangeOptions struct {
-	Limit int64
-	Rev   int64
-	Count bool
-}
-
-type RangeResult struct {
-	KVs   []mvccpb.KeyValue
-	Rev   int64
-	Count int
-}
-
-type ReadView interface {
-	// FirstRev returns the first KV revision at the time of opening the txn.
-	// After a compaction, the first revision increases to the compaction
-	// revision.
-	FirstRev() int64
-
-	// Rev returns the revision of the KV at the time of opening the txn.
-	Rev() int64
-
-	// Range gets the keys in the range at rangeRev.
-	// The returned rev is the current revision of the KV when the operation is executed.
-	// If rangeRev <=0, range gets the keys at currentRev.
-	// If `end` is nil, the request returns the key.
-	// If `end` is not nil and not empty, it gets the keys in range [key, range_end).
-	// If `end` is not nil and empty, it gets the keys greater than or equal to key.
-	// Limit limits the number of keys returned.
-	// If the required rev is compacted, ErrCompacted will be returned.
-	Range(key, end []byte, ro RangeOptions) (r *RangeResult, err error)
-}
-
-// TxnRead represents a read-only transaction with operations that will not
-// block other read transactions.
-type TxnRead interface {
-	ReadView
-	// End marks the transaction is complete and ready to commit.
-	End()
-}
-
-type WriteView interface {
-	// DeleteRange deletes the given range from the store.
-	// A deleteRange increases the rev of the store if any key in the range exists.
-	// The number of key deleted will be returned.
-	// The returned rev is the current revision of the KV when the operation is executed.
-	// It also generates one event for each key delete in the event history.
-	// if the `end` is nil, deleteRange deletes the key.
-	// if the `end` is not nil, deleteRange deletes the keys in range [key, range_end).
-	DeleteRange(key, end []byte) (n, rev int64)
-
-	// Put puts the given key, value into the store. Put also takes additional argument lease to
-	// attach a lease to a key-value pair as meta-data. KV implementation does not validate the lease
-	// id.
-	// A put also increases the rev of the store, and generates one event in the event history.
-	// The returned rev is the current revision of the KV when the operation is executed.
-	Put(key, value []byte, lease lease.LeaseID) (rev int64)
-}
-
-// TxnWrite represents a transaction that can modify the store.
-type TxnWrite interface {
-	TxnRead
-	WriteView
-	// Changes gets the changes made since opening the write txn.
-	Changes() []mvccpb.KeyValue
-}
-
-// txnReadWrite coerces a read txn to a write, panicking on any write operation.
-type txnReadWrite struct{ TxnRead }
-
-func (trw *txnReadWrite) DeleteRange(key, end []byte) (n, rev int64) { panic("unexpected DeleteRange") }
-func (trw *txnReadWrite) Put(key, value []byte, lease lease.LeaseID) (rev int64) {
-	panic("unexpected Put")
-}
-func (trw *txnReadWrite) Changes() []mvccpb.KeyValue { return nil }
-
-func NewReadOnlyTxnWrite(txn TxnRead) TxnWrite { return &txnReadWrite{txn} }
-
-type KV interface {
-	ReadView
-	WriteView
-
-	// Read creates a read transaction.
-	Read() TxnRead
-
-	// Write creates a write transaction.
-	Write() TxnWrite
-
-	// Hash computes the hash of the KV's backend.
-	Hash() (hash uint32, revision int64, err error)
-
-	// HashByRev computes the hash of all MVCC revisions up to a given revision.
-	HashByRev(rev int64) (hash uint32, revision int64, compactRev int64, err error)
-
-	// Compact frees all superseded keys with revisions less than rev.
-	Compact(rev int64) (<-chan struct{}, error)
-
-	// Commit commits outstanding txns into the underlying backend.
-	Commit()
-
-	// Restore restores the KV store from a backend.
-	Restore(b backend.Backend) error
-	Close() error
-}
-
-// WatchableKV is a KV that can be watched.
-type WatchableKV interface {
-	KV
-	Watchable
-}
-
-// Watchable is the interface that wraps the NewWatchStream function.
-type Watchable interface {
-	// NewWatchStream returns a WatchStream that can be used to
-	// watch events happened or happening on the KV.
-	NewWatchStream() WatchStream
-}
-
-// ConsistentWatchableKV is a WatchableKV that understands the consistency
-// algorithm and consistent index.
-// If the consistent index of executing entry is not larger than the
-// consistent index of ConsistentWatchableKV, all operations in
-// this entry are skipped and return empty response.
-type ConsistentWatchableKV interface {
-	WatchableKV
-	// ConsistentIndex returns the current consistent index of the KV.
-	ConsistentIndex() uint64
-}
diff --git a/mvcc/kv_test.go b/mvcc/kv_test.go
deleted file mode 100644
index 0728974..0000000
--- a/mvcc/kv_test.go
+++ /dev/null
@@ -1,831 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"fmt"
-	"os"
-	"reflect"
-	"testing"
-	"time"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
-	"github.com/coreos/etcd/pkg/testutil"
-
-	"github.com/prometheus/client_golang/prometheus"
-	dto "github.com/prometheus/client_model/go"
-)
-
-// Functional tests for features implemented in v3 store. It treats v3 store
-// as a black box, and tests it by feeding the input and validating the output.
-
-// TODO: add similar tests on operations in one txn/rev
-
-type (
-	rangeFunc       func(kv KV, key, end []byte, ro RangeOptions) (*RangeResult, error)
-	putFunc         func(kv KV, key, value []byte, lease lease.LeaseID) int64
-	deleteRangeFunc func(kv KV, key, end []byte) (n, rev int64)
-)
-
-var (
-	normalRangeFunc = func(kv KV, key, end []byte, ro RangeOptions) (*RangeResult, error) {
-		return kv.Range(key, end, ro)
-	}
-	txnRangeFunc = func(kv KV, key, end []byte, ro RangeOptions) (*RangeResult, error) {
-		txn := kv.Read()
-		defer txn.End()
-		return txn.Range(key, end, ro)
-	}
-
-	normalPutFunc = func(kv KV, key, value []byte, lease lease.LeaseID) int64 {
-		return kv.Put(key, value, lease)
-	}
-	txnPutFunc = func(kv KV, key, value []byte, lease lease.LeaseID) int64 {
-		txn := kv.Write()
-		defer txn.End()
-		return txn.Put(key, value, lease)
-	}
-
-	normalDeleteRangeFunc = func(kv KV, key, end []byte) (n, rev int64) {
-		return kv.DeleteRange(key, end)
-	}
-	txnDeleteRangeFunc = func(kv KV, key, end []byte) (n, rev int64) {
-		txn := kv.Write()
-		defer txn.End()
-		return txn.DeleteRange(key, end)
-	}
-)
-
-func TestKVRange(t *testing.T)    { testKVRange(t, normalRangeFunc) }
-func TestKVTxnRange(t *testing.T) { testKVRange(t, txnRangeFunc) }
-
-func testKVRange(t *testing.T, f rangeFunc) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	kvs := put3TestKVs(s)
-
-	wrev := int64(4)
-	tests := []struct {
-		key, end []byte
-		wkvs     []mvccpb.KeyValue
-	}{
-		// get no keys
-		{
-			[]byte("doo"), []byte("foo"),
-			nil,
-		},
-		// get no keys when key == end
-		{
-			[]byte("foo"), []byte("foo"),
-			nil,
-		},
-		// get no keys when ranging single key
-		{
-			[]byte("doo"), nil,
-			nil,
-		},
-		// get all keys
-		{
-			[]byte("foo"), []byte("foo3"),
-			kvs,
-		},
-		// get partial keys
-		{
-			[]byte("foo"), []byte("foo1"),
-			kvs[:1],
-		},
-		// get single key
-		{
-			[]byte("foo"), nil,
-			kvs[:1],
-		},
-		// get entire keyspace
-		{
-			[]byte(""), []byte(""),
-			kvs,
-		},
-	}
-
-	for i, tt := range tests {
-		r, err := f(s, tt.key, tt.end, RangeOptions{})
-		if err != nil {
-			t.Fatal(err)
-		}
-		if r.Rev != wrev {
-			t.Errorf("#%d: rev = %d, want %d", i, r.Rev, wrev)
-		}
-		if !reflect.DeepEqual(r.KVs, tt.wkvs) {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, tt.wkvs)
-		}
-	}
-}
-
-func TestKVRangeRev(t *testing.T)    { testKVRangeRev(t, normalRangeFunc) }
-func TestKVTxnRangeRev(t *testing.T) { testKVRangeRev(t, txnRangeFunc) }
-
-func testKVRangeRev(t *testing.T, f rangeFunc) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	kvs := put3TestKVs(s)
-
-	tests := []struct {
-		rev  int64
-		wrev int64
-		wkvs []mvccpb.KeyValue
-	}{
-		{-1, 4, kvs},
-		{0, 4, kvs},
-		{2, 4, kvs[:1]},
-		{3, 4, kvs[:2]},
-		{4, 4, kvs},
-	}
-
-	for i, tt := range tests {
-		r, err := f(s, []byte("foo"), []byte("foo3"), RangeOptions{Rev: tt.rev})
-		if err != nil {
-			t.Fatal(err)
-		}
-		if r.Rev != tt.wrev {
-			t.Errorf("#%d: rev = %d, want %d", i, r.Rev, tt.wrev)
-		}
-		if !reflect.DeepEqual(r.KVs, tt.wkvs) {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, tt.wkvs)
-		}
-	}
-}
-
-func TestKVRangeBadRev(t *testing.T)    { testKVRangeBadRev(t, normalRangeFunc) }
-func TestKVTxnRangeBadRev(t *testing.T) { testKVRangeBadRev(t, txnRangeFunc) }
-
-func testKVRangeBadRev(t *testing.T, f rangeFunc) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	put3TestKVs(s)
-	if _, err := s.Compact(4); err != nil {
-		t.Fatalf("compact error (%v)", err)
-	}
-
-	tests := []struct {
-		rev  int64
-		werr error
-	}{
-		{-1, nil}, // <= 0 is most recent store
-		{0, nil},
-		{1, ErrCompacted},
-		{2, ErrCompacted},
-		{4, nil},
-		{5, ErrFutureRev},
-		{100, ErrFutureRev},
-	}
-	for i, tt := range tests {
-		_, err := f(s, []byte("foo"), []byte("foo3"), RangeOptions{Rev: tt.rev})
-		if err != tt.werr {
-			t.Errorf("#%d: error = %v, want %v", i, err, tt.werr)
-		}
-	}
-}
-
-func TestKVRangeLimit(t *testing.T)    { testKVRangeLimit(t, normalRangeFunc) }
-func TestKVTxnRangeLimit(t *testing.T) { testKVRangeLimit(t, txnRangeFunc) }
-
-func testKVRangeLimit(t *testing.T, f rangeFunc) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	kvs := put3TestKVs(s)
-
-	wrev := int64(4)
-	tests := []struct {
-		limit int64
-		wkvs  []mvccpb.KeyValue
-	}{
-		// no limit
-		{-1, kvs},
-		// no limit
-		{0, kvs},
-		{1, kvs[:1]},
-		{2, kvs[:2]},
-		{3, kvs},
-		{100, kvs},
-	}
-	for i, tt := range tests {
-		r, err := f(s, []byte("foo"), []byte("foo3"), RangeOptions{Limit: tt.limit})
-		if err != nil {
-			t.Fatalf("#%d: range error (%v)", i, err)
-		}
-		if !reflect.DeepEqual(r.KVs, tt.wkvs) {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, tt.wkvs)
-		}
-		if r.Rev != wrev {
-			t.Errorf("#%d: rev = %d, want %d", i, r.Rev, wrev)
-		}
-		if r.Count != len(kvs) {
-			t.Errorf("#%d: count = %d, want %d", i, r.Count, len(kvs))
-		}
-	}
-}
-
-func TestKVPutMultipleTimes(t *testing.T)    { testKVPutMultipleTimes(t, normalPutFunc) }
-func TestKVTxnPutMultipleTimes(t *testing.T) { testKVPutMultipleTimes(t, txnPutFunc) }
-
-func testKVPutMultipleTimes(t *testing.T, f putFunc) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	for i := 0; i < 10; i++ {
-		base := int64(i + 1)
-
-		rev := f(s, []byte("foo"), []byte("bar"), lease.LeaseID(base))
-		if rev != base+1 {
-			t.Errorf("#%d: rev = %d, want %d", i, rev, base+1)
-		}
-
-		r, err := s.Range([]byte("foo"), nil, RangeOptions{})
-		if err != nil {
-			t.Fatal(err)
-		}
-		wkvs := []mvccpb.KeyValue{
-			{Key: []byte("foo"), Value: []byte("bar"), CreateRevision: 2, ModRevision: base + 1, Version: base, Lease: base},
-		}
-		if !reflect.DeepEqual(r.KVs, wkvs) {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, wkvs)
-		}
-	}
-}
-
-func TestKVDeleteRange(t *testing.T)    { testKVDeleteRange(t, normalDeleteRangeFunc) }
-func TestKVTxnDeleteRange(t *testing.T) { testKVDeleteRange(t, txnDeleteRangeFunc) }
-
-func testKVDeleteRange(t *testing.T, f deleteRangeFunc) {
-	tests := []struct {
-		key, end []byte
-
-		wrev int64
-		wN   int64
-	}{
-		{
-			[]byte("foo"), nil,
-			5, 1,
-		},
-		{
-			[]byte("foo"), []byte("foo1"),
-			5, 1,
-		},
-		{
-			[]byte("foo"), []byte("foo2"),
-			5, 2,
-		},
-		{
-			[]byte("foo"), []byte("foo3"),
-			5, 3,
-		},
-		{
-			[]byte("foo3"), []byte("foo8"),
-			4, 0,
-		},
-		{
-			[]byte("foo3"), nil,
-			4, 0,
-		},
-	}
-
-	for i, tt := range tests {
-		b, tmpPath := backend.NewDefaultTmpBackend()
-		s := NewStore(b, &lease.FakeLessor{}, nil)
-
-		s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
-		s.Put([]byte("foo1"), []byte("bar1"), lease.NoLease)
-		s.Put([]byte("foo2"), []byte("bar2"), lease.NoLease)
-
-		n, rev := f(s, tt.key, tt.end)
-		if n != tt.wN || rev != tt.wrev {
-			t.Errorf("#%d: n = %d, rev = %d, want (%d, %d)", i, n, rev, tt.wN, tt.wrev)
-		}
-
-		cleanup(s, b, tmpPath)
-	}
-}
-
-func TestKVDeleteMultipleTimes(t *testing.T)    { testKVDeleteMultipleTimes(t, normalDeleteRangeFunc) }
-func TestKVTxnDeleteMultipleTimes(t *testing.T) { testKVDeleteMultipleTimes(t, txnDeleteRangeFunc) }
-
-func testKVDeleteMultipleTimes(t *testing.T, f deleteRangeFunc) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
-
-	n, rev := f(s, []byte("foo"), nil)
-	if n != 1 || rev != 3 {
-		t.Fatalf("n = %d, rev = %d, want (%d, %d)", n, rev, 1, 3)
-	}
-
-	for i := 0; i < 10; i++ {
-		n, rev := f(s, []byte("foo"), nil)
-		if n != 0 || rev != 3 {
-			t.Fatalf("#%d: n = %d, rev = %d, want (%d, %d)", i, n, rev, 0, 3)
-		}
-	}
-}
-
-// test that range, put, delete on single key in sequence repeatedly works correctly.
-func TestKVOperationInSequence(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	for i := 0; i < 10; i++ {
-		base := int64(i*2 + 1)
-
-		// put foo
-		rev := s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
-		if rev != base+1 {
-			t.Errorf("#%d: put rev = %d, want %d", i, rev, base+1)
-		}
-
-		r, err := s.Range([]byte("foo"), nil, RangeOptions{Rev: base + 1})
-		if err != nil {
-			t.Fatal(err)
-		}
-		wkvs := []mvccpb.KeyValue{
-			{Key: []byte("foo"), Value: []byte("bar"), CreateRevision: base + 1, ModRevision: base + 1, Version: 1, Lease: int64(lease.NoLease)},
-		}
-		if !reflect.DeepEqual(r.KVs, wkvs) {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, wkvs)
-		}
-		if r.Rev != base+1 {
-			t.Errorf("#%d: range rev = %d, want %d", i, rev, base+1)
-		}
-
-		// delete foo
-		n, rev := s.DeleteRange([]byte("foo"), nil)
-		if n != 1 || rev != base+2 {
-			t.Errorf("#%d: n = %d, rev = %d, want (%d, %d)", i, n, rev, 1, base+2)
-		}
-
-		r, err = s.Range([]byte("foo"), nil, RangeOptions{Rev: base + 2})
-		if err != nil {
-			t.Fatal(err)
-		}
-		if r.KVs != nil {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, nil)
-		}
-		if r.Rev != base+2 {
-			t.Errorf("#%d: range rev = %d, want %d", i, r.Rev, base+2)
-		}
-	}
-}
-
-func TestKVTxnBlockWriteOperations(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-
-	tests := []func(){
-		func() { s.Put([]byte("foo"), nil, lease.NoLease) },
-		func() { s.DeleteRange([]byte("foo"), nil) },
-	}
-	for i, tt := range tests {
-		txn := s.Write()
-		done := make(chan struct{}, 1)
-		go func() {
-			tt()
-			done <- struct{}{}
-		}()
-		select {
-		case <-done:
-			t.Fatalf("#%d: operation failed to be blocked", i)
-		case <-time.After(10 * time.Millisecond):
-		}
-
-		txn.End()
-		select {
-		case <-done:
-		case <-time.After(10 * time.Second):
-			testutil.FatalStack(t, fmt.Sprintf("#%d: operation failed to be unblocked", i))
-		}
-	}
-
-	// only close backend when we know all the tx are finished
-	cleanup(s, b, tmpPath)
-}
-
-func TestKVTxnNonBlockRange(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	txn := s.Write()
-	defer txn.End()
-
-	donec := make(chan struct{})
-	go func() {
-		defer close(donec)
-		s.Range([]byte("foo"), nil, RangeOptions{})
-	}()
-	select {
-	case <-donec:
-	case <-time.After(100 * time.Millisecond):
-		t.Fatalf("range operation blocked on write txn")
-	}
-}
-
-// test that txn range, put, delete on single key in sequence repeatedly works correctly.
-func TestKVTxnOperationInSequence(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	for i := 0; i < 10; i++ {
-		txn := s.Write()
-		base := int64(i + 1)
-
-		// put foo
-		rev := txn.Put([]byte("foo"), []byte("bar"), lease.NoLease)
-		if rev != base+1 {
-			t.Errorf("#%d: put rev = %d, want %d", i, rev, base+1)
-		}
-
-		r, err := txn.Range([]byte("foo"), nil, RangeOptions{Rev: base + 1})
-		if err != nil {
-			t.Fatal(err)
-		}
-		wkvs := []mvccpb.KeyValue{
-			{Key: []byte("foo"), Value: []byte("bar"), CreateRevision: base + 1, ModRevision: base + 1, Version: 1, Lease: int64(lease.NoLease)},
-		}
-		if !reflect.DeepEqual(r.KVs, wkvs) {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, wkvs)
-		}
-		if r.Rev != base+1 {
-			t.Errorf("#%d: range rev = %d, want %d", i, r.Rev, base+1)
-		}
-
-		// delete foo
-		n, rev := txn.DeleteRange([]byte("foo"), nil)
-		if n != 1 || rev != base+1 {
-			t.Errorf("#%d: n = %d, rev = %d, want (%d, %d)", i, n, rev, 1, base+1)
-		}
-
-		r, err = txn.Range([]byte("foo"), nil, RangeOptions{Rev: base + 1})
-		if err != nil {
-			t.Errorf("#%d: range error (%v)", i, err)
-		}
-		if r.KVs != nil {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, nil)
-		}
-		if r.Rev != base+1 {
-			t.Errorf("#%d: range rev = %d, want %d", i, r.Rev, base+1)
-		}
-
-		txn.End()
-	}
-}
-
-func TestKVCompactReserveLastValue(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	s.Put([]byte("foo"), []byte("bar0"), 1)
-	s.Put([]byte("foo"), []byte("bar1"), 2)
-	s.DeleteRange([]byte("foo"), nil)
-	s.Put([]byte("foo"), []byte("bar2"), 3)
-
-	// rev in tests will be called in Compact() one by one on the same store
-	tests := []struct {
-		rev int64
-		// wanted kvs right after the compacted rev
-		wkvs []mvccpb.KeyValue
-	}{
-		{
-			1,
-			[]mvccpb.KeyValue{
-				{Key: []byte("foo"), Value: []byte("bar0"), CreateRevision: 2, ModRevision: 2, Version: 1, Lease: 1},
-			},
-		},
-		{
-			2,
-			[]mvccpb.KeyValue{
-				{Key: []byte("foo"), Value: []byte("bar1"), CreateRevision: 2, ModRevision: 3, Version: 2, Lease: 2},
-			},
-		},
-		{
-			3,
-			nil,
-		},
-		{
-			4,
-			[]mvccpb.KeyValue{
-				{Key: []byte("foo"), Value: []byte("bar2"), CreateRevision: 5, ModRevision: 5, Version: 1, Lease: 3},
-			},
-		},
-	}
-	for i, tt := range tests {
-		_, err := s.Compact(tt.rev)
-		if err != nil {
-			t.Errorf("#%d: unexpect compact error %v", i, err)
-		}
-		r, err := s.Range([]byte("foo"), nil, RangeOptions{Rev: tt.rev + 1})
-		if err != nil {
-			t.Errorf("#%d: unexpect range error %v", i, err)
-		}
-		if !reflect.DeepEqual(r.KVs, tt.wkvs) {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, r.KVs, tt.wkvs)
-		}
-	}
-}
-
-func TestKVCompactBad(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	s.Put([]byte("foo"), []byte("bar0"), lease.NoLease)
-	s.Put([]byte("foo"), []byte("bar1"), lease.NoLease)
-	s.Put([]byte("foo"), []byte("bar2"), lease.NoLease)
-
-	// rev in tests will be called in Compact() one by one on the same store
-	tests := []struct {
-		rev  int64
-		werr error
-	}{
-		{0, nil},
-		{1, nil},
-		{1, ErrCompacted},
-		{4, nil},
-		{5, ErrFutureRev},
-		{100, ErrFutureRev},
-	}
-	for i, tt := range tests {
-		_, err := s.Compact(tt.rev)
-		if err != tt.werr {
-			t.Errorf("#%d: compact error = %v, want %v", i, err, tt.werr)
-		}
-	}
-}
-
-func TestKVHash(t *testing.T) {
-	hashes := make([]uint32, 3)
-
-	for i := 0; i < len(hashes); i++ {
-		var err error
-		b, tmpPath := backend.NewDefaultTmpBackend()
-		kv := NewStore(b, &lease.FakeLessor{}, nil)
-		kv.Put([]byte("foo0"), []byte("bar0"), lease.NoLease)
-		kv.Put([]byte("foo1"), []byte("bar0"), lease.NoLease)
-		hashes[i], _, err = kv.Hash()
-		if err != nil {
-			t.Fatalf("failed to get hash: %v", err)
-		}
-		cleanup(kv, b, tmpPath)
-	}
-
-	for i := 1; i < len(hashes); i++ {
-		if hashes[i-1] != hashes[i] {
-			t.Errorf("hash[%d](%d) != hash[%d](%d)", i-1, hashes[i-1], i, hashes[i])
-		}
-	}
-}
-
-func TestKVRestore(t *testing.T) {
-	tests := []func(kv KV){
-		func(kv KV) {
-			kv.Put([]byte("foo"), []byte("bar0"), 1)
-			kv.Put([]byte("foo"), []byte("bar1"), 2)
-			kv.Put([]byte("foo"), []byte("bar2"), 3)
-			kv.Put([]byte("foo2"), []byte("bar0"), 1)
-		},
-		func(kv KV) {
-			kv.Put([]byte("foo"), []byte("bar0"), 1)
-			kv.DeleteRange([]byte("foo"), nil)
-			kv.Put([]byte("foo"), []byte("bar1"), 2)
-		},
-		func(kv KV) {
-			kv.Put([]byte("foo"), []byte("bar0"), 1)
-			kv.Put([]byte("foo"), []byte("bar1"), 2)
-			kv.Compact(1)
-		},
-	}
-	for i, tt := range tests {
-		b, tmpPath := backend.NewDefaultTmpBackend()
-		s := NewStore(b, &lease.FakeLessor{}, nil)
-		tt(s)
-		var kvss [][]mvccpb.KeyValue
-		for k := int64(0); k < 10; k++ {
-			r, _ := s.Range([]byte("a"), []byte("z"), RangeOptions{Rev: k})
-			kvss = append(kvss, r.KVs)
-		}
-
-		keysBefore := readGaugeInt(&keysGauge)
-		s.Close()
-
-		// ns should recover the the previous state from backend.
-		ns := NewStore(b, &lease.FakeLessor{}, nil)
-
-		if keysRestore := readGaugeInt(&keysGauge); keysBefore != keysRestore {
-			t.Errorf("#%d: got %d key count, expected %d", i, keysRestore, keysBefore)
-		}
-
-		// wait for possible compaction to finish
-		testutil.WaitSchedule()
-		var nkvss [][]mvccpb.KeyValue
-		for k := int64(0); k < 10; k++ {
-			r, _ := ns.Range([]byte("a"), []byte("z"), RangeOptions{Rev: k})
-			nkvss = append(nkvss, r.KVs)
-		}
-		cleanup(ns, b, tmpPath)
-
-		if !reflect.DeepEqual(nkvss, kvss) {
-			t.Errorf("#%d: kvs history = %+v, want %+v", i, nkvss, kvss)
-		}
-	}
-}
-
-func readGaugeInt(g *prometheus.Gauge) int {
-	ch := make(chan prometheus.Metric, 1)
-	keysGauge.Collect(ch)
-	m := <-ch
-	mm := &dto.Metric{}
-	m.Write(mm)
-	return int(mm.GetGauge().GetValue())
-}
-
-func TestKVSnapshot(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	wkvs := put3TestKVs(s)
-
-	newPath := "new_test"
-	f, err := os.Create(newPath)
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer os.Remove(newPath)
-
-	snap := s.b.Snapshot()
-	defer snap.Close()
-	_, err = snap.WriteTo(f)
-	if err != nil {
-		t.Fatal(err)
-	}
-	f.Close()
-
-	ns := NewStore(b, &lease.FakeLessor{}, nil)
-	defer ns.Close()
-	r, err := ns.Range([]byte("a"), []byte("z"), RangeOptions{})
-	if err != nil {
-		t.Errorf("unexpect range error (%v)", err)
-	}
-	if !reflect.DeepEqual(r.KVs, wkvs) {
-		t.Errorf("kvs = %+v, want %+v", r.KVs, wkvs)
-	}
-	if r.Rev != 4 {
-		t.Errorf("rev = %d, want %d", r.Rev, 4)
-	}
-}
-
-func TestWatchableKVWatch(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
-	defer cleanup(s, b, tmpPath)
-
-	w := s.NewWatchStream()
-	defer w.Close()
-
-	wid, _ := w.Watch(0, []byte("foo"), []byte("fop"), 0)
-
-	wev := []mvccpb.Event{
-		{Type: mvccpb.PUT,
-			Kv: &mvccpb.KeyValue{
-				Key:            []byte("foo"),
-				Value:          []byte("bar"),
-				CreateRevision: 2,
-				ModRevision:    2,
-				Version:        1,
-				Lease:          1,
-			},
-		},
-		{
-			Type: mvccpb.PUT,
-			Kv: &mvccpb.KeyValue{
-				Key:            []byte("foo1"),
-				Value:          []byte("bar1"),
-				CreateRevision: 3,
-				ModRevision:    3,
-				Version:        1,
-				Lease:          2,
-			},
-		},
-		{
-			Type: mvccpb.PUT,
-			Kv: &mvccpb.KeyValue{
-				Key:            []byte("foo1"),
-				Value:          []byte("bar11"),
-				CreateRevision: 3,
-				ModRevision:    4,
-				Version:        2,
-				Lease:          3,
-			},
-		},
-	}
-
-	s.Put([]byte("foo"), []byte("bar"), 1)
-	select {
-	case resp := <-w.Chan():
-		if resp.WatchID != wid {
-			t.Errorf("resp.WatchID got = %d, want = %d", resp.WatchID, wid)
-		}
-		ev := resp.Events[0]
-		if !reflect.DeepEqual(ev, wev[0]) {
-			t.Errorf("watched event = %+v, want %+v", ev, wev[0])
-		}
-	case <-time.After(5 * time.Second):
-		// CPU might be too slow, and the routine is not able to switch around
-		testutil.FatalStack(t, "failed to watch the event")
-	}
-
-	s.Put([]byte("foo1"), []byte("bar1"), 2)
-	select {
-	case resp := <-w.Chan():
-		if resp.WatchID != wid {
-			t.Errorf("resp.WatchID got = %d, want = %d", resp.WatchID, wid)
-		}
-		ev := resp.Events[0]
-		if !reflect.DeepEqual(ev, wev[1]) {
-			t.Errorf("watched event = %+v, want %+v", ev, wev[1])
-		}
-	case <-time.After(5 * time.Second):
-		testutil.FatalStack(t, "failed to watch the event")
-	}
-
-	w = s.NewWatchStream()
-	wid, _ = w.Watch(0, []byte("foo1"), []byte("foo2"), 3)
-
-	select {
-	case resp := <-w.Chan():
-		if resp.WatchID != wid {
-			t.Errorf("resp.WatchID got = %d, want = %d", resp.WatchID, wid)
-		}
-		ev := resp.Events[0]
-		if !reflect.DeepEqual(ev, wev[1]) {
-			t.Errorf("watched event = %+v, want %+v", ev, wev[1])
-		}
-	case <-time.After(5 * time.Second):
-		testutil.FatalStack(t, "failed to watch the event")
-	}
-
-	s.Put([]byte("foo1"), []byte("bar11"), 3)
-	select {
-	case resp := <-w.Chan():
-		if resp.WatchID != wid {
-			t.Errorf("resp.WatchID got = %d, want = %d", resp.WatchID, wid)
-		}
-		ev := resp.Events[0]
-		if !reflect.DeepEqual(ev, wev[2]) {
-			t.Errorf("watched event = %+v, want %+v", ev, wev[2])
-		}
-	case <-time.After(5 * time.Second):
-		testutil.FatalStack(t, "failed to watch the event")
-	}
-}
-
-func cleanup(s KV, b backend.Backend, path string) {
-	s.Close()
-	b.Close()
-	os.Remove(path)
-}
-
-func put3TestKVs(s KV) []mvccpb.KeyValue {
-	s.Put([]byte("foo"), []byte("bar"), 1)
-	s.Put([]byte("foo1"), []byte("bar1"), 2)
-	s.Put([]byte("foo2"), []byte("bar2"), 3)
-	return []mvccpb.KeyValue{
-		{Key: []byte("foo"), Value: []byte("bar"), CreateRevision: 2, ModRevision: 2, Version: 1, Lease: 1},
-		{Key: []byte("foo1"), Value: []byte("bar1"), CreateRevision: 3, ModRevision: 3, Version: 1, Lease: 2},
-		{Key: []byte("foo2"), Value: []byte("bar2"), CreateRevision: 4, ModRevision: 4, Version: 1, Lease: 3},
-	}
-}
diff --git a/mvcc/kv_view.go b/mvcc/kv_view.go
deleted file mode 100644
index 8269a72..0000000
--- a/mvcc/kv_view.go
+++ /dev/null
@@ -1,51 +0,0 @@
-// Copyright 2017 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import "github.com/coreos/etcd/internal/lease"
-
-type readView struct{ kv KV }
-
-func (rv *readView) FirstRev() int64 {
-	tr := rv.kv.Read()
-	defer tr.End()
-	return tr.FirstRev()
-}
-
-func (rv *readView) Rev() int64 {
-	tr := rv.kv.Read()
-	defer tr.End()
-	return tr.Rev()
-}
-
-func (rv *readView) Range(key, end []byte, ro RangeOptions) (r *RangeResult, err error) {
-	tr := rv.kv.Read()
-	defer tr.End()
-	return tr.Range(key, end, ro)
-}
-
-type writeView struct{ kv KV }
-
-func (wv *writeView) DeleteRange(key, end []byte) (n, rev int64) {
-	tw := wv.kv.Write()
-	defer tw.End()
-	return tw.DeleteRange(key, end)
-}
-
-func (wv *writeView) Put(key, value []byte, lease lease.LeaseID) (rev int64) {
-	tw := wv.kv.Write()
-	defer tw.End()
-	return tw.Put(key, value, lease)
-}
diff --git a/mvcc/kvstore.go b/mvcc/kvstore.go
deleted file mode 100644
index 4c022d2..0000000
--- a/mvcc/kvstore.go
+++ /dev/null
@@ -1,497 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"context"
-	"encoding/binary"
-	"errors"
-	"hash/crc32"
-	"math"
-	"sync"
-	"sync/atomic"
-	"time"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
-	"github.com/coreos/etcd/pkg/schedule"
-	"github.com/coreos/pkg/capnslog"
-)
-
-var (
-	keyBucketName  = []byte("key")
-	metaBucketName = []byte("meta")
-
-	consistentIndexKeyName  = []byte("consistent_index")
-	scheduledCompactKeyName = []byte("scheduledCompactRev")
-	finishedCompactKeyName  = []byte("finishedCompactRev")
-
-	ErrCompacted = errors.New("mvcc: required revision has been compacted")
-	ErrFutureRev = errors.New("mvcc: required revision is a future revision")
-	ErrCanceled  = errors.New("mvcc: watcher is canceled")
-	ErrClosed    = errors.New("mvcc: closed")
-
-	plog = capnslog.NewPackageLogger("github.com/coreos/etcd", "mvcc")
-)
-
-const (
-	// markedRevBytesLen is the byte length of marked revision.
-	// The first `revBytesLen` bytes represents a normal revision. The last
-	// one byte is the mark.
-	markedRevBytesLen      = revBytesLen + 1
-	markBytePosition       = markedRevBytesLen - 1
-	markTombstone     byte = 't'
-)
-
-var restoreChunkKeys = 10000 // non-const for testing
-
-// ConsistentIndexGetter is an interface that wraps the Get method.
-// Consistent index is the offset of an entry in a consistent replicated log.
-type ConsistentIndexGetter interface {
-	// ConsistentIndex returns the consistent index of current executing entry.
-	ConsistentIndex() uint64
-}
-
-type store struct {
-	ReadView
-	WriteView
-
-	// consistentIndex caches the "consistent_index" key's value. Accessed
-	// through atomics so must be 64-bit aligned.
-	consistentIndex uint64
-
-	// mu read locks for txns and write locks for non-txn store changes.
-	mu sync.RWMutex
-
-	ig ConsistentIndexGetter
-
-	b       backend.Backend
-	kvindex index
-
-	le lease.Lessor
-
-	// revMuLock protects currentRev and compactMainRev.
-	// Locked at end of write txn and released after write txn unlock lock.
-	// Locked before locking read txn and released after locking.
-	revMu sync.RWMutex
-	// currentRev is the revision of the last completed transaction.
-	currentRev int64
-	// compactMainRev is the main revision of the last compaction.
-	compactMainRev int64
-
-	// bytesBuf8 is a byte slice of length 8
-	// to avoid a repetitive allocation in saveIndex.
-	bytesBuf8 []byte
-
-	fifoSched schedule.Scheduler
-
-	stopc chan struct{}
-}
-
-// NewStore returns a new store. It is useful to create a store inside
-// mvcc pkg. It should only be used for testing externally.
-func NewStore(b backend.Backend, le lease.Lessor, ig ConsistentIndexGetter) *store {
-	s := &store{
-		b:       b,
-		ig:      ig,
-		kvindex: newTreeIndex(),
-
-		le: le,
-
-		currentRev:     1,
-		compactMainRev: -1,
-
-		bytesBuf8: make([]byte, 8),
-		fifoSched: schedule.NewFIFOScheduler(),
-
-		stopc: make(chan struct{}),
-	}
-	s.ReadView = &readView{s}
-	s.WriteView = &writeView{s}
-	if s.le != nil {
-		s.le.SetRangeDeleter(func() lease.TxnDelete { return s.Write() })
-	}
-
-	tx := s.b.BatchTx()
-	tx.Lock()
-	tx.UnsafeCreateBucket(keyBucketName)
-	tx.UnsafeCreateBucket(metaBucketName)
-	tx.Unlock()
-	s.b.ForceCommit()
-
-	if err := s.restore(); err != nil {
-		// TODO: return the error instead of panic here?
-		panic("failed to recover store from backend")
-	}
-
-	return s
-}
-
-func (s *store) compactBarrier(ctx context.Context, ch chan struct{}) {
-	if ctx == nil || ctx.Err() != nil {
-		s.mu.Lock()
-		select {
-		case <-s.stopc:
-		default:
-			f := func(ctx context.Context) { s.compactBarrier(ctx, ch) }
-			s.fifoSched.Schedule(f)
-		}
-		s.mu.Unlock()
-		return
-	}
-	close(ch)
-}
-
-func (s *store) Hash() (hash uint32, revision int64, err error) {
-	s.b.ForceCommit()
-	h, err := s.b.Hash(DefaultIgnores)
-	return h, s.currentRev, err
-}
-
-func (s *store) HashByRev(rev int64) (hash uint32, currentRev int64, compactRev int64, err error) {
-	s.mu.RLock()
-	s.revMu.RLock()
-	compactRev, currentRev = s.compactMainRev, s.currentRev
-	s.revMu.RUnlock()
-
-	if rev > 0 && rev <= compactRev {
-		s.mu.RUnlock()
-		return 0, 0, compactRev, ErrCompacted
-	} else if rev > 0 && rev > currentRev {
-		s.mu.RUnlock()
-		return 0, currentRev, 0, ErrFutureRev
-	}
-
-	if rev == 0 {
-		rev = currentRev
-	}
-	keep := s.kvindex.Keep(rev)
-
-	tx := s.b.ReadTx()
-	tx.Lock()
-	defer tx.Unlock()
-	s.mu.RUnlock()
-
-	upper := revision{main: rev + 1}
-	lower := revision{main: compactRev + 1}
-	h := crc32.New(crc32.MakeTable(crc32.Castagnoli))
-
-	h.Write(keyBucketName)
-	err = tx.UnsafeForEach(keyBucketName, func(k, v []byte) error {
-		kr := bytesToRev(k)
-		if !upper.GreaterThan(kr) {
-			return nil
-		}
-		// skip revisions that are scheduled for deletion
-		// due to compacting; don't skip if there isn't one.
-		if lower.GreaterThan(kr) && len(keep) > 0 {
-			if _, ok := keep[kr]; !ok {
-				return nil
-			}
-		}
-		h.Write(k)
-		h.Write(v)
-		return nil
-	})
-	return h.Sum32(), currentRev, compactRev, err
-}
-
-func (s *store) Compact(rev int64) (<-chan struct{}, error) {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	s.revMu.Lock()
-	defer s.revMu.Unlock()
-
-	if rev <= s.compactMainRev {
-		ch := make(chan struct{})
-		f := func(ctx context.Context) { s.compactBarrier(ctx, ch) }
-		s.fifoSched.Schedule(f)
-		return ch, ErrCompacted
-	}
-	if rev > s.currentRev {
-		return nil, ErrFutureRev
-	}
-
-	start := time.Now()
-
-	s.compactMainRev = rev
-
-	rbytes := newRevBytes()
-	revToBytes(revision{main: rev}, rbytes)
-
-	tx := s.b.BatchTx()
-	tx.Lock()
-	tx.UnsafePut(metaBucketName, scheduledCompactKeyName, rbytes)
-	tx.Unlock()
-	// ensure that desired compaction is persisted
-	s.b.ForceCommit()
-
-	keep := s.kvindex.Compact(rev)
-	ch := make(chan struct{})
-	var j = func(ctx context.Context) {
-		if ctx.Err() != nil {
-			s.compactBarrier(ctx, ch)
-			return
-		}
-		if !s.scheduleCompaction(rev, keep) {
-			s.compactBarrier(nil, ch)
-			return
-		}
-		close(ch)
-	}
-
-	s.fifoSched.Schedule(j)
-
-	indexCompactionPauseDurations.Observe(float64(time.Since(start) / time.Millisecond))
-	return ch, nil
-}
-
-// DefaultIgnores is a map of keys to ignore in hash checking.
-var DefaultIgnores map[backend.IgnoreKey]struct{}
-
-func init() {
-	DefaultIgnores = map[backend.IgnoreKey]struct{}{
-		// consistent index might be changed due to v2 internal sync, which
-		// is not controllable by the user.
-		{Bucket: string(metaBucketName), Key: string(consistentIndexKeyName)}: {},
-	}
-}
-
-func (s *store) Commit() {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	tx := s.b.BatchTx()
-	tx.Lock()
-	s.saveIndex(tx)
-	tx.Unlock()
-	s.b.ForceCommit()
-}
-
-func (s *store) Restore(b backend.Backend) error {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	close(s.stopc)
-	s.fifoSched.Stop()
-
-	atomic.StoreUint64(&s.consistentIndex, 0)
-	s.b = b
-	s.kvindex = newTreeIndex()
-	s.currentRev = 1
-	s.compactMainRev = -1
-	s.fifoSched = schedule.NewFIFOScheduler()
-	s.stopc = make(chan struct{})
-
-	return s.restore()
-}
-
-func (s *store) restore() error {
-	reportDbTotalSizeInBytesMu.Lock()
-	b := s.b
-	reportDbTotalSizeInBytes = func() float64 { return float64(b.Size()) }
-	reportDbTotalSizeInBytesMu.Unlock()
-
-	min, max := newRevBytes(), newRevBytes()
-	revToBytes(revision{main: 1}, min)
-	revToBytes(revision{main: math.MaxInt64, sub: math.MaxInt64}, max)
-
-	keyToLease := make(map[string]lease.LeaseID)
-
-	// restore index
-	tx := s.b.BatchTx()
-	tx.Lock()
-
-	_, finishedCompactBytes := tx.UnsafeRange(metaBucketName, finishedCompactKeyName, nil, 0)
-	if len(finishedCompactBytes) != 0 {
-		s.compactMainRev = bytesToRev(finishedCompactBytes[0]).main
-		plog.Printf("restore compact to %d", s.compactMainRev)
-	}
-	_, scheduledCompactBytes := tx.UnsafeRange(metaBucketName, scheduledCompactKeyName, nil, 0)
-	scheduledCompact := int64(0)
-	if len(scheduledCompactBytes) != 0 {
-		scheduledCompact = bytesToRev(scheduledCompactBytes[0]).main
-	}
-
-	// index keys concurrently as they're loaded in from tx
-	keysGauge.Set(0)
-	rkvc, revc := restoreIntoIndex(s.kvindex)
-	for {
-		keys, vals := tx.UnsafeRange(keyBucketName, min, max, int64(restoreChunkKeys))
-		if len(keys) == 0 {
-			break
-		}
-		// rkvc blocks if the total pending keys exceeds the restore
-		// chunk size to keep keys from consuming too much memory.
-		restoreChunk(rkvc, keys, vals, keyToLease)
-		if len(keys) < restoreChunkKeys {
-			// partial set implies final set
-			break
-		}
-		// next set begins after where this one ended
-		newMin := bytesToRev(keys[len(keys)-1][:revBytesLen])
-		newMin.sub++
-		revToBytes(newMin, min)
-	}
-	close(rkvc)
-	s.currentRev = <-revc
-
-	// keys in the range [compacted revision -N, compaction] might all be deleted due to compaction.
-	// the correct revision should be set to compaction revision in the case, not the largest revision
-	// we have seen.
-	if s.currentRev < s.compactMainRev {
-		s.currentRev = s.compactMainRev
-	}
-	if scheduledCompact <= s.compactMainRev {
-		scheduledCompact = 0
-	}
-
-	for key, lid := range keyToLease {
-		if s.le == nil {
-			panic("no lessor to attach lease")
-		}
-		err := s.le.Attach(lid, []lease.LeaseItem{{Key: key}})
-		if err != nil {
-			plog.Errorf("unexpected Attach error: %v", err)
-		}
-	}
-
-	tx.Unlock()
-
-	if scheduledCompact != 0 {
-		s.Compact(scheduledCompact)
-		plog.Printf("resume scheduled compaction at %d", scheduledCompact)
-	}
-
-	return nil
-}
-
-type revKeyValue struct {
-	key  []byte
-	kv   mvccpb.KeyValue
-	kstr string
-}
-
-func restoreIntoIndex(idx index) (chan<- revKeyValue, <-chan int64) {
-	rkvc, revc := make(chan revKeyValue, restoreChunkKeys), make(chan int64, 1)
-	go func() {
-		currentRev := int64(1)
-		defer func() { revc <- currentRev }()
-		// restore the tree index from streaming the unordered index.
-		kiCache := make(map[string]*keyIndex, restoreChunkKeys)
-		for rkv := range rkvc {
-			ki, ok := kiCache[rkv.kstr]
-			// purge kiCache if many keys but still missing in the cache
-			if !ok && len(kiCache) >= restoreChunkKeys {
-				i := 10
-				for k := range kiCache {
-					delete(kiCache, k)
-					if i--; i == 0 {
-						break
-					}
-				}
-			}
-			// cache miss, fetch from tree index if there
-			if !ok {
-				ki = &keyIndex{key: rkv.kv.Key}
-				if idxKey := idx.KeyIndex(ki); idxKey != nil {
-					kiCache[rkv.kstr], ki = idxKey, idxKey
-					ok = true
-				}
-			}
-			rev := bytesToRev(rkv.key)
-			currentRev = rev.main
-			if ok {
-				if isTombstone(rkv.key) {
-					ki.tombstone(rev.main, rev.sub)
-					continue
-				}
-				ki.put(rev.main, rev.sub)
-			} else if !isTombstone(rkv.key) {
-				ki.restore(revision{rkv.kv.CreateRevision, 0}, rev, rkv.kv.Version)
-				idx.Insert(ki)
-				kiCache[rkv.kstr] = ki
-			}
-		}
-	}()
-	return rkvc, revc
-}
-
-func restoreChunk(kvc chan<- revKeyValue, keys, vals [][]byte, keyToLease map[string]lease.LeaseID) {
-	for i, key := range keys {
-		rkv := revKeyValue{key: key}
-		if err := rkv.kv.Unmarshal(vals[i]); err != nil {
-			plog.Fatalf("cannot unmarshal event: %v", err)
-		}
-		rkv.kstr = string(rkv.kv.Key)
-		if isTombstone(key) {
-			delete(keyToLease, rkv.kstr)
-		} else if lid := lease.LeaseID(rkv.kv.Lease); lid != lease.NoLease {
-			keyToLease[rkv.kstr] = lid
-		} else {
-			delete(keyToLease, rkv.kstr)
-		}
-		kvc <- rkv
-	}
-}
-
-func (s *store) Close() error {
-	close(s.stopc)
-	s.fifoSched.Stop()
-	return nil
-}
-
-func (s *store) saveIndex(tx backend.BatchTx) {
-	if s.ig == nil {
-		return
-	}
-	bs := s.bytesBuf8
-	ci := s.ig.ConsistentIndex()
-	binary.BigEndian.PutUint64(bs, ci)
-	// put the index into the underlying backend
-	// tx has been locked in TxnBegin, so there is no need to lock it again
-	tx.UnsafePut(metaBucketName, consistentIndexKeyName, bs)
-	atomic.StoreUint64(&s.consistentIndex, ci)
-}
-
-func (s *store) ConsistentIndex() uint64 {
-	if ci := atomic.LoadUint64(&s.consistentIndex); ci > 0 {
-		return ci
-	}
-	tx := s.b.BatchTx()
-	tx.Lock()
-	defer tx.Unlock()
-	_, vs := tx.UnsafeRange(metaBucketName, consistentIndexKeyName, nil, 0)
-	if len(vs) == 0 {
-		return 0
-	}
-	v := binary.BigEndian.Uint64(vs[0])
-	atomic.StoreUint64(&s.consistentIndex, v)
-	return v
-}
-
-// appendMarkTombstone appends tombstone mark to normal revision bytes.
-func appendMarkTombstone(b []byte) []byte {
-	if len(b) != revBytesLen {
-		plog.Panicf("cannot append mark to non normal revision bytes")
-	}
-	return append(b, markTombstone)
-}
-
-// isTombstone checks whether the revision bytes is a tombstone.
-func isTombstone(b []byte) bool {
-	return len(b) == markedRevBytesLen && b[markBytePosition] == markTombstone
-}
diff --git a/mvcc/kvstore_bench_test.go b/mvcc/kvstore_bench_test.go
deleted file mode 100644
index af4310c..0000000
--- a/mvcc/kvstore_bench_test.go
+++ /dev/null
@@ -1,174 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"sync/atomic"
-	"testing"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-)
-
-type fakeConsistentIndex uint64
-
-func (i *fakeConsistentIndex) ConsistentIndex() uint64 {
-	return atomic.LoadUint64((*uint64)(i))
-}
-
-func BenchmarkStorePut(b *testing.B) {
-	var i fakeConsistentIndex
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(be, &lease.FakeLessor{}, &i)
-	defer cleanup(s, be, tmpPath)
-
-	// arbitrary number of bytes
-	bytesN := 64
-	keys := createBytesSlice(bytesN, b.N)
-	vals := createBytesSlice(bytesN, b.N)
-
-	b.ResetTimer()
-	for i := 0; i < b.N; i++ {
-		s.Put(keys[i], vals[i], lease.NoLease)
-	}
-}
-
-func BenchmarkStoreRangeKey1(b *testing.B)   { benchmarkStoreRange(b, 1) }
-func BenchmarkStoreRangeKey100(b *testing.B) { benchmarkStoreRange(b, 100) }
-
-func benchmarkStoreRange(b *testing.B, n int) {
-	var i fakeConsistentIndex
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(be, &lease.FakeLessor{}, &i)
-	defer cleanup(s, be, tmpPath)
-
-	// 64 byte key/val
-	keys, val := createBytesSlice(64, n), createBytesSlice(64, 1)
-	for i := range keys {
-		s.Put(keys[i], val[0], lease.NoLease)
-	}
-	// Force into boltdb tx instead of backend read tx.
-	s.Commit()
-
-	var begin, end []byte
-	if n == 1 {
-		begin, end = keys[0], nil
-	} else {
-		begin, end = []byte{}, []byte{}
-	}
-
-	b.ReportAllocs()
-	b.ResetTimer()
-	for i := 0; i < b.N; i++ {
-		s.Range(begin, end, RangeOptions{})
-	}
-}
-
-func BenchmarkConsistentIndex(b *testing.B) {
-	fci := fakeConsistentIndex(10)
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(be, &lease.FakeLessor{}, &fci)
-	defer cleanup(s, be, tmpPath)
-
-	tx := s.b.BatchTx()
-	tx.Lock()
-	s.saveIndex(tx)
-	tx.Unlock()
-
-	b.ReportAllocs()
-	b.ResetTimer()
-	for i := 0; i < b.N; i++ {
-		s.ConsistentIndex()
-	}
-}
-
-// BenchmarkStoreTxnPutUpdate is same as above, but instead updates single key
-func BenchmarkStorePutUpdate(b *testing.B) {
-	var i fakeConsistentIndex
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(be, &lease.FakeLessor{}, &i)
-	defer cleanup(s, be, tmpPath)
-
-	// arbitrary number of bytes
-	keys := createBytesSlice(64, 1)
-	vals := createBytesSlice(1024, 1)
-
-	b.ResetTimer()
-	for i := 0; i < b.N; i++ {
-		s.Put(keys[0], vals[0], lease.NoLease)
-	}
-}
-
-// BenchmarkStoreTxnPut benchmarks the Put operation
-// with transaction begin and end, where transaction involves
-// some synchronization operations, such as mutex locking.
-func BenchmarkStoreTxnPut(b *testing.B) {
-	var i fakeConsistentIndex
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(be, &lease.FakeLessor{}, &i)
-	defer cleanup(s, be, tmpPath)
-
-	// arbitrary number of bytes
-	bytesN := 64
-	keys := createBytesSlice(bytesN, b.N)
-	vals := createBytesSlice(bytesN, b.N)
-
-	b.ResetTimer()
-	b.ReportAllocs()
-	for i := 0; i < b.N; i++ {
-		txn := s.Write()
-		txn.Put(keys[i], vals[i], lease.NoLease)
-		txn.End()
-	}
-}
-
-// benchmarkStoreRestore benchmarks the restore operation
-func benchmarkStoreRestore(revsPerKey int, b *testing.B) {
-	var i fakeConsistentIndex
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(be, &lease.FakeLessor{}, &i)
-	// use closure to capture 's' to pick up the reassignment
-	defer func() { cleanup(s, be, tmpPath) }()
-
-	// arbitrary number of bytes
-	bytesN := 64
-	keys := createBytesSlice(bytesN, b.N)
-	vals := createBytesSlice(bytesN, b.N)
-
-	for i := 0; i < b.N; i++ {
-		for j := 0; j < revsPerKey; j++ {
-			txn := s.Write()
-			txn.Put(keys[i], vals[i], lease.NoLease)
-			txn.End()
-		}
-	}
-	s.Close()
-
-	b.ReportAllocs()
-	b.ResetTimer()
-	s = NewStore(be, &lease.FakeLessor{}, &i)
-}
-
-func BenchmarkStoreRestoreRevs1(b *testing.B) {
-	benchmarkStoreRestore(1, b)
-}
-
-func BenchmarkStoreRestoreRevs10(b *testing.B) {
-	benchmarkStoreRestore(10, b)
-}
-
-func BenchmarkStoreRestoreRevs20(b *testing.B) {
-	benchmarkStoreRestore(20, b)
-}
diff --git a/mvcc/kvstore_compaction.go b/mvcc/kvstore_compaction.go
deleted file mode 100644
index 1726490..0000000
--- a/mvcc/kvstore_compaction.go
+++ /dev/null
@@ -1,69 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"encoding/binary"
-	"time"
-)
-
-func (s *store) scheduleCompaction(compactMainRev int64, keep map[revision]struct{}) bool {
-	totalStart := time.Now()
-	defer dbCompactionTotalDurations.Observe(float64(time.Since(totalStart) / time.Millisecond))
-	keyCompactions := 0
-	defer func() { dbCompactionKeysCounter.Add(float64(keyCompactions)) }()
-
-	end := make([]byte, 8)
-	binary.BigEndian.PutUint64(end, uint64(compactMainRev+1))
-
-	batchsize := int64(10000)
-	last := make([]byte, 8+1+8)
-	for {
-		var rev revision
-
-		start := time.Now()
-		tx := s.b.BatchTx()
-		tx.Lock()
-
-		keys, _ := tx.UnsafeRange(keyBucketName, last, end, batchsize)
-		for _, key := range keys {
-			rev = bytesToRev(key)
-			if _, ok := keep[rev]; !ok {
-				tx.UnsafeDelete(keyBucketName, key)
-				keyCompactions++
-			}
-		}
-
-		if len(keys) < int(batchsize) {
-			rbytes := make([]byte, 8+1+8)
-			revToBytes(revision{main: compactMainRev}, rbytes)
-			tx.UnsafePut(metaBucketName, finishedCompactKeyName, rbytes)
-			tx.Unlock()
-			plog.Printf("finished scheduled compaction at %d (took %v)", compactMainRev, time.Since(totalStart))
-			return true
-		}
-
-		// update last
-		revToBytes(revision{main: rev.main, sub: rev.sub + 1}, last)
-		tx.Unlock()
-		dbCompactionPauseDurations.Observe(float64(time.Since(start) / time.Millisecond))
-
-		select {
-		case <-time.After(100 * time.Millisecond):
-		case <-s.stopc:
-			return false
-		}
-	}
-}
diff --git a/mvcc/kvstore_compaction_test.go b/mvcc/kvstore_compaction_test.go
deleted file mode 100644
index fc04ef4..0000000
--- a/mvcc/kvstore_compaction_test.go
+++ /dev/null
@@ -1,135 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"os"
-	"reflect"
-	"testing"
-	"time"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-)
-
-func TestScheduleCompaction(t *testing.T) {
-	revs := []revision{{1, 0}, {2, 0}, {3, 0}}
-
-	tests := []struct {
-		rev   int64
-		keep  map[revision]struct{}
-		wrevs []revision
-	}{
-		// compact at 1 and discard all history
-		{
-			1,
-			nil,
-			revs[1:],
-		},
-		// compact at 3 and discard all history
-		{
-			3,
-			nil,
-			nil,
-		},
-		// compact at 1 and keeps history one step earlier
-		{
-			1,
-			map[revision]struct{}{
-				{main: 1}: {},
-			},
-			revs,
-		},
-		// compact at 1 and keeps history two steps earlier
-		{
-			3,
-			map[revision]struct{}{
-				{main: 2}: {},
-				{main: 3}: {},
-			},
-			revs[1:],
-		},
-	}
-	for i, tt := range tests {
-		b, tmpPath := backend.NewDefaultTmpBackend()
-		s := NewStore(b, &lease.FakeLessor{}, nil)
-		tx := s.b.BatchTx()
-
-		tx.Lock()
-		ibytes := newRevBytes()
-		for _, rev := range revs {
-			revToBytes(rev, ibytes)
-			tx.UnsafePut(keyBucketName, ibytes, []byte("bar"))
-		}
-		tx.Unlock()
-
-		s.scheduleCompaction(tt.rev, tt.keep)
-
-		tx.Lock()
-		for _, rev := range tt.wrevs {
-			revToBytes(rev, ibytes)
-			keys, _ := tx.UnsafeRange(keyBucketName, ibytes, nil, 0)
-			if len(keys) != 1 {
-				t.Errorf("#%d: range on %v = %d, want 1", i, rev, len(keys))
-			}
-		}
-		_, vals := tx.UnsafeRange(metaBucketName, finishedCompactKeyName, nil, 0)
-		revToBytes(revision{main: tt.rev}, ibytes)
-		if w := [][]byte{ibytes}; !reflect.DeepEqual(vals, w) {
-			t.Errorf("#%d: vals on %v = %+v, want %+v", i, finishedCompactKeyName, vals, w)
-		}
-		tx.Unlock()
-
-		cleanup(s, b, tmpPath)
-	}
-}
-
-func TestCompactAllAndRestore(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s0 := NewStore(b, &lease.FakeLessor{}, nil)
-	defer os.Remove(tmpPath)
-
-	s0.Put([]byte("foo"), []byte("bar"), lease.NoLease)
-	s0.Put([]byte("foo"), []byte("bar1"), lease.NoLease)
-	s0.Put([]byte("foo"), []byte("bar2"), lease.NoLease)
-	s0.DeleteRange([]byte("foo"), nil)
-
-	rev := s0.Rev()
-	// compact all keys
-	done, err := s0.Compact(rev)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	select {
-	case <-done:
-	case <-time.After(10 * time.Second):
-		t.Fatal("timeout waiting for compaction to finish")
-	}
-
-	err = s0.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	s1 := NewStore(b, &lease.FakeLessor{}, nil)
-	if s1.Rev() != rev {
-		t.Errorf("rev = %v, want %v", s1.Rev(), rev)
-	}
-	_, err = s1.Range([]byte("foo"), nil, RangeOptions{})
-	if err != nil {
-		t.Errorf("unexpect range error %v", err)
-	}
-}
diff --git a/mvcc/kvstore_test.go b/mvcc/kvstore_test.go
deleted file mode 100644
index f315282..0000000
--- a/mvcc/kvstore_test.go
+++ /dev/null
@@ -1,829 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"crypto/rand"
-	"encoding/binary"
-	"fmt"
-	"math"
-	mrand "math/rand"
-	"os"
-	"reflect"
-	"sync"
-	"testing"
-	"time"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
-	"github.com/coreos/etcd/pkg/schedule"
-	"github.com/coreos/etcd/pkg/testutil"
-)
-
-func TestStoreRev(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer s.Close()
-	defer os.Remove(tmpPath)
-
-	for i := 1; i <= 3; i++ {
-		s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
-		if r := s.Rev(); r != int64(i+1) {
-			t.Errorf("#%d: rev = %d, want %d", i, r, i+1)
-		}
-	}
-}
-
-func TestStorePut(t *testing.T) {
-	kv := mvccpb.KeyValue{
-		Key:            []byte("foo"),
-		Value:          []byte("bar"),
-		CreateRevision: 1,
-		ModRevision:    2,
-		Version:        1,
-	}
-	kvb, err := kv.Marshal()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	tests := []struct {
-		rev revision
-		r   indexGetResp
-		rr  *rangeResp
-
-		wrev    revision
-		wkey    []byte
-		wkv     mvccpb.KeyValue
-		wputrev revision
-	}{
-		{
-			revision{1, 0},
-			indexGetResp{revision{}, revision{}, 0, ErrRevisionNotFound},
-			nil,
-
-			revision{2, 0},
-			newTestKeyBytes(revision{2, 0}, false),
-			mvccpb.KeyValue{
-				Key:            []byte("foo"),
-				Value:          []byte("bar"),
-				CreateRevision: 2,
-				ModRevision:    2,
-				Version:        1,
-				Lease:          1,
-			},
-			revision{2, 0},
-		},
-		{
-			revision{1, 1},
-			indexGetResp{revision{2, 0}, revision{2, 0}, 1, nil},
-			&rangeResp{[][]byte{newTestKeyBytes(revision{2, 1}, false)}, [][]byte{kvb}},
-
-			revision{2, 0},
-			newTestKeyBytes(revision{2, 0}, false),
-			mvccpb.KeyValue{
-				Key:            []byte("foo"),
-				Value:          []byte("bar"),
-				CreateRevision: 2,
-				ModRevision:    2,
-				Version:        2,
-				Lease:          2,
-			},
-			revision{2, 0},
-		},
-		{
-			revision{2, 0},
-			indexGetResp{revision{2, 1}, revision{2, 0}, 2, nil},
-			&rangeResp{[][]byte{newTestKeyBytes(revision{2, 1}, false)}, [][]byte{kvb}},
-
-			revision{3, 0},
-			newTestKeyBytes(revision{3, 0}, false),
-			mvccpb.KeyValue{
-				Key:            []byte("foo"),
-				Value:          []byte("bar"),
-				CreateRevision: 2,
-				ModRevision:    3,
-				Version:        3,
-				Lease:          3,
-			},
-			revision{3, 0},
-		},
-	}
-	for i, tt := range tests {
-		s := newFakeStore()
-		b := s.b.(*fakeBackend)
-		fi := s.kvindex.(*fakeIndex)
-
-		s.currentRev = tt.rev.main
-		fi.indexGetRespc <- tt.r
-		if tt.rr != nil {
-			b.tx.rangeRespc <- *tt.rr
-		}
-
-		s.Put([]byte("foo"), []byte("bar"), lease.LeaseID(i+1))
-
-		data, err := tt.wkv.Marshal()
-		if err != nil {
-			t.Errorf("#%d: marshal err = %v, want nil", i, err)
-		}
-
-		wact := []testutil.Action{
-			{Name: "seqput", Params: []interface{}{keyBucketName, tt.wkey, data}},
-		}
-
-		if tt.rr != nil {
-			wact = []testutil.Action{
-				{Name: "seqput", Params: []interface{}{keyBucketName, tt.wkey, data}},
-			}
-		}
-
-		if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
-			t.Errorf("#%d: tx action = %+v, want %+v", i, g, wact)
-		}
-		wact = []testutil.Action{
-			{Name: "get", Params: []interface{}{[]byte("foo"), tt.wputrev.main}},
-			{Name: "put", Params: []interface{}{[]byte("foo"), tt.wputrev}},
-		}
-		if g := fi.Action(); !reflect.DeepEqual(g, wact) {
-			t.Errorf("#%d: index action = %+v, want %+v", i, g, wact)
-		}
-		if s.currentRev != tt.wrev.main {
-			t.Errorf("#%d: rev = %+v, want %+v", i, s.currentRev, tt.wrev)
-		}
-
-		s.Close()
-	}
-}
-
-func TestStoreRange(t *testing.T) {
-	key := newTestKeyBytes(revision{2, 0}, false)
-	kv := mvccpb.KeyValue{
-		Key:            []byte("foo"),
-		Value:          []byte("bar"),
-		CreateRevision: 1,
-		ModRevision:    2,
-		Version:        1,
-	}
-	kvb, err := kv.Marshal()
-	if err != nil {
-		t.Fatal(err)
-	}
-	wrev := int64(2)
-
-	tests := []struct {
-		idxr indexRangeResp
-		r    rangeResp
-	}{
-		{
-			indexRangeResp{[][]byte{[]byte("foo")}, []revision{{2, 0}}},
-			rangeResp{[][]byte{key}, [][]byte{kvb}},
-		},
-		{
-			indexRangeResp{[][]byte{[]byte("foo"), []byte("foo1")}, []revision{{2, 0}, {3, 0}}},
-			rangeResp{[][]byte{key}, [][]byte{kvb}},
-		},
-	}
-
-	ro := RangeOptions{Limit: 1, Rev: 0, Count: false}
-	for i, tt := range tests {
-		s := newFakeStore()
-		b := s.b.(*fakeBackend)
-		fi := s.kvindex.(*fakeIndex)
-
-		s.currentRev = 2
-		b.tx.rangeRespc <- tt.r
-		fi.indexRangeRespc <- tt.idxr
-
-		ret, err := s.Range([]byte("foo"), []byte("goo"), ro)
-		if err != nil {
-			t.Errorf("#%d: err = %v, want nil", i, err)
-		}
-		if w := []mvccpb.KeyValue{kv}; !reflect.DeepEqual(ret.KVs, w) {
-			t.Errorf("#%d: kvs = %+v, want %+v", i, ret.KVs, w)
-		}
-		if ret.Rev != wrev {
-			t.Errorf("#%d: rev = %d, want %d", i, ret.Rev, wrev)
-		}
-
-		wstart := newRevBytes()
-		revToBytes(tt.idxr.revs[0], wstart)
-		wact := []testutil.Action{
-			{Name: "range", Params: []interface{}{keyBucketName, wstart, []byte(nil), int64(0)}},
-		}
-		if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
-			t.Errorf("#%d: tx action = %+v, want %+v", i, g, wact)
-		}
-		wact = []testutil.Action{
-			{Name: "range", Params: []interface{}{[]byte("foo"), []byte("goo"), wrev}},
-		}
-		if g := fi.Action(); !reflect.DeepEqual(g, wact) {
-			t.Errorf("#%d: index action = %+v, want %+v", i, g, wact)
-		}
-		if s.currentRev != 2 {
-			t.Errorf("#%d: current rev = %+v, want %+v", i, s.currentRev, 2)
-		}
-
-		s.Close()
-	}
-}
-
-func TestStoreDeleteRange(t *testing.T) {
-	key := newTestKeyBytes(revision{2, 0}, false)
-	kv := mvccpb.KeyValue{
-		Key:            []byte("foo"),
-		Value:          []byte("bar"),
-		CreateRevision: 1,
-		ModRevision:    2,
-		Version:        1,
-	}
-	kvb, err := kv.Marshal()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	tests := []struct {
-		rev revision
-		r   indexRangeResp
-		rr  rangeResp
-
-		wkey    []byte
-		wrev    revision
-		wrrev   int64
-		wdelrev revision
-	}{
-		{
-			revision{2, 0},
-			indexRangeResp{[][]byte{[]byte("foo")}, []revision{{2, 0}}},
-			rangeResp{[][]byte{key}, [][]byte{kvb}},
-
-			newTestKeyBytes(revision{3, 0}, true),
-			revision{3, 0},
-			2,
-			revision{3, 0},
-		},
-	}
-	for i, tt := range tests {
-		s := newFakeStore()
-		b := s.b.(*fakeBackend)
-		fi := s.kvindex.(*fakeIndex)
-
-		s.currentRev = tt.rev.main
-		fi.indexRangeRespc <- tt.r
-		b.tx.rangeRespc <- tt.rr
-
-		n, _ := s.DeleteRange([]byte("foo"), []byte("goo"))
-		if n != 1 {
-			t.Errorf("#%d: n = %d, want 1", i, n)
-		}
-
-		data, err := (&mvccpb.KeyValue{
-			Key: []byte("foo"),
-		}).Marshal()
-		if err != nil {
-			t.Errorf("#%d: marshal err = %v, want nil", i, err)
-		}
-		wact := []testutil.Action{
-			{Name: "seqput", Params: []interface{}{keyBucketName, tt.wkey, data}},
-		}
-		if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
-			t.Errorf("#%d: tx action = %+v, want %+v", i, g, wact)
-		}
-		wact = []testutil.Action{
-			{Name: "range", Params: []interface{}{[]byte("foo"), []byte("goo"), tt.wrrev}},
-			{Name: "tombstone", Params: []interface{}{[]byte("foo"), tt.wdelrev}},
-		}
-		if g := fi.Action(); !reflect.DeepEqual(g, wact) {
-			t.Errorf("#%d: index action = %+v, want %+v", i, g, wact)
-		}
-		if s.currentRev != tt.wrev.main {
-			t.Errorf("#%d: rev = %+v, want %+v", i, s.currentRev, tt.wrev)
-		}
-	}
-}
-
-func TestStoreCompact(t *testing.T) {
-	s := newFakeStore()
-	defer s.Close()
-	b := s.b.(*fakeBackend)
-	fi := s.kvindex.(*fakeIndex)
-
-	s.currentRev = 3
-	fi.indexCompactRespc <- map[revision]struct{}{{1, 0}: {}}
-	key1 := newTestKeyBytes(revision{1, 0}, false)
-	key2 := newTestKeyBytes(revision{2, 0}, false)
-	b.tx.rangeRespc <- rangeResp{[][]byte{key1, key2}, nil}
-
-	s.Compact(3)
-	s.fifoSched.WaitFinish(1)
-
-	if s.compactMainRev != 3 {
-		t.Errorf("compact main rev = %d, want 3", s.compactMainRev)
-	}
-	end := make([]byte, 8)
-	binary.BigEndian.PutUint64(end, uint64(4))
-	wact := []testutil.Action{
-		{Name: "put", Params: []interface{}{metaBucketName, scheduledCompactKeyName, newTestRevBytes(revision{3, 0})}},
-		{Name: "range", Params: []interface{}{keyBucketName, make([]byte, 17), end, int64(10000)}},
-		{Name: "delete", Params: []interface{}{keyBucketName, key2}},
-		{Name: "put", Params: []interface{}{metaBucketName, finishedCompactKeyName, newTestRevBytes(revision{3, 0})}},
-	}
-	if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
-		t.Errorf("tx actions = %+v, want %+v", g, wact)
-	}
-	wact = []testutil.Action{
-		{Name: "compact", Params: []interface{}{int64(3)}},
-	}
-	if g := fi.Action(); !reflect.DeepEqual(g, wact) {
-		t.Errorf("index action = %+v, want %+v", g, wact)
-	}
-}
-
-func TestStoreRestore(t *testing.T) {
-	s := newFakeStore()
-	b := s.b.(*fakeBackend)
-	fi := s.kvindex.(*fakeIndex)
-
-	putkey := newTestKeyBytes(revision{3, 0}, false)
-	putkv := mvccpb.KeyValue{
-		Key:            []byte("foo"),
-		Value:          []byte("bar"),
-		CreateRevision: 4,
-		ModRevision:    4,
-		Version:        1,
-	}
-	putkvb, err := putkv.Marshal()
-	if err != nil {
-		t.Fatal(err)
-	}
-	delkey := newTestKeyBytes(revision{5, 0}, true)
-	delkv := mvccpb.KeyValue{
-		Key: []byte("foo"),
-	}
-	delkvb, err := delkv.Marshal()
-	if err != nil {
-		t.Fatal(err)
-	}
-	b.tx.rangeRespc <- rangeResp{[][]byte{finishedCompactKeyName}, [][]byte{newTestRevBytes(revision{3, 0})}}
-	b.tx.rangeRespc <- rangeResp{[][]byte{scheduledCompactKeyName}, [][]byte{newTestRevBytes(revision{3, 0})}}
-
-	b.tx.rangeRespc <- rangeResp{[][]byte{putkey, delkey}, [][]byte{putkvb, delkvb}}
-	b.tx.rangeRespc <- rangeResp{nil, nil}
-
-	s.restore()
-
-	if s.compactMainRev != 3 {
-		t.Errorf("compact rev = %d, want 5", s.compactMainRev)
-	}
-	if s.currentRev != 5 {
-		t.Errorf("current rev = %v, want 5", s.currentRev)
-	}
-	wact := []testutil.Action{
-		{Name: "range", Params: []interface{}{metaBucketName, finishedCompactKeyName, []byte(nil), int64(0)}},
-		{Name: "range", Params: []interface{}{metaBucketName, scheduledCompactKeyName, []byte(nil), int64(0)}},
-		{Name: "range", Params: []interface{}{keyBucketName, newTestRevBytes(revision{1, 0}), newTestRevBytes(revision{math.MaxInt64, math.MaxInt64}), int64(restoreChunkKeys)}},
-	}
-	if g := b.tx.Action(); !reflect.DeepEqual(g, wact) {
-		t.Errorf("tx actions = %+v, want %+v", g, wact)
-	}
-
-	gens := []generation{
-		{created: revision{4, 0}, ver: 2, revs: []revision{{3, 0}, {5, 0}}},
-		{created: revision{0, 0}, ver: 0, revs: nil},
-	}
-	ki := &keyIndex{key: []byte("foo"), modified: revision{5, 0}, generations: gens}
-	wact = []testutil.Action{
-		{Name: "keyIndex", Params: []interface{}{ki}},
-		{Name: "insert", Params: []interface{}{ki}},
-	}
-	if g := fi.Action(); !reflect.DeepEqual(g, wact) {
-		t.Errorf("index action = %+v, want %+v", g, wact)
-	}
-}
-
-func TestRestoreDelete(t *testing.T) {
-	oldChunk := restoreChunkKeys
-	restoreChunkKeys = mrand.Intn(3) + 2
-	defer func() { restoreChunkKeys = oldChunk }()
-
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer os.Remove(tmpPath)
-
-	keys := make(map[string]struct{})
-	for i := 0; i < 20; i++ {
-		ks := fmt.Sprintf("foo-%d", i)
-		k := []byte(ks)
-		s.Put(k, []byte("bar"), lease.NoLease)
-		keys[ks] = struct{}{}
-		switch mrand.Intn(3) {
-		case 0:
-			// put random key from past via random range on map
-			ks = fmt.Sprintf("foo-%d", mrand.Intn(i+1))
-			s.Put([]byte(ks), []byte("baz"), lease.NoLease)
-			keys[ks] = struct{}{}
-		case 1:
-			// delete random key via random range on map
-			for k := range keys {
-				s.DeleteRange([]byte(k), nil)
-				delete(keys, k)
-				break
-			}
-		}
-	}
-	s.Close()
-
-	s = NewStore(b, &lease.FakeLessor{}, nil)
-	defer s.Close()
-	for i := 0; i < 20; i++ {
-		ks := fmt.Sprintf("foo-%d", i)
-		r, err := s.Range([]byte(ks), nil, RangeOptions{})
-		if err != nil {
-			t.Fatal(err)
-		}
-		if _, ok := keys[ks]; ok {
-			if len(r.KVs) == 0 {
-				t.Errorf("#%d: expected %q, got deleted", i, ks)
-			}
-		} else if len(r.KVs) != 0 {
-			t.Errorf("#%d: expected deleted, got %q", i, ks)
-		}
-	}
-}
-
-func TestRestoreContinueUnfinishedCompaction(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s0 := NewStore(b, &lease.FakeLessor{}, nil)
-	defer os.Remove(tmpPath)
-
-	s0.Put([]byte("foo"), []byte("bar"), lease.NoLease)
-	s0.Put([]byte("foo"), []byte("bar1"), lease.NoLease)
-	s0.Put([]byte("foo"), []byte("bar2"), lease.NoLease)
-
-	// write scheduled compaction, but not do compaction
-	rbytes := newRevBytes()
-	revToBytes(revision{main: 2}, rbytes)
-	tx := s0.b.BatchTx()
-	tx.Lock()
-	tx.UnsafePut(metaBucketName, scheduledCompactKeyName, rbytes)
-	tx.Unlock()
-
-	s0.Close()
-
-	s1 := NewStore(b, &lease.FakeLessor{}, nil)
-
-	// wait for scheduled compaction to be finished
-	time.Sleep(100 * time.Millisecond)
-
-	if _, err := s1.Range([]byte("foo"), nil, RangeOptions{Rev: 1}); err != ErrCompacted {
-		t.Errorf("range on compacted rev error = %v, want %v", err, ErrCompacted)
-	}
-	// check the key in backend is deleted
-	revbytes := newRevBytes()
-	revToBytes(revision{main: 1}, revbytes)
-
-	// The disk compaction is done asynchronously and requires more time on slow disk.
-	// try 5 times for CI with slow IO.
-	for i := 0; i < 5; i++ {
-		tx = s1.b.BatchTx()
-		tx.Lock()
-		ks, _ := tx.UnsafeRange(keyBucketName, revbytes, nil, 0)
-		tx.Unlock()
-		if len(ks) != 0 {
-			time.Sleep(100 * time.Millisecond)
-			continue
-		}
-		return
-	}
-
-	t.Errorf("key for rev %+v still exists, want deleted", bytesToRev(revbytes))
-}
-
-type hashKVResult struct {
-	hash       uint32
-	compactRev int64
-}
-
-// TestHashKVWhenCompacting ensures that HashKV returns correct hash when compacting.
-func TestHashKVWhenCompacting(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer os.Remove(tmpPath)
-
-	rev := 10000
-	for i := 2; i <= rev; i++ {
-		s.Put([]byte("foo"), []byte(fmt.Sprintf("bar%d", i)), lease.NoLease)
-	}
-
-	hashCompactc := make(chan hashKVResult, 1)
-
-	donec := make(chan struct{})
-	var wg sync.WaitGroup
-	for i := 0; i < 10; i++ {
-		wg.Add(1)
-		go func() {
-			defer wg.Done()
-			for {
-				hash, _, compactRev, err := s.HashByRev(int64(rev))
-				if err != nil {
-					t.Fatal(err)
-				}
-				select {
-				case <-donec:
-					return
-				case hashCompactc <- hashKVResult{hash, compactRev}:
-				}
-			}
-		}()
-	}
-
-	go func() {
-		defer close(donec)
-		revHash := make(map[int64]uint32)
-		for round := 0; round < 1000; round++ {
-			r := <-hashCompactc
-			if revHash[r.compactRev] == 0 {
-				revHash[r.compactRev] = r.hash
-			}
-			if r.hash != revHash[r.compactRev] {
-				t.Fatalf("Hashes differ (current %v) != (saved %v)", r.hash, revHash[r.compactRev])
-			}
-		}
-	}()
-
-	wg.Add(1)
-	go func() {
-		defer wg.Done()
-		for i := 100; i >= 0; i-- {
-			_, err := s.Compact(int64(rev - 1 - i))
-			if err != nil {
-				t.Fatal(err)
-			}
-			time.Sleep(10 * time.Millisecond)
-		}
-	}()
-
-	select {
-	case <-donec:
-		wg.Wait()
-	case <-time.After(10 * time.Second):
-		testutil.FatalStack(t, "timeout")
-	}
-}
-
-// TestHashKVZeroRevision ensures that "HashByRev(0)" computes
-// correct hash value with latest revision.
-func TestHashKVZeroRevision(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer os.Remove(tmpPath)
-
-	rev := 1000
-	for i := 2; i <= rev; i++ {
-		s.Put([]byte("foo"), []byte(fmt.Sprintf("bar%d", i)), lease.NoLease)
-	}
-	if _, err := s.Compact(int64(rev / 2)); err != nil {
-		t.Fatal(err)
-	}
-
-	hash1, _, _, err := s.HashByRev(int64(rev))
-	if err != nil {
-		t.Fatal(err)
-	}
-	var hash2 uint32
-	hash2, _, _, err = s.HashByRev(0)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if hash1 != hash2 {
-		t.Errorf("hash %d (rev %d) != hash %d (rev 0)", hash1, rev, hash2)
-	}
-}
-
-func TestTxnPut(t *testing.T) {
-	// assign arbitrary size
-	bytesN := 30
-	sliceN := 100
-	keys := createBytesSlice(bytesN, sliceN)
-	vals := createBytesSlice(bytesN, sliceN)
-
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	for i := 0; i < sliceN; i++ {
-		txn := s.Write()
-		base := int64(i + 2)
-		if rev := txn.Put(keys[i], vals[i], lease.NoLease); rev != base {
-			t.Errorf("#%d: rev = %d, want %d", i, rev, base)
-		}
-		txn.End()
-	}
-}
-
-func TestTxnBlockBackendForceCommit(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(b, &lease.FakeLessor{}, nil)
-	defer os.Remove(tmpPath)
-
-	txn := s.Read()
-
-	done := make(chan struct{})
-	go func() {
-		s.b.ForceCommit()
-		done <- struct{}{}
-	}()
-	select {
-	case <-done:
-		t.Fatalf("failed to block ForceCommit")
-	case <-time.After(100 * time.Millisecond):
-	}
-
-	txn.End()
-	select {
-	case <-done:
-	case <-time.After(5 * time.Second): // wait 5 seconds for CI with slow IO
-		testutil.FatalStack(t, "failed to execute ForceCommit")
-	}
-}
-
-// TODO: test attach key to lessor
-
-func newTestRevBytes(rev revision) []byte {
-	bytes := newRevBytes()
-	revToBytes(rev, bytes)
-	return bytes
-}
-
-func newTestKeyBytes(rev revision, tombstone bool) []byte {
-	bytes := newRevBytes()
-	revToBytes(rev, bytes)
-	if tombstone {
-		bytes = appendMarkTombstone(bytes)
-	}
-	return bytes
-}
-
-func newFakeStore() *store {
-	b := &fakeBackend{&fakeBatchTx{
-		Recorder:   &testutil.RecorderBuffered{},
-		rangeRespc: make(chan rangeResp, 5)}}
-	fi := &fakeIndex{
-		Recorder:              &testutil.RecorderBuffered{},
-		indexGetRespc:         make(chan indexGetResp, 1),
-		indexRangeRespc:       make(chan indexRangeResp, 1),
-		indexRangeEventsRespc: make(chan indexRangeEventsResp, 1),
-		indexCompactRespc:     make(chan map[revision]struct{}, 1),
-	}
-	s := &store{
-		b:              b,
-		le:             &lease.FakeLessor{},
-		kvindex:        fi,
-		currentRev:     0,
-		compactMainRev: -1,
-		fifoSched:      schedule.NewFIFOScheduler(),
-		stopc:          make(chan struct{}),
-	}
-	s.ReadView, s.WriteView = &readView{s}, &writeView{s}
-	return s
-}
-
-type rangeResp struct {
-	keys [][]byte
-	vals [][]byte
-}
-
-type fakeBatchTx struct {
-	testutil.Recorder
-	rangeRespc chan rangeResp
-}
-
-func (b *fakeBatchTx) Lock()                          {}
-func (b *fakeBatchTx) Unlock()                        {}
-func (b *fakeBatchTx) UnsafeCreateBucket(name []byte) {}
-func (b *fakeBatchTx) UnsafePut(bucketName []byte, key []byte, value []byte) {
-	b.Recorder.Record(testutil.Action{Name: "put", Params: []interface{}{bucketName, key, value}})
-}
-func (b *fakeBatchTx) UnsafeSeqPut(bucketName []byte, key []byte, value []byte) {
-	b.Recorder.Record(testutil.Action{Name: "seqput", Params: []interface{}{bucketName, key, value}})
-}
-func (b *fakeBatchTx) UnsafeRange(bucketName []byte, key, endKey []byte, limit int64) (keys [][]byte, vals [][]byte) {
-	b.Recorder.Record(testutil.Action{Name: "range", Params: []interface{}{bucketName, key, endKey, limit}})
-	r := <-b.rangeRespc
-	return r.keys, r.vals
-}
-func (b *fakeBatchTx) UnsafeDelete(bucketName []byte, key []byte) {
-	b.Recorder.Record(testutil.Action{Name: "delete", Params: []interface{}{bucketName, key}})
-}
-func (b *fakeBatchTx) UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error {
-	return nil
-}
-func (b *fakeBatchTx) Commit()        {}
-func (b *fakeBatchTx) CommitAndStop() {}
-
-type fakeBackend struct {
-	tx *fakeBatchTx
-}
-
-func (b *fakeBackend) BatchTx() backend.BatchTx                                    { return b.tx }
-func (b *fakeBackend) ReadTx() backend.ReadTx                                      { return b.tx }
-func (b *fakeBackend) Hash(ignores map[backend.IgnoreKey]struct{}) (uint32, error) { return 0, nil }
-func (b *fakeBackend) Size() int64                                                 { return 0 }
-func (b *fakeBackend) Snapshot() backend.Snapshot                                  { return nil }
-func (b *fakeBackend) ForceCommit()                                                {}
-func (b *fakeBackend) Defrag() error                                               { return nil }
-func (b *fakeBackend) Close() error                                                { return nil }
-
-type indexGetResp struct {
-	rev     revision
-	created revision
-	ver     int64
-	err     error
-}
-
-type indexRangeResp struct {
-	keys [][]byte
-	revs []revision
-}
-
-type indexRangeEventsResp struct {
-	revs []revision
-}
-
-type fakeIndex struct {
-	testutil.Recorder
-	indexGetRespc         chan indexGetResp
-	indexRangeRespc       chan indexRangeResp
-	indexRangeEventsRespc chan indexRangeEventsResp
-	indexCompactRespc     chan map[revision]struct{}
-}
-
-func (i *fakeIndex) Revisions(key, end []byte, atRev int64) []revision {
-	_, rev := i.Range(key, end, atRev)
-	return rev
-}
-
-func (i *fakeIndex) Get(key []byte, atRev int64) (rev, created revision, ver int64, err error) {
-	i.Recorder.Record(testutil.Action{Name: "get", Params: []interface{}{key, atRev}})
-	r := <-i.indexGetRespc
-	return r.rev, r.created, r.ver, r.err
-}
-func (i *fakeIndex) Range(key, end []byte, atRev int64) ([][]byte, []revision) {
-	i.Recorder.Record(testutil.Action{Name: "range", Params: []interface{}{key, end, atRev}})
-	r := <-i.indexRangeRespc
-	return r.keys, r.revs
-}
-func (i *fakeIndex) Put(key []byte, rev revision) {
-	i.Recorder.Record(testutil.Action{Name: "put", Params: []interface{}{key, rev}})
-}
-func (i *fakeIndex) Tombstone(key []byte, rev revision) error {
-	i.Recorder.Record(testutil.Action{Name: "tombstone", Params: []interface{}{key, rev}})
-	return nil
-}
-func (i *fakeIndex) RangeSince(key, end []byte, rev int64) []revision {
-	i.Recorder.Record(testutil.Action{Name: "rangeEvents", Params: []interface{}{key, end, rev}})
-	r := <-i.indexRangeEventsRespc
-	return r.revs
-}
-func (i *fakeIndex) Compact(rev int64) map[revision]struct{} {
-	i.Recorder.Record(testutil.Action{Name: "compact", Params: []interface{}{rev}})
-	return <-i.indexCompactRespc
-}
-func (i *fakeIndex) Keep(rev int64) map[revision]struct{} {
-	i.Recorder.Record(testutil.Action{Name: "keep", Params: []interface{}{rev}})
-	return <-i.indexCompactRespc
-}
-func (i *fakeIndex) Equal(b index) bool { return false }
-
-func (i *fakeIndex) Insert(ki *keyIndex) {
-	i.Recorder.Record(testutil.Action{Name: "insert", Params: []interface{}{ki}})
-}
-
-func (i *fakeIndex) KeyIndex(ki *keyIndex) *keyIndex {
-	i.Recorder.Record(testutil.Action{Name: "keyIndex", Params: []interface{}{ki}})
-	return nil
-}
-
-func createBytesSlice(bytesN, sliceN int) [][]byte {
-	rs := [][]byte{}
-	for len(rs) != sliceN {
-		v := make([]byte, bytesN)
-		if _, err := rand.Read(v); err != nil {
-			panic(err)
-		}
-		rs = append(rs, v)
-	}
-	return rs
-}
diff --git a/mvcc/kvstore_txn.go b/mvcc/kvstore_txn.go
deleted file mode 100644
index 7122d64..0000000
--- a/mvcc/kvstore_txn.go
+++ /dev/null
@@ -1,253 +0,0 @@
-// Copyright 2017 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
-)
-
-type storeTxnRead struct {
-	s  *store
-	tx backend.ReadTx
-
-	firstRev int64
-	rev      int64
-}
-
-func (s *store) Read() TxnRead {
-	s.mu.RLock()
-	tx := s.b.ReadTx()
-	s.revMu.RLock()
-	tx.Lock()
-	firstRev, rev := s.compactMainRev, s.currentRev
-	s.revMu.RUnlock()
-	return newMetricsTxnRead(&storeTxnRead{s, tx, firstRev, rev})
-}
-
-func (tr *storeTxnRead) FirstRev() int64 { return tr.firstRev }
-func (tr *storeTxnRead) Rev() int64      { return tr.rev }
-
-func (tr *storeTxnRead) Range(key, end []byte, ro RangeOptions) (r *RangeResult, err error) {
-	return tr.rangeKeys(key, end, tr.Rev(), ro)
-}
-
-func (tr *storeTxnRead) End() {
-	tr.tx.Unlock()
-	tr.s.mu.RUnlock()
-}
-
-type storeTxnWrite struct {
-	storeTxnRead
-	tx backend.BatchTx
-	// beginRev is the revision where the txn begins; it will write to the next revision.
-	beginRev int64
-	changes  []mvccpb.KeyValue
-}
-
-func (s *store) Write() TxnWrite {
-	s.mu.RLock()
-	tx := s.b.BatchTx()
-	tx.Lock()
-	tw := &storeTxnWrite{
-		storeTxnRead: storeTxnRead{s, tx, 0, 0},
-		tx:           tx,
-		beginRev:     s.currentRev,
-		changes:      make([]mvccpb.KeyValue, 0, 4),
-	}
-	return newMetricsTxnWrite(tw)
-}
-
-func (tw *storeTxnWrite) Rev() int64 { return tw.beginRev }
-
-func (tw *storeTxnWrite) Range(key, end []byte, ro RangeOptions) (r *RangeResult, err error) {
-	rev := tw.beginRev
-	if len(tw.changes) > 0 {
-		rev++
-	}
-	return tw.rangeKeys(key, end, rev, ro)
-}
-
-func (tw *storeTxnWrite) DeleteRange(key, end []byte) (int64, int64) {
-	if n := tw.deleteRange(key, end); n != 0 || len(tw.changes) > 0 {
-		return n, int64(tw.beginRev + 1)
-	}
-	return 0, int64(tw.beginRev)
-}
-
-func (tw *storeTxnWrite) Put(key, value []byte, lease lease.LeaseID) int64 {
-	tw.put(key, value, lease)
-	return int64(tw.beginRev + 1)
-}
-
-func (tw *storeTxnWrite) End() {
-	// only update index if the txn modifies the mvcc state.
-	if len(tw.changes) != 0 {
-		tw.s.saveIndex(tw.tx)
-		// hold revMu lock to prevent new read txns from opening until writeback.
-		tw.s.revMu.Lock()
-		tw.s.currentRev++
-	}
-	tw.tx.Unlock()
-	if len(tw.changes) != 0 {
-		tw.s.revMu.Unlock()
-	}
-	tw.s.mu.RUnlock()
-}
-
-func (tr *storeTxnRead) rangeKeys(key, end []byte, curRev int64, ro RangeOptions) (*RangeResult, error) {
-	rev := ro.Rev
-	if rev > curRev {
-		return &RangeResult{KVs: nil, Count: -1, Rev: curRev}, ErrFutureRev
-	}
-	if rev <= 0 {
-		rev = curRev
-	}
-	if rev < tr.s.compactMainRev {
-		return &RangeResult{KVs: nil, Count: -1, Rev: 0}, ErrCompacted
-	}
-
-	revpairs := tr.s.kvindex.Revisions(key, end, int64(rev))
-	if len(revpairs) == 0 {
-		return &RangeResult{KVs: nil, Count: 0, Rev: curRev}, nil
-	}
-	if ro.Count {
-		return &RangeResult{KVs: nil, Count: len(revpairs), Rev: curRev}, nil
-	}
-
-	limit := int(ro.Limit)
-	if limit <= 0 || limit > len(revpairs) {
-		limit = len(revpairs)
-	}
-
-	kvs := make([]mvccpb.KeyValue, limit)
-	revBytes := newRevBytes()
-	for i, revpair := range revpairs[:len(kvs)] {
-		revToBytes(revpair, revBytes)
-		_, vs := tr.tx.UnsafeRange(keyBucketName, revBytes, nil, 0)
-		if len(vs) != 1 {
-			plog.Fatalf("range cannot find rev (%d,%d)", revpair.main, revpair.sub)
-		}
-		if err := kvs[i].Unmarshal(vs[0]); err != nil {
-			plog.Fatalf("cannot unmarshal event: %v", err)
-		}
-	}
-	return &RangeResult{KVs: kvs, Count: len(revpairs), Rev: curRev}, nil
-}
-
-func (tw *storeTxnWrite) put(key, value []byte, leaseID lease.LeaseID) {
-	rev := tw.beginRev + 1
-	c := rev
-	oldLease := lease.NoLease
-
-	// if the key exists before, use its previous created and
-	// get its previous leaseID
-	_, created, ver, err := tw.s.kvindex.Get(key, rev)
-	if err == nil {
-		c = created.main
-		oldLease = tw.s.le.GetLease(lease.LeaseItem{Key: string(key)})
-	}
-
-	ibytes := newRevBytes()
-	idxRev := revision{main: rev, sub: int64(len(tw.changes))}
-	revToBytes(idxRev, ibytes)
-
-	ver = ver + 1
-	kv := mvccpb.KeyValue{
-		Key:            key,
-		Value:          value,
-		CreateRevision: c,
-		ModRevision:    rev,
-		Version:        ver,
-		Lease:          int64(leaseID),
-	}
-
-	d, err := kv.Marshal()
-	if err != nil {
-		plog.Fatalf("cannot marshal event: %v", err)
-	}
-
-	tw.tx.UnsafeSeqPut(keyBucketName, ibytes, d)
-	tw.s.kvindex.Put(key, idxRev)
-	tw.changes = append(tw.changes, kv)
-
-	if oldLease != lease.NoLease {
-		if tw.s.le == nil {
-			panic("no lessor to detach lease")
-		}
-		err = tw.s.le.Detach(oldLease, []lease.LeaseItem{{Key: string(key)}})
-		if err != nil {
-			plog.Errorf("unexpected error from lease detach: %v", err)
-		}
-	}
-	if leaseID != lease.NoLease {
-		if tw.s.le == nil {
-			panic("no lessor to attach lease")
-		}
-		err = tw.s.le.Attach(leaseID, []lease.LeaseItem{{Key: string(key)}})
-		if err != nil {
-			panic("unexpected error from lease Attach")
-		}
-	}
-}
-
-func (tw *storeTxnWrite) deleteRange(key, end []byte) int64 {
-	rrev := tw.beginRev
-	if len(tw.changes) > 0 {
-		rrev += 1
-	}
-	keys, revs := tw.s.kvindex.Range(key, end, rrev)
-	if len(keys) == 0 {
-		return 0
-	}
-	for i, key := range keys {
-		tw.delete(key, revs[i])
-	}
-	return int64(len(keys))
-}
-
-func (tw *storeTxnWrite) delete(key []byte, rev revision) {
-	ibytes := newRevBytes()
-	idxRev := revision{main: tw.beginRev + 1, sub: int64(len(tw.changes))}
-	revToBytes(idxRev, ibytes)
-	ibytes = appendMarkTombstone(ibytes)
-
-	kv := mvccpb.KeyValue{Key: key}
-
-	d, err := kv.Marshal()
-	if err != nil {
-		plog.Fatalf("cannot marshal event: %v", err)
-	}
-
-	tw.tx.UnsafeSeqPut(keyBucketName, ibytes, d)
-	err = tw.s.kvindex.Tombstone(key, idxRev)
-	if err != nil {
-		plog.Fatalf("cannot tombstone an existing key (%s): %v", string(key), err)
-	}
-	tw.changes = append(tw.changes, kv)
-
-	item := lease.LeaseItem{Key: string(key)}
-	leaseID := tw.s.le.GetLease(item)
-
-	if leaseID != lease.NoLease {
-		err = tw.s.le.Detach(leaseID, []lease.LeaseItem{item})
-		if err != nil {
-			plog.Errorf("cannot detach %v", err)
-		}
-	}
-}
-
-func (tw *storeTxnWrite) Changes() []mvccpb.KeyValue { return tw.changes }
diff --git a/mvcc/metrics.go b/mvcc/metrics.go
deleted file mode 100644
index e44eb12..0000000
--- a/mvcc/metrics.go
+++ /dev/null
@@ -1,183 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"sync"
-
-	"github.com/prometheus/client_golang/prometheus"
-)
-
-var (
-	rangeCounter = prometheus.NewCounter(
-		prometheus.CounterOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "range_total",
-			Help:      "Total number of ranges seen by this member.",
-		})
-
-	putCounter = prometheus.NewCounter(
-		prometheus.CounterOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "put_total",
-			Help:      "Total number of puts seen by this member.",
-		})
-
-	deleteCounter = prometheus.NewCounter(
-		prometheus.CounterOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "delete_total",
-			Help:      "Total number of deletes seen by this member.",
-		})
-
-	txnCounter = prometheus.NewCounter(
-		prometheus.CounterOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "txn_total",
-			Help:      "Total number of txns seen by this member.",
-		})
-
-	keysGauge = prometheus.NewGauge(
-		prometheus.GaugeOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "keys_total",
-			Help:      "Total number of keys.",
-		})
-
-	watchStreamGauge = prometheus.NewGauge(
-		prometheus.GaugeOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "watch_stream_total",
-			Help:      "Total number of watch streams.",
-		})
-
-	watcherGauge = prometheus.NewGauge(
-		prometheus.GaugeOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "watcher_total",
-			Help:      "Total number of watchers.",
-		})
-
-	slowWatcherGauge = prometheus.NewGauge(
-		prometheus.GaugeOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "slow_watcher_total",
-			Help:      "Total number of unsynced slow watchers.",
-		})
-
-	totalEventsCounter = prometheus.NewCounter(
-		prometheus.CounterOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "events_total",
-			Help:      "Total number of events sent by this member.",
-		})
-
-	pendingEventsGauge = prometheus.NewGauge(
-		prometheus.GaugeOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "pending_events_total",
-			Help:      "Total number of pending events to be sent.",
-		})
-
-	indexCompactionPauseDurations = prometheus.NewHistogram(
-		prometheus.HistogramOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "index_compaction_pause_duration_milliseconds",
-			Help:      "Bucketed histogram of index compaction pause duration.",
-			// 0.5ms -> 1second
-			Buckets: prometheus.ExponentialBuckets(0.5, 2, 12),
-		})
-
-	dbCompactionPauseDurations = prometheus.NewHistogram(
-		prometheus.HistogramOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "db_compaction_pause_duration_milliseconds",
-			Help:      "Bucketed histogram of db compaction pause duration.",
-			// 1ms -> 4second
-			Buckets: prometheus.ExponentialBuckets(1, 2, 13),
-		})
-
-	dbCompactionTotalDurations = prometheus.NewHistogram(
-		prometheus.HistogramOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "db_compaction_total_duration_milliseconds",
-			Help:      "Bucketed histogram of db compaction total duration.",
-			// 100ms -> 800second
-			Buckets: prometheus.ExponentialBuckets(100, 2, 14),
-		})
-
-	dbCompactionKeysCounter = prometheus.NewCounter(
-		prometheus.CounterOpts{
-			Namespace: "etcd_debugging",
-			Subsystem: "mvcc",
-			Name:      "db_compaction_keys_total",
-			Help:      "Total number of db keys compacted.",
-		})
-
-	dbTotalSize = prometheus.NewGaugeFunc(prometheus.GaugeOpts{
-		Namespace: "etcd_debugging",
-		Subsystem: "mvcc",
-		Name:      "db_total_size_in_bytes",
-		Help:      "Total size of the underlying database in bytes.",
-	},
-		func() float64 {
-			reportDbTotalSizeInBytesMu.RLock()
-			defer reportDbTotalSizeInBytesMu.RUnlock()
-			return reportDbTotalSizeInBytes()
-		},
-	)
-	// overridden by mvcc initialization
-	reportDbTotalSizeInBytesMu sync.RWMutex
-	reportDbTotalSizeInBytes   func() float64 = func() float64 { return 0 }
-)
-
-func init() {
-	prometheus.MustRegister(rangeCounter)
-	prometheus.MustRegister(putCounter)
-	prometheus.MustRegister(deleteCounter)
-	prometheus.MustRegister(txnCounter)
-	prometheus.MustRegister(keysGauge)
-	prometheus.MustRegister(watchStreamGauge)
-	prometheus.MustRegister(watcherGauge)
-	prometheus.MustRegister(slowWatcherGauge)
-	prometheus.MustRegister(totalEventsCounter)
-	prometheus.MustRegister(pendingEventsGauge)
-	prometheus.MustRegister(indexCompactionPauseDurations)
-	prometheus.MustRegister(dbCompactionPauseDurations)
-	prometheus.MustRegister(dbCompactionTotalDurations)
-	prometheus.MustRegister(dbCompactionKeysCounter)
-	prometheus.MustRegister(dbTotalSize)
-}
-
-// ReportEventReceived reports that an event is received.
-// This function should be called when the external systems received an
-// event from mvcc.Watcher.
-func ReportEventReceived(n int) {
-	pendingEventsGauge.Sub(float64(n))
-	totalEventsCounter.Add(float64(n))
-}
diff --git a/mvcc/metrics_txn.go b/mvcc/metrics_txn.go
deleted file mode 100644
index 8f81f45..0000000
--- a/mvcc/metrics_txn.go
+++ /dev/null
@@ -1,59 +0,0 @@
-// Copyright 2017 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"github.com/coreos/etcd/internal/lease"
-)
-
-type metricsTxnWrite struct {
-	TxnWrite
-	ranges  uint
-	puts    uint
-	deletes uint
-}
-
-func newMetricsTxnRead(tr TxnRead) TxnRead {
-	return &metricsTxnWrite{&txnReadWrite{tr}, 0, 0, 0}
-}
-
-func newMetricsTxnWrite(tw TxnWrite) TxnWrite {
-	return &metricsTxnWrite{tw, 0, 0, 0}
-}
-
-func (tw *metricsTxnWrite) Range(key, end []byte, ro RangeOptions) (*RangeResult, error) {
-	tw.ranges++
-	return tw.TxnWrite.Range(key, end, ro)
-}
-
-func (tw *metricsTxnWrite) DeleteRange(key, end []byte) (n, rev int64) {
-	tw.deletes++
-	return tw.TxnWrite.DeleteRange(key, end)
-}
-
-func (tw *metricsTxnWrite) Put(key, value []byte, lease lease.LeaseID) (rev int64) {
-	tw.puts++
-	return tw.TxnWrite.Put(key, value, lease)
-}
-
-func (tw *metricsTxnWrite) End() {
-	defer tw.TxnWrite.End()
-	if sum := tw.ranges + tw.puts + tw.deletes; sum > 1 {
-		txnCounter.Inc()
-	}
-	rangeCounter.Add(float64(tw.ranges))
-	putCounter.Add(float64(tw.puts))
-	deleteCounter.Add(float64(tw.deletes))
-}
diff --git a/mvcc/mvccpb/kv.pb.go b/mvcc/mvccpb/kv.pb.go
deleted file mode 100644
index 23fe337..0000000
--- a/mvcc/mvccpb/kv.pb.go
+++ /dev/null
@@ -1,718 +0,0 @@
-// Code generated by protoc-gen-gogo. DO NOT EDIT.
-// source: kv.proto
-
-/*
-	Package mvccpb is a generated protocol buffer package.
-
-	It is generated from these files:
-		kv.proto
-
-	It has these top-level messages:
-		KeyValue
-		Event
-*/
-package mvccpb
-
-import (
-	"fmt"
-
-	proto "github.com/golang/protobuf/proto"
-
-	math "math"
-
-	_ "github.com/gogo/protobuf/gogoproto"
-
-	io "io"
-)
-
-// Reference imports to suppress errors if they are not otherwise used.
-var _ = proto.Marshal
-var _ = fmt.Errorf
-var _ = math.Inf
-
-// This is a compile-time assertion to ensure that this generated file
-// is compatible with the proto package it is being compiled against.
-// A compilation error at this line likely means your copy of the
-// proto package needs to be updated.
-const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package
-
-type Event_EventType int32
-
-const (
-	PUT    Event_EventType = 0
-	DELETE Event_EventType = 1
-)
-
-var Event_EventType_name = map[int32]string{
-	0: "PUT",
-	1: "DELETE",
-}
-var Event_EventType_value = map[string]int32{
-	"PUT":    0,
-	"DELETE": 1,
-}
-
-func (x Event_EventType) String() string {
-	return proto.EnumName(Event_EventType_name, int32(x))
-}
-func (Event_EventType) EnumDescriptor() ([]byte, []int) { return fileDescriptorKv, []int{1, 0} }
-
-type KeyValue struct {
-	// key is the key in bytes. An empty key is not allowed.
-	Key []byte `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
-	// create_revision is the revision of last creation on this key.
-	CreateRevision int64 `protobuf:"varint,2,opt,name=create_revision,json=createRevision,proto3" json:"create_revision,omitempty"`
-	// mod_revision is the revision of last modification on this key.
-	ModRevision int64 `protobuf:"varint,3,opt,name=mod_revision,json=modRevision,proto3" json:"mod_revision,omitempty"`
-	// version is the version of the key. A deletion resets
-	// the version to zero and any modification of the key
-	// increases its version.
-	Version int64 `protobuf:"varint,4,opt,name=version,proto3" json:"version,omitempty"`
-	// value is the value held by the key, in bytes.
-	Value []byte `protobuf:"bytes,5,opt,name=value,proto3" json:"value,omitempty"`
-	// lease is the ID of the lease that attached to key.
-	// When the attached lease expires, the key will be deleted.
-	// If lease is 0, then no lease is attached to the key.
-	Lease int64 `protobuf:"varint,6,opt,name=lease,proto3" json:"lease,omitempty"`
-}
-
-func (m *KeyValue) Reset()                    { *m = KeyValue{} }
-func (m *KeyValue) String() string            { return proto.CompactTextString(m) }
-func (*KeyValue) ProtoMessage()               {}
-func (*KeyValue) Descriptor() ([]byte, []int) { return fileDescriptorKv, []int{0} }
-
-type Event struct {
-	// type is the kind of event. If type is a PUT, it indicates
-	// new data has been stored to the key. If type is a DELETE,
-	// it indicates the key was deleted.
-	Type Event_EventType `protobuf:"varint,1,opt,name=type,proto3,enum=mvccpb.Event_EventType" json:"type,omitempty"`
-	// kv holds the KeyValue for the event.
-	// A PUT event contains current kv pair.
-	// A PUT event with kv.Version=1 indicates the creation of a key.
-	// A DELETE/EXPIRE event contains the deleted key with
-	// its modification revision set to the revision of deletion.
-	Kv *KeyValue `protobuf:"bytes,2,opt,name=kv" json:"kv,omitempty"`
-	// prev_kv holds the key-value pair before the event happens.
-	PrevKv *KeyValue `protobuf:"bytes,3,opt,name=prev_kv,json=prevKv" json:"prev_kv,omitempty"`
-}
-
-func (m *Event) Reset()                    { *m = Event{} }
-func (m *Event) String() string            { return proto.CompactTextString(m) }
-func (*Event) ProtoMessage()               {}
-func (*Event) Descriptor() ([]byte, []int) { return fileDescriptorKv, []int{1} }
-
-func init() {
-	proto.RegisterType((*KeyValue)(nil), "mvccpb.KeyValue")
-	proto.RegisterType((*Event)(nil), "mvccpb.Event")
-	proto.RegisterEnum("mvccpb.Event_EventType", Event_EventType_name, Event_EventType_value)
-}
-func (m *KeyValue) Marshal() (dAtA []byte, err error) {
-	size := m.Size()
-	dAtA = make([]byte, size)
-	n, err := m.MarshalTo(dAtA)
-	if err != nil {
-		return nil, err
-	}
-	return dAtA[:n], nil
-}
-
-func (m *KeyValue) MarshalTo(dAtA []byte) (int, error) {
-	var i int
-	_ = i
-	var l int
-	_ = l
-	if len(m.Key) > 0 {
-		dAtA[i] = 0xa
-		i++
-		i = encodeVarintKv(dAtA, i, uint64(len(m.Key)))
-		i += copy(dAtA[i:], m.Key)
-	}
-	if m.CreateRevision != 0 {
-		dAtA[i] = 0x10
-		i++
-		i = encodeVarintKv(dAtA, i, uint64(m.CreateRevision))
-	}
-	if m.ModRevision != 0 {
-		dAtA[i] = 0x18
-		i++
-		i = encodeVarintKv(dAtA, i, uint64(m.ModRevision))
-	}
-	if m.Version != 0 {
-		dAtA[i] = 0x20
-		i++
-		i = encodeVarintKv(dAtA, i, uint64(m.Version))
-	}
-	if len(m.Value) > 0 {
-		dAtA[i] = 0x2a
-		i++
-		i = encodeVarintKv(dAtA, i, uint64(len(m.Value)))
-		i += copy(dAtA[i:], m.Value)
-	}
-	if m.Lease != 0 {
-		dAtA[i] = 0x30
-		i++
-		i = encodeVarintKv(dAtA, i, uint64(m.Lease))
-	}
-	return i, nil
-}
-
-func (m *Event) Marshal() (dAtA []byte, err error) {
-	size := m.Size()
-	dAtA = make([]byte, size)
-	n, err := m.MarshalTo(dAtA)
-	if err != nil {
-		return nil, err
-	}
-	return dAtA[:n], nil
-}
-
-func (m *Event) MarshalTo(dAtA []byte) (int, error) {
-	var i int
-	_ = i
-	var l int
-	_ = l
-	if m.Type != 0 {
-		dAtA[i] = 0x8
-		i++
-		i = encodeVarintKv(dAtA, i, uint64(m.Type))
-	}
-	if m.Kv != nil {
-		dAtA[i] = 0x12
-		i++
-		i = encodeVarintKv(dAtA, i, uint64(m.Kv.Size()))
-		n1, err := m.Kv.MarshalTo(dAtA[i:])
-		if err != nil {
-			return 0, err
-		}
-		i += n1
-	}
-	if m.PrevKv != nil {
-		dAtA[i] = 0x1a
-		i++
-		i = encodeVarintKv(dAtA, i, uint64(m.PrevKv.Size()))
-		n2, err := m.PrevKv.MarshalTo(dAtA[i:])
-		if err != nil {
-			return 0, err
-		}
-		i += n2
-	}
-	return i, nil
-}
-
-func encodeVarintKv(dAtA []byte, offset int, v uint64) int {
-	for v >= 1<<7 {
-		dAtA[offset] = uint8(v&0x7f | 0x80)
-		v >>= 7
-		offset++
-	}
-	dAtA[offset] = uint8(v)
-	return offset + 1
-}
-func (m *KeyValue) Size() (n int) {
-	var l int
-	_ = l
-	l = len(m.Key)
-	if l > 0 {
-		n += 1 + l + sovKv(uint64(l))
-	}
-	if m.CreateRevision != 0 {
-		n += 1 + sovKv(uint64(m.CreateRevision))
-	}
-	if m.ModRevision != 0 {
-		n += 1 + sovKv(uint64(m.ModRevision))
-	}
-	if m.Version != 0 {
-		n += 1 + sovKv(uint64(m.Version))
-	}
-	l = len(m.Value)
-	if l > 0 {
-		n += 1 + l + sovKv(uint64(l))
-	}
-	if m.Lease != 0 {
-		n += 1 + sovKv(uint64(m.Lease))
-	}
-	return n
-}
-
-func (m *Event) Size() (n int) {
-	var l int
-	_ = l
-	if m.Type != 0 {
-		n += 1 + sovKv(uint64(m.Type))
-	}
-	if m.Kv != nil {
-		l = m.Kv.Size()
-		n += 1 + l + sovKv(uint64(l))
-	}
-	if m.PrevKv != nil {
-		l = m.PrevKv.Size()
-		n += 1 + l + sovKv(uint64(l))
-	}
-	return n
-}
-
-func sovKv(x uint64) (n int) {
-	for {
-		n++
-		x >>= 7
-		if x == 0 {
-			break
-		}
-	}
-	return n
-}
-func sozKv(x uint64) (n int) {
-	return sovKv(uint64((x << 1) ^ uint64((int64(x) >> 63))))
-}
-func (m *KeyValue) Unmarshal(dAtA []byte) error {
-	l := len(dAtA)
-	iNdEx := 0
-	for iNdEx < l {
-		preIndex := iNdEx
-		var wire uint64
-		for shift := uint(0); ; shift += 7 {
-			if shift >= 64 {
-				return ErrIntOverflowKv
-			}
-			if iNdEx >= l {
-				return io.ErrUnexpectedEOF
-			}
-			b := dAtA[iNdEx]
-			iNdEx++
-			wire |= (uint64(b) & 0x7F) << shift
-			if b < 0x80 {
-				break
-			}
-		}
-		fieldNum := int32(wire >> 3)
-		wireType := int(wire & 0x7)
-		if wireType == 4 {
-			return fmt.Errorf("proto: KeyValue: wiretype end group for non-group")
-		}
-		if fieldNum <= 0 {
-			return fmt.Errorf("proto: KeyValue: illegal tag %d (wire type %d)", fieldNum, wire)
-		}
-		switch fieldNum {
-		case 1:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
-			}
-			var byteLen int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				byteLen |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			if byteLen < 0 {
-				return ErrInvalidLengthKv
-			}
-			postIndex := iNdEx + byteLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.Key = append(m.Key[:0], dAtA[iNdEx:postIndex]...)
-			if m.Key == nil {
-				m.Key = []byte{}
-			}
-			iNdEx = postIndex
-		case 2:
-			if wireType != 0 {
-				return fmt.Errorf("proto: wrong wireType = %d for field CreateRevision", wireType)
-			}
-			m.CreateRevision = 0
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				m.CreateRevision |= (int64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-		case 3:
-			if wireType != 0 {
-				return fmt.Errorf("proto: wrong wireType = %d for field ModRevision", wireType)
-			}
-			m.ModRevision = 0
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				m.ModRevision |= (int64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-		case 4:
-			if wireType != 0 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Version", wireType)
-			}
-			m.Version = 0
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				m.Version |= (int64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-		case 5:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Value", wireType)
-			}
-			var byteLen int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				byteLen |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			if byteLen < 0 {
-				return ErrInvalidLengthKv
-			}
-			postIndex := iNdEx + byteLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.Value = append(m.Value[:0], dAtA[iNdEx:postIndex]...)
-			if m.Value == nil {
-				m.Value = []byte{}
-			}
-			iNdEx = postIndex
-		case 6:
-			if wireType != 0 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Lease", wireType)
-			}
-			m.Lease = 0
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				m.Lease |= (int64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-		default:
-			iNdEx = preIndex
-			skippy, err := skipKv(dAtA[iNdEx:])
-			if err != nil {
-				return err
-			}
-			if skippy < 0 {
-				return ErrInvalidLengthKv
-			}
-			if (iNdEx + skippy) > l {
-				return io.ErrUnexpectedEOF
-			}
-			iNdEx += skippy
-		}
-	}
-
-	if iNdEx > l {
-		return io.ErrUnexpectedEOF
-	}
-	return nil
-}
-func (m *Event) Unmarshal(dAtA []byte) error {
-	l := len(dAtA)
-	iNdEx := 0
-	for iNdEx < l {
-		preIndex := iNdEx
-		var wire uint64
-		for shift := uint(0); ; shift += 7 {
-			if shift >= 64 {
-				return ErrIntOverflowKv
-			}
-			if iNdEx >= l {
-				return io.ErrUnexpectedEOF
-			}
-			b := dAtA[iNdEx]
-			iNdEx++
-			wire |= (uint64(b) & 0x7F) << shift
-			if b < 0x80 {
-				break
-			}
-		}
-		fieldNum := int32(wire >> 3)
-		wireType := int(wire & 0x7)
-		if wireType == 4 {
-			return fmt.Errorf("proto: Event: wiretype end group for non-group")
-		}
-		if fieldNum <= 0 {
-			return fmt.Errorf("proto: Event: illegal tag %d (wire type %d)", fieldNum, wire)
-		}
-		switch fieldNum {
-		case 1:
-			if wireType != 0 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
-			}
-			m.Type = 0
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				m.Type |= (Event_EventType(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-		case 2:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Kv", wireType)
-			}
-			var msglen int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			if msglen < 0 {
-				return ErrInvalidLengthKv
-			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			if m.Kv == nil {
-				m.Kv = &KeyValue{}
-			}
-			if err := m.Kv.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
-			iNdEx = postIndex
-		case 3:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field PrevKv", wireType)
-			}
-			var msglen int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			if msglen < 0 {
-				return ErrInvalidLengthKv
-			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			if m.PrevKv == nil {
-				m.PrevKv = &KeyValue{}
-			}
-			if err := m.PrevKv.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
-			iNdEx = postIndex
-		default:
-			iNdEx = preIndex
-			skippy, err := skipKv(dAtA[iNdEx:])
-			if err != nil {
-				return err
-			}
-			if skippy < 0 {
-				return ErrInvalidLengthKv
-			}
-			if (iNdEx + skippy) > l {
-				return io.ErrUnexpectedEOF
-			}
-			iNdEx += skippy
-		}
-	}
-
-	if iNdEx > l {
-		return io.ErrUnexpectedEOF
-	}
-	return nil
-}
-func skipKv(dAtA []byte) (n int, err error) {
-	l := len(dAtA)
-	iNdEx := 0
-	for iNdEx < l {
-		var wire uint64
-		for shift := uint(0); ; shift += 7 {
-			if shift >= 64 {
-				return 0, ErrIntOverflowKv
-			}
-			if iNdEx >= l {
-				return 0, io.ErrUnexpectedEOF
-			}
-			b := dAtA[iNdEx]
-			iNdEx++
-			wire |= (uint64(b) & 0x7F) << shift
-			if b < 0x80 {
-				break
-			}
-		}
-		wireType := int(wire & 0x7)
-		switch wireType {
-		case 0:
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return 0, ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return 0, io.ErrUnexpectedEOF
-				}
-				iNdEx++
-				if dAtA[iNdEx-1] < 0x80 {
-					break
-				}
-			}
-			return iNdEx, nil
-		case 1:
-			iNdEx += 8
-			return iNdEx, nil
-		case 2:
-			var length int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return 0, ErrIntOverflowKv
-				}
-				if iNdEx >= l {
-					return 0, io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				length |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			iNdEx += length
-			if length < 0 {
-				return 0, ErrInvalidLengthKv
-			}
-			return iNdEx, nil
-		case 3:
-			for {
-				var innerWire uint64
-				var start int = iNdEx
-				for shift := uint(0); ; shift += 7 {
-					if shift >= 64 {
-						return 0, ErrIntOverflowKv
-					}
-					if iNdEx >= l {
-						return 0, io.ErrUnexpectedEOF
-					}
-					b := dAtA[iNdEx]
-					iNdEx++
-					innerWire |= (uint64(b) & 0x7F) << shift
-					if b < 0x80 {
-						break
-					}
-				}
-				innerWireType := int(innerWire & 0x7)
-				if innerWireType == 4 {
-					break
-				}
-				next, err := skipKv(dAtA[start:])
-				if err != nil {
-					return 0, err
-				}
-				iNdEx = start + next
-			}
-			return iNdEx, nil
-		case 4:
-			return iNdEx, nil
-		case 5:
-			iNdEx += 4
-			return iNdEx, nil
-		default:
-			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
-		}
-	}
-	panic("unreachable")
-}
-
-var (
-	ErrInvalidLengthKv = fmt.Errorf("proto: negative length found during unmarshaling")
-	ErrIntOverflowKv   = fmt.Errorf("proto: integer overflow")
-)
-
-func init() { proto.RegisterFile("kv.proto", fileDescriptorKv) }
-
-var fileDescriptorKv = []byte{
-	// 303 bytes of a gzipped FileDescriptorProto
-	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x6c, 0x90, 0x41, 0x4e, 0xc2, 0x40,
-	0x14, 0x86, 0x3b, 0x14, 0x0a, 0x3e, 0x08, 0x36, 0x13, 0x12, 0x27, 0x2e, 0x26, 0x95, 0x8d, 0x18,
-	0x13, 0x4c, 0xf0, 0x06, 0xc6, 0xae, 0x70, 0x61, 0x1a, 0x74, 0x4b, 0x4a, 0x79, 0x21, 0xa4, 0x94,
-	0x69, 0x4a, 0x9d, 0xa4, 0x37, 0x71, 0xef, 0xde, 0x73, 0xb0, 0xe4, 0x08, 0x52, 0x2f, 0x62, 0xfa,
-	0xc6, 0xe2, 0xc6, 0xcd, 0xe4, 0xfd, 0xff, 0xff, 0x65, 0xe6, 0x7f, 0x03, 0x9d, 0x58, 0x8f, 0xd3,
-	0x4c, 0xe5, 0x8a, 0x3b, 0x89, 0x8e, 0xa2, 0x74, 0x71, 0x39, 0x58, 0xa9, 0x95, 0x22, 0xeb, 0xae,
-	0x9a, 0x4c, 0x3a, 0xfc, 0x64, 0xd0, 0x99, 0x62, 0xf1, 0x1a, 0x6e, 0xde, 0x90, 0xbb, 0x60, 0xc7,
-	0x58, 0x08, 0xe6, 0xb1, 0x51, 0x2f, 0xa8, 0x46, 0x7e, 0x0d, 0xe7, 0x51, 0x86, 0x61, 0x8e, 0xf3,
-	0x0c, 0xf5, 0x7a, 0xb7, 0x56, 0x5b, 0xd1, 0xf0, 0xd8, 0xc8, 0x0e, 0xfa, 0xc6, 0x0e, 0x7e, 0x5d,
-	0x7e, 0x05, 0xbd, 0x44, 0x2d, 0xff, 0x28, 0x9b, 0xa8, 0x6e, 0xa2, 0x96, 0x27, 0x44, 0x40, 0x5b,
-	0x63, 0x46, 0x69, 0x93, 0xd2, 0x5a, 0xf2, 0x01, 0xb4, 0x74, 0x55, 0x40, 0xb4, 0xe8, 0x65, 0x23,
-	0x2a, 0x77, 0x83, 0xe1, 0x0e, 0x85, 0x43, 0xb4, 0x11, 0xc3, 0x0f, 0x06, 0x2d, 0x5f, 0xe3, 0x36,
-	0xe7, 0xb7, 0xd0, 0xcc, 0x8b, 0x14, 0xa9, 0x6e, 0x7f, 0x72, 0x31, 0x36, 0x7b, 0x8e, 0x29, 0x34,
-	0xe7, 0xac, 0x48, 0x31, 0x20, 0x88, 0x7b, 0xd0, 0x88, 0x35, 0x75, 0xef, 0x4e, 0xdc, 0x1a, 0xad,
-	0x17, 0x0f, 0x1a, 0xb1, 0xe6, 0x37, 0xd0, 0x4e, 0x33, 0xd4, 0xf3, 0x58, 0x53, 0xf9, 0xff, 0x30,
-	0xa7, 0x02, 0xa6, 0x7a, 0xe8, 0xc1, 0xd9, 0xe9, 0x7e, 0xde, 0x06, 0xfb, 0xf9, 0x65, 0xe6, 0x5a,
-	0x1c, 0xc0, 0x79, 0xf4, 0x9f, 0xfc, 0x99, 0xef, 0xb2, 0x07, 0xb1, 0x3f, 0x4a, 0xeb, 0x70, 0x94,
-	0xd6, 0xbe, 0x94, 0xec, 0x50, 0x4a, 0xf6, 0x55, 0x4a, 0xf6, 0xfe, 0x2d, 0xad, 0x85, 0x43, 0xff,
-	0x7e, 0xff, 0x13, 0x00, 0x00, 0xff, 0xff, 0xb5, 0x45, 0x92, 0x5d, 0xa1, 0x01, 0x00, 0x00,
-}
diff --git a/mvcc/mvccpb/kv.proto b/mvcc/mvccpb/kv.proto
deleted file mode 100644
index 23c911b..0000000
--- a/mvcc/mvccpb/kv.proto
+++ /dev/null
@@ -1,49 +0,0 @@
-syntax = "proto3";
-package mvccpb;
-
-import "gogoproto/gogo.proto";
-
-option (gogoproto.marshaler_all) = true;
-option (gogoproto.sizer_all) = true;
-option (gogoproto.unmarshaler_all) = true;
-option (gogoproto.goproto_getters_all) = false;
-option (gogoproto.goproto_enum_prefix_all) = false;
-
-message KeyValue {
-  // key is the key in bytes. An empty key is not allowed.
-  bytes key = 1;
-  // create_revision is the revision of last creation on this key.
-  int64 create_revision = 2;
-  // mod_revision is the revision of last modification on this key.
-  int64 mod_revision = 3;
-  // version is the version of the key. A deletion resets
-  // the version to zero and any modification of the key
-  // increases its version.
-  int64 version = 4;
-  // value is the value held by the key, in bytes.
-  bytes value = 5;
-  // lease is the ID of the lease that attached to key.
-  // When the attached lease expires, the key will be deleted.
-  // If lease is 0, then no lease is attached to the key.
-  int64 lease = 6;
-}
-
-message Event {
-  enum EventType {
-    PUT = 0;
-    DELETE = 1;
-  }
-  // type is the kind of event. If type is a PUT, it indicates
-  // new data has been stored to the key. If type is a DELETE,
-  // it indicates the key was deleted.
-  EventType type = 1;
-  // kv holds the KeyValue for the event.
-  // A PUT event contains current kv pair.
-  // A PUT event with kv.Version=1 indicates the creation of a key.
-  // A DELETE/EXPIRE event contains the deleted key with
-  // its modification revision set to the revision of deletion.
-  KeyValue kv = 2;
-
-  // prev_kv holds the key-value pair before the event happens.
-  KeyValue prev_kv = 3;
-}
diff --git a/mvcc/revision.go b/mvcc/revision.go
deleted file mode 100644
index 5fa35a1..0000000
--- a/mvcc/revision.go
+++ /dev/null
@@ -1,67 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import "encoding/binary"
-
-// revBytesLen is the byte length of a normal revision.
-// First 8 bytes is the revision.main in big-endian format. The 9th byte
-// is a '_'. The last 8 bytes is the revision.sub in big-endian format.
-const revBytesLen = 8 + 1 + 8
-
-// A revision indicates modification of the key-value space.
-// The set of changes that share same main revision changes the key-value space atomically.
-type revision struct {
-	// main is the main revision of a set of changes that happen atomically.
-	main int64
-
-	// sub is the the sub revision of a change in a set of changes that happen
-	// atomically. Each change has different increasing sub revision in that
-	// set.
-	sub int64
-}
-
-func (a revision) GreaterThan(b revision) bool {
-	if a.main > b.main {
-		return true
-	}
-	if a.main < b.main {
-		return false
-	}
-	return a.sub > b.sub
-}
-
-func newRevBytes() []byte {
-	return make([]byte, revBytesLen, markedRevBytesLen)
-}
-
-func revToBytes(rev revision, bytes []byte) {
-	binary.BigEndian.PutUint64(bytes, uint64(rev.main))
-	bytes[8] = '_'
-	binary.BigEndian.PutUint64(bytes[9:], uint64(rev.sub))
-}
-
-func bytesToRev(bytes []byte) revision {
-	return revision{
-		main: int64(binary.BigEndian.Uint64(bytes[0:8])),
-		sub:  int64(binary.BigEndian.Uint64(bytes[9:])),
-	}
-}
-
-type revisions []revision
-
-func (a revisions) Len() int           { return len(a) }
-func (a revisions) Less(i, j int) bool { return a[j].GreaterThan(a[i]) }
-func (a revisions) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }
diff --git a/mvcc/revision_test.go b/mvcc/revision_test.go
deleted file mode 100644
index 46fcb48..0000000
--- a/mvcc/revision_test.go
+++ /dev/null
@@ -1,53 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"bytes"
-	"math"
-	"reflect"
-	"testing"
-)
-
-// TestRevision tests that revision could be encoded to and decoded from
-// bytes slice. Moreover, the lexicographical order of its byte slice representation
-// follows the order of (main, sub).
-func TestRevision(t *testing.T) {
-	tests := []revision{
-		// order in (main, sub)
-		{},
-		{main: 1, sub: 0},
-		{main: 1, sub: 1},
-		{main: 2, sub: 0},
-		{main: math.MaxInt64, sub: math.MaxInt64},
-	}
-
-	bs := make([][]byte, len(tests))
-	for i, tt := range tests {
-		b := newRevBytes()
-		revToBytes(tt, b)
-		bs[i] = b
-
-		if grev := bytesToRev(b); !reflect.DeepEqual(grev, tt) {
-			t.Errorf("#%d: revision = %+v, want %+v", i, grev, tt)
-		}
-	}
-
-	for i := 0; i < len(tests)-1; i++ {
-		if bytes.Compare(bs[i], bs[i+1]) >= 0 {
-			t.Errorf("#%d: %v (%+v) should be smaller than %v (%+v)", i, bs[i], tests[i], bs[i+1], tests[i+1])
-		}
-	}
-}
diff --git a/mvcc/util.go b/mvcc/util.go
deleted file mode 100644
index 8a0df0b..0000000
--- a/mvcc/util.go
+++ /dev/null
@@ -1,56 +0,0 @@
-// Copyright 2016 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"encoding/binary"
-
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
-)
-
-func UpdateConsistentIndex(be backend.Backend, index uint64) {
-	tx := be.BatchTx()
-	tx.Lock()
-	defer tx.Unlock()
-
-	var oldi uint64
-	_, vs := tx.UnsafeRange(metaBucketName, consistentIndexKeyName, nil, 0)
-	if len(vs) != 0 {
-		oldi = binary.BigEndian.Uint64(vs[0])
-	}
-
-	if index <= oldi {
-		return
-	}
-
-	bs := make([]byte, 8)
-	binary.BigEndian.PutUint64(bs, index)
-	tx.UnsafePut(metaBucketName, consistentIndexKeyName, bs)
-}
-
-func WriteKV(be backend.Backend, kv mvccpb.KeyValue) {
-	ibytes := newRevBytes()
-	revToBytes(revision{main: kv.ModRevision}, ibytes)
-
-	d, err := kv.Marshal()
-	if err != nil {
-		plog.Fatalf("cannot marshal event: %v", err)
-	}
-
-	be.BatchTx().Lock()
-	be.BatchTx().UnsafePut(keyBucketName, ibytes, d)
-	be.BatchTx().Unlock()
-}
diff --git a/mvcc/watchable_store.go b/mvcc/watchable_store.go
deleted file mode 100644
index ee0d867..0000000
--- a/mvcc/watchable_store.go
+++ /dev/null
@@ -1,525 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"sync"
-	"time"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
-)
-
-// non-const so modifiable by tests
-var (
-	// chanBufLen is the length of the buffered chan
-	// for sending out watched events.
-	// TODO: find a good buf value. 1024 is just a random one that
-	// seems to be reasonable.
-	chanBufLen = 1024
-
-	// maxWatchersPerSync is the number of watchers to sync in a single batch
-	maxWatchersPerSync = 512
-)
-
-type watchable interface {
-	watch(key, end []byte, startRev int64, id WatchID, ch chan<- WatchResponse, fcs ...FilterFunc) (*watcher, cancelFunc)
-	progress(w *watcher)
-	rev() int64
-}
-
-type watchableStore struct {
-	*store
-
-	// mu protects watcher groups and batches. It should never be locked
-	// before locking store.mu to avoid deadlock.
-	mu sync.RWMutex
-
-	// victims are watcher batches that were blocked on the watch channel
-	victims []watcherBatch
-	victimc chan struct{}
-
-	// contains all unsynced watchers that needs to sync with events that have happened
-	unsynced watcherGroup
-
-	// contains all synced watchers that are in sync with the progress of the store.
-	// The key of the map is the key that the watcher watches on.
-	synced watcherGroup
-
-	stopc chan struct{}
-	wg    sync.WaitGroup
-}
-
-// cancelFunc updates unsynced and synced maps when running
-// cancel operations.
-type cancelFunc func()
-
-func New(b backend.Backend, le lease.Lessor, ig ConsistentIndexGetter) ConsistentWatchableKV {
-	return newWatchableStore(b, le, ig)
-}
-
-func newWatchableStore(b backend.Backend, le lease.Lessor, ig ConsistentIndexGetter) *watchableStore {
-	s := &watchableStore{
-		store:    NewStore(b, le, ig),
-		victimc:  make(chan struct{}, 1),
-		unsynced: newWatcherGroup(),
-		synced:   newWatcherGroup(),
-		stopc:    make(chan struct{}),
-	}
-	s.store.ReadView = &readView{s}
-	s.store.WriteView = &writeView{s}
-	if s.le != nil {
-		// use this store as the deleter so revokes trigger watch events
-		s.le.SetRangeDeleter(func() lease.TxnDelete { return s.Write() })
-	}
-	s.wg.Add(2)
-	go s.syncWatchersLoop()
-	go s.syncVictimsLoop()
-	return s
-}
-
-func (s *watchableStore) Close() error {
-	close(s.stopc)
-	s.wg.Wait()
-	return s.store.Close()
-}
-
-func (s *watchableStore) NewWatchStream() WatchStream {
-	watchStreamGauge.Inc()
-	return &watchStream{
-		watchable: s,
-		ch:        make(chan WatchResponse, chanBufLen),
-		cancels:   make(map[WatchID]cancelFunc),
-		watchers:  make(map[WatchID]*watcher),
-	}
-}
-
-func (s *watchableStore) watch(key, end []byte, startRev int64, id WatchID, ch chan<- WatchResponse, fcs ...FilterFunc) (*watcher, cancelFunc) {
-	wa := &watcher{
-		key:    key,
-		end:    end,
-		minRev: startRev,
-		id:     id,
-		ch:     ch,
-		fcs:    fcs,
-	}
-
-	s.mu.Lock()
-	s.revMu.RLock()
-	synced := startRev > s.store.currentRev || startRev == 0
-	if synced {
-		wa.minRev = s.store.currentRev + 1
-		if startRev > wa.minRev {
-			wa.minRev = startRev
-		}
-	}
-	if synced {
-		s.synced.add(wa)
-	} else {
-		slowWatcherGauge.Inc()
-		s.unsynced.add(wa)
-	}
-	s.revMu.RUnlock()
-	s.mu.Unlock()
-
-	watcherGauge.Inc()
-
-	return wa, func() { s.cancelWatcher(wa) }
-}
-
-// cancelWatcher removes references of the watcher from the watchableStore
-func (s *watchableStore) cancelWatcher(wa *watcher) {
-	for {
-		s.mu.Lock()
-		if s.unsynced.delete(wa) {
-			slowWatcherGauge.Dec()
-			break
-		} else if s.synced.delete(wa) {
-			break
-		} else if wa.compacted {
-			break
-		} else if wa.ch == nil {
-			// already canceled (e.g., cancel/close race)
-			break
-		}
-
-		if !wa.victim {
-			panic("watcher not victim but not in watch groups")
-		}
-
-		var victimBatch watcherBatch
-		for _, wb := range s.victims {
-			if wb[wa] != nil {
-				victimBatch = wb
-				break
-			}
-		}
-		if victimBatch != nil {
-			slowWatcherGauge.Dec()
-			delete(victimBatch, wa)
-			break
-		}
-
-		// victim being processed so not accessible; retry
-		s.mu.Unlock()
-		time.Sleep(time.Millisecond)
-	}
-
-	watcherGauge.Dec()
-	wa.ch = nil
-	s.mu.Unlock()
-}
-
-func (s *watchableStore) Restore(b backend.Backend) error {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	err := s.store.Restore(b)
-	if err != nil {
-		return err
-	}
-
-	for wa := range s.synced.watchers {
-		s.unsynced.watchers.add(wa)
-	}
-	s.synced = newWatcherGroup()
-	return nil
-}
-
-// syncWatchersLoop syncs the watcher in the unsynced map every 100ms.
-func (s *watchableStore) syncWatchersLoop() {
-	defer s.wg.Done()
-
-	for {
-		s.mu.RLock()
-		st := time.Now()
-		lastUnsyncedWatchers := s.unsynced.size()
-		s.mu.RUnlock()
-
-		unsyncedWatchers := 0
-		if lastUnsyncedWatchers > 0 {
-			unsyncedWatchers = s.syncWatchers()
-		}
-		syncDuration := time.Since(st)
-
-		waitDuration := 100 * time.Millisecond
-		// more work pending?
-		if unsyncedWatchers != 0 && lastUnsyncedWatchers > unsyncedWatchers {
-			// be fair to other store operations by yielding time taken
-			waitDuration = syncDuration
-		}
-
-		select {
-		case <-time.After(waitDuration):
-		case <-s.stopc:
-			return
-		}
-	}
-}
-
-// syncVictimsLoop tries to write precomputed watcher responses to
-// watchers that had a blocked watcher channel
-func (s *watchableStore) syncVictimsLoop() {
-	defer s.wg.Done()
-
-	for {
-		for s.moveVictims() != 0 {
-			// try to update all victim watchers
-		}
-		s.mu.RLock()
-		isEmpty := len(s.victims) == 0
-		s.mu.RUnlock()
-
-		var tickc <-chan time.Time
-		if !isEmpty {
-			tickc = time.After(10 * time.Millisecond)
-		}
-
-		select {
-		case <-tickc:
-		case <-s.victimc:
-		case <-s.stopc:
-			return
-		}
-	}
-}
-
-// moveVictims tries to update watches with already pending event data
-func (s *watchableStore) moveVictims() (moved int) {
-	s.mu.Lock()
-	victims := s.victims
-	s.victims = nil
-	s.mu.Unlock()
-
-	var newVictim watcherBatch
-	for _, wb := range victims {
-		// try to send responses again
-		for w, eb := range wb {
-			// watcher has observed the store up to, but not including, w.minRev
-			rev := w.minRev - 1
-			if w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: rev}) {
-				pendingEventsGauge.Add(float64(len(eb.evs)))
-			} else {
-				if newVictim == nil {
-					newVictim = make(watcherBatch)
-				}
-				newVictim[w] = eb
-				continue
-			}
-			moved++
-		}
-
-		// assign completed victim watchers to unsync/sync
-		s.mu.Lock()
-		s.store.revMu.RLock()
-		curRev := s.store.currentRev
-		for w, eb := range wb {
-			if newVictim != nil && newVictim[w] != nil {
-				// couldn't send watch response; stays victim
-				continue
-			}
-			w.victim = false
-			if eb.moreRev != 0 {
-				w.minRev = eb.moreRev
-			}
-			if w.minRev <= curRev {
-				s.unsynced.add(w)
-			} else {
-				slowWatcherGauge.Dec()
-				s.synced.add(w)
-			}
-		}
-		s.store.revMu.RUnlock()
-		s.mu.Unlock()
-	}
-
-	if len(newVictim) > 0 {
-		s.mu.Lock()
-		s.victims = append(s.victims, newVictim)
-		s.mu.Unlock()
-	}
-
-	return moved
-}
-
-// syncWatchers syncs unsynced watchers by:
-//	1. choose a set of watchers from the unsynced watcher group
-//	2. iterate over the set to get the minimum revision and remove compacted watchers
-//	3. use minimum revision to get all key-value pairs and send those events to watchers
-//	4. remove synced watchers in set from unsynced group and move to synced group
-func (s *watchableStore) syncWatchers() int {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	if s.unsynced.size() == 0 {
-		return 0
-	}
-
-	s.store.revMu.RLock()
-	defer s.store.revMu.RUnlock()
-
-	// in order to find key-value pairs from unsynced watchers, we need to
-	// find min revision index, and these revisions can be used to
-	// query the backend store of key-value pairs
-	curRev := s.store.currentRev
-	compactionRev := s.store.compactMainRev
-
-	wg, minRev := s.unsynced.choose(maxWatchersPerSync, curRev, compactionRev)
-	minBytes, maxBytes := newRevBytes(), newRevBytes()
-	revToBytes(revision{main: minRev}, minBytes)
-	revToBytes(revision{main: curRev + 1}, maxBytes)
-
-	// UnsafeRange returns keys and values. And in boltdb, keys are revisions.
-	// values are actual key-value pairs in backend.
-	tx := s.store.b.ReadTx()
-	tx.Lock()
-	revs, vs := tx.UnsafeRange(keyBucketName, minBytes, maxBytes, 0)
-	evs := kvsToEvents(wg, revs, vs)
-	tx.Unlock()
-
-	var victims watcherBatch
-	wb := newWatcherBatch(wg, evs)
-	for w := range wg.watchers {
-		w.minRev = curRev + 1
-
-		eb, ok := wb[w]
-		if !ok {
-			// bring un-notified watcher to synced
-			s.synced.add(w)
-			s.unsynced.delete(w)
-			continue
-		}
-
-		if eb.moreRev != 0 {
-			w.minRev = eb.moreRev
-		}
-
-		if w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: curRev}) {
-			pendingEventsGauge.Add(float64(len(eb.evs)))
-		} else {
-			if victims == nil {
-				victims = make(watcherBatch)
-			}
-			w.victim = true
-		}
-
-		if w.victim {
-			victims[w] = eb
-		} else {
-			if eb.moreRev != 0 {
-				// stay unsynced; more to read
-				continue
-			}
-			s.synced.add(w)
-		}
-		s.unsynced.delete(w)
-	}
-	s.addVictim(victims)
-
-	vsz := 0
-	for _, v := range s.victims {
-		vsz += len(v)
-	}
-	slowWatcherGauge.Set(float64(s.unsynced.size() + vsz))
-
-	return s.unsynced.size()
-}
-
-// kvsToEvents gets all events for the watchers from all key-value pairs
-func kvsToEvents(wg *watcherGroup, revs, vals [][]byte) (evs []mvccpb.Event) {
-	for i, v := range vals {
-		var kv mvccpb.KeyValue
-		if err := kv.Unmarshal(v); err != nil {
-			plog.Panicf("cannot unmarshal event: %v", err)
-		}
-
-		if !wg.contains(string(kv.Key)) {
-			continue
-		}
-
-		ty := mvccpb.PUT
-		if isTombstone(revs[i]) {
-			ty = mvccpb.DELETE
-			// patch in mod revision so watchers won't skip
-			kv.ModRevision = bytesToRev(revs[i]).main
-		}
-		evs = append(evs, mvccpb.Event{Kv: &kv, Type: ty})
-	}
-	return evs
-}
-
-// notify notifies the fact that given event at the given rev just happened to
-// watchers that watch on the key of the event.
-func (s *watchableStore) notify(rev int64, evs []mvccpb.Event) {
-	var victim watcherBatch
-	for w, eb := range newWatcherBatch(&s.synced, evs) {
-		if eb.revs != 1 {
-			plog.Panicf("unexpected multiple revisions in notification")
-		}
-		if w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: rev}) {
-			pendingEventsGauge.Add(float64(len(eb.evs)))
-		} else {
-			// move slow watcher to victims
-			w.minRev = rev + 1
-			if victim == nil {
-				victim = make(watcherBatch)
-			}
-			w.victim = true
-			victim[w] = eb
-			s.synced.delete(w)
-			slowWatcherGauge.Inc()
-		}
-	}
-	s.addVictim(victim)
-}
-
-func (s *watchableStore) addVictim(victim watcherBatch) {
-	if victim == nil {
-		return
-	}
-	s.victims = append(s.victims, victim)
-	select {
-	case s.victimc <- struct{}{}:
-	default:
-	}
-}
-
-func (s *watchableStore) rev() int64 { return s.store.Rev() }
-
-func (s *watchableStore) progress(w *watcher) {
-	s.mu.RLock()
-	defer s.mu.RUnlock()
-
-	if _, ok := s.synced.watchers[w]; ok {
-		w.send(WatchResponse{WatchID: w.id, Revision: s.rev()})
-		// If the ch is full, this watcher is receiving events.
-		// We do not need to send progress at all.
-	}
-}
-
-type watcher struct {
-	// the watcher key
-	key []byte
-	// end indicates the end of the range to watch.
-	// If end is set, the watcher is on a range.
-	end []byte
-
-	// victim is set when ch is blocked and undergoing victim processing
-	victim bool
-
-	// compacted is set when the watcher is removed because of compaction
-	compacted bool
-
-	// minRev is the minimum revision update the watcher will accept
-	minRev int64
-	id     WatchID
-
-	fcs []FilterFunc
-	// a chan to send out the watch response.
-	// The chan might be shared with other watchers.
-	ch chan<- WatchResponse
-}
-
-func (w *watcher) send(wr WatchResponse) bool {
-	progressEvent := len(wr.Events) == 0
-
-	if len(w.fcs) != 0 {
-		ne := make([]mvccpb.Event, 0, len(wr.Events))
-		for i := range wr.Events {
-			filtered := false
-			for _, filter := range w.fcs {
-				if filter(wr.Events[i]) {
-					filtered = true
-					break
-				}
-			}
-			if !filtered {
-				ne = append(ne, wr.Events[i])
-			}
-		}
-		wr.Events = ne
-	}
-
-	// if all events are filtered out, we should send nothing.
-	if !progressEvent && len(wr.Events) == 0 {
-		return true
-	}
-	select {
-	case w.ch <- wr:
-		return true
-	default:
-		return false
-	}
-}
diff --git a/mvcc/watchable_store_bench_test.go b/mvcc/watchable_store_bench_test.go
deleted file mode 100644
index bda6e8c..0000000
--- a/mvcc/watchable_store_bench_test.go
+++ /dev/null
@@ -1,200 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"math/rand"
-	"os"
-	"testing"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-)
-
-func BenchmarkWatchableStorePut(b *testing.B) {
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := New(be, &lease.FakeLessor{}, nil)
-	defer cleanup(s, be, tmpPath)
-
-	// arbitrary number of bytes
-	bytesN := 64
-	keys := createBytesSlice(bytesN, b.N)
-	vals := createBytesSlice(bytesN, b.N)
-
-	b.ResetTimer()
-	b.ReportAllocs()
-	for i := 0; i < b.N; i++ {
-		s.Put(keys[i], vals[i], lease.NoLease)
-	}
-}
-
-// BenchmarkWatchableStoreTxnPut benchmarks the Put operation
-// with transaction begin and end, where transaction involves
-// some synchronization operations, such as mutex locking.
-func BenchmarkWatchableStoreTxnPut(b *testing.B) {
-	var i fakeConsistentIndex
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := New(be, &lease.FakeLessor{}, &i)
-	defer cleanup(s, be, tmpPath)
-
-	// arbitrary number of bytes
-	bytesN := 64
-	keys := createBytesSlice(bytesN, b.N)
-	vals := createBytesSlice(bytesN, b.N)
-
-	b.ResetTimer()
-	b.ReportAllocs()
-	for i := 0; i < b.N; i++ {
-		txn := s.Write()
-		txn.Put(keys[i], vals[i], lease.NoLease)
-		txn.End()
-	}
-}
-
-// BenchmarkWatchableStoreWatchSyncPut benchmarks the case of
-// many synced watchers receiving a Put notification.
-func BenchmarkWatchableStoreWatchSyncPut(b *testing.B) {
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(be, &lease.FakeLessor{}, nil)
-	defer cleanup(s, be, tmpPath)
-
-	k := []byte("testkey")
-	v := []byte("testval")
-
-	w := s.NewWatchStream()
-	defer w.Close()
-	watchIDs := make([]WatchID, b.N)
-	for i := range watchIDs {
-		// non-0 value to keep watchers in unsynced
-		watchIDs[i], _ = w.Watch(0, k, nil, 1)
-	}
-
-	b.ResetTimer()
-	b.ReportAllocs()
-
-	// trigger watchers
-	s.Put(k, v, lease.NoLease)
-	for range watchIDs {
-		<-w.Chan()
-	}
-	select {
-	case wc := <-w.Chan():
-		b.Fatalf("unexpected data %v", wc)
-	default:
-	}
-}
-
-// Benchmarks on cancel function performance for unsynced watchers
-// in a WatchableStore. It creates k*N watchers to populate unsynced
-// with a reasonably large number of watchers. And measures the time it
-// takes to cancel N watchers out of k*N watchers. The performance is
-// expected to differ depending on the unsynced member implementation.
-// TODO: k is an arbitrary constant. We need to figure out what factor
-// we should put to simulate the real-world use cases.
-func BenchmarkWatchableStoreUnsyncedCancel(b *testing.B) {
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := NewStore(be, &lease.FakeLessor{}, nil)
-
-	// manually create watchableStore instead of newWatchableStore
-	// because newWatchableStore periodically calls syncWatchersLoop
-	// method to sync watchers in unsynced map. We want to keep watchers
-	// in unsynced for this benchmark.
-	ws := &watchableStore{
-		store:    s,
-		unsynced: newWatcherGroup(),
-
-		// to make the test not crash from assigning to nil map.
-		// 'synced' doesn't get populated in this test.
-		synced: newWatcherGroup(),
-	}
-
-	defer func() {
-		ws.store.Close()
-		os.Remove(tmpPath)
-	}()
-
-	// Put a key so that we can spawn watchers on that key
-	// (testKey in this test). This increases the rev to 1,
-	// and later we can we set the watcher's startRev to 1,
-	// and force watchers to be in unsynced.
-	testKey := []byte("foo")
-	testValue := []byte("bar")
-	s.Put(testKey, testValue, lease.NoLease)
-
-	w := ws.NewWatchStream()
-
-	const k int = 2
-	benchSampleN := b.N
-	watcherN := k * benchSampleN
-
-	watchIDs := make([]WatchID, watcherN)
-	for i := 0; i < watcherN; i++ {
-		// non-0 value to keep watchers in unsynced
-		watchIDs[i], _ = w.Watch(0, testKey, nil, 1)
-	}
-
-	// random-cancel N watchers to make it not biased towards
-	// data structures with an order, such as slice.
-	ix := rand.Perm(watcherN)
-
-	b.ResetTimer()
-	b.ReportAllocs()
-
-	// cancel N watchers
-	for _, idx := range ix[:benchSampleN] {
-		if err := w.Cancel(watchIDs[idx]); err != nil {
-			b.Error(err)
-		}
-	}
-}
-
-func BenchmarkWatchableStoreSyncedCancel(b *testing.B) {
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(be, &lease.FakeLessor{}, nil)
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-
-	// Put a key so that we can spawn watchers on that key
-	testKey := []byte("foo")
-	testValue := []byte("bar")
-	s.Put(testKey, testValue, lease.NoLease)
-
-	w := s.NewWatchStream()
-
-	// put 1 million watchers on the same key
-	const watcherN = 1000000
-
-	watchIDs := make([]WatchID, watcherN)
-	for i := 0; i < watcherN; i++ {
-		// 0 for startRev to keep watchers in synced
-		watchIDs[i], _ = w.Watch(0, testKey, nil, 0)
-	}
-
-	// randomly cancel watchers to make it not biased towards
-	// data structures with an order, such as slice.
-	ix := rand.Perm(watcherN)
-
-	b.ResetTimer()
-	b.ReportAllocs()
-
-	for _, idx := range ix {
-		if err := w.Cancel(watchIDs[idx]); err != nil {
-			b.Error(err)
-		}
-	}
-}
diff --git a/mvcc/watchable_store_test.go b/mvcc/watchable_store_test.go
deleted file mode 100644
index 16bbffc..0000000
--- a/mvcc/watchable_store_test.go
+++ /dev/null
@@ -1,587 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"bytes"
-	"fmt"
-	"os"
-	"reflect"
-	"sync"
-	"testing"
-	"time"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
-)
-
-func TestWatch(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-
-	testKey := []byte("foo")
-	testValue := []byte("bar")
-	s.Put(testKey, testValue, lease.NoLease)
-
-	w := s.NewWatchStream()
-	w.Watch(0, testKey, nil, 0)
-
-	if !s.synced.contains(string(testKey)) {
-		// the key must have had an entry in synced
-		t.Errorf("existence = false, want true")
-	}
-}
-
-func TestNewWatcherCancel(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-	testKey := []byte("foo")
-	testValue := []byte("bar")
-	s.Put(testKey, testValue, lease.NoLease)
-
-	w := s.NewWatchStream()
-	wt, _ := w.Watch(0, testKey, nil, 0)
-
-	if err := w.Cancel(wt); err != nil {
-		t.Error(err)
-	}
-
-	if s.synced.contains(string(testKey)) {
-		// the key shoud have been deleted
-		t.Errorf("existence = true, want false")
-	}
-}
-
-// TestCancelUnsynced tests if running CancelFunc removes watchers from unsynced.
-func TestCancelUnsynced(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-
-	// manually create watchableStore instead of newWatchableStore
-	// because newWatchableStore automatically calls syncWatchers
-	// method to sync watchers in unsynced map. We want to keep watchers
-	// in unsynced to test if syncWatchers works as expected.
-	s := &watchableStore{
-		store:    NewStore(b, &lease.FakeLessor{}, nil),
-		unsynced: newWatcherGroup(),
-
-		// to make the test not crash from assigning to nil map.
-		// 'synced' doesn't get populated in this test.
-		synced: newWatcherGroup(),
-	}
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-
-	// Put a key so that we can spawn watchers on that key.
-	// (testKey in this test). This increases the rev to 1,
-	// and later we can we set the watcher's startRev to 1,
-	// and force watchers to be in unsynced.
-	testKey := []byte("foo")
-	testValue := []byte("bar")
-	s.Put(testKey, testValue, lease.NoLease)
-
-	w := s.NewWatchStream()
-
-	// arbitrary number for watchers
-	watcherN := 100
-
-	// create watcherN of watch ids to cancel
-	watchIDs := make([]WatchID, watcherN)
-	for i := 0; i < watcherN; i++ {
-		// use 1 to keep watchers in unsynced
-		watchIDs[i], _ = w.Watch(0, testKey, nil, 1)
-	}
-
-	for _, idx := range watchIDs {
-		if err := w.Cancel(idx); err != nil {
-			t.Error(err)
-		}
-	}
-
-	// After running CancelFunc
-	//
-	// unsynced should be empty
-	// because cancel removes watcher from unsynced
-	if size := s.unsynced.size(); size != 0 {
-		t.Errorf("unsynced size = %d, want 0", size)
-	}
-}
-
-// TestSyncWatchers populates unsynced watcher map and tests syncWatchers
-// method to see if it correctly sends events to channel of unsynced watchers
-// and moves these watchers to synced.
-func TestSyncWatchers(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-
-	s := &watchableStore{
-		store:    NewStore(b, &lease.FakeLessor{}, nil),
-		unsynced: newWatcherGroup(),
-		synced:   newWatcherGroup(),
-	}
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-
-	testKey := []byte("foo")
-	testValue := []byte("bar")
-	s.Put(testKey, testValue, lease.NoLease)
-
-	w := s.NewWatchStream()
-
-	// arbitrary number for watchers
-	watcherN := 100
-
-	for i := 0; i < watcherN; i++ {
-		// specify rev as 1 to keep watchers in unsynced
-		w.Watch(0, testKey, nil, 1)
-	}
-
-	// Before running s.syncWatchers() synced should be empty because we manually
-	// populate unsynced only
-	sws := s.synced.watcherSetByKey(string(testKey))
-	uws := s.unsynced.watcherSetByKey(string(testKey))
-
-	if len(sws) != 0 {
-		t.Fatalf("synced[string(testKey)] size = %d, want 0", len(sws))
-	}
-	// unsynced should not be empty because we manually populated unsynced only
-	if len(uws) != watcherN {
-		t.Errorf("unsynced size = %d, want %d", len(uws), watcherN)
-	}
-
-	// this should move all unsynced watchers to synced ones
-	s.syncWatchers()
-
-	sws = s.synced.watcherSetByKey(string(testKey))
-	uws = s.unsynced.watcherSetByKey(string(testKey))
-
-	// After running s.syncWatchers(), synced should not be empty because syncwatchers
-	// populates synced in this test case
-	if len(sws) != watcherN {
-		t.Errorf("synced[string(testKey)] size = %d, want %d", len(sws), watcherN)
-	}
-
-	// unsynced should be empty because syncwatchers is expected to move all watchers
-	// from unsynced to synced in this test case
-	if len(uws) != 0 {
-		t.Errorf("unsynced size = %d, want 0", len(uws))
-	}
-
-	for w := range sws {
-		if w.minRev != s.Rev()+1 {
-			t.Errorf("w.minRev = %d, want %d", w.minRev, s.Rev()+1)
-		}
-	}
-
-	if len(w.(*watchStream).ch) != watcherN {
-		t.Errorf("watched event size = %d, want %d", len(w.(*watchStream).ch), watcherN)
-	}
-
-	evs := (<-w.(*watchStream).ch).Events
-	if len(evs) != 1 {
-		t.Errorf("len(evs) got = %d, want = 1", len(evs))
-	}
-	if evs[0].Type != mvccpb.PUT {
-		t.Errorf("got = %v, want = %v", evs[0].Type, mvccpb.PUT)
-	}
-	if !bytes.Equal(evs[0].Kv.Key, testKey) {
-		t.Errorf("got = %s, want = %s", evs[0].Kv.Key, testKey)
-	}
-	if !bytes.Equal(evs[0].Kv.Value, testValue) {
-		t.Errorf("got = %s, want = %s", evs[0].Kv.Value, testValue)
-	}
-}
-
-// TestWatchCompacted tests a watcher that watches on a compacted revision.
-func TestWatchCompacted(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-	testKey := []byte("foo")
-	testValue := []byte("bar")
-
-	maxRev := 10
-	compactRev := int64(5)
-	for i := 0; i < maxRev; i++ {
-		s.Put(testKey, testValue, lease.NoLease)
-	}
-	_, err := s.Compact(compactRev)
-	if err != nil {
-		t.Fatalf("failed to compact kv (%v)", err)
-	}
-
-	w := s.NewWatchStream()
-	wt, _ := w.Watch(0, testKey, nil, compactRev-1)
-
-	select {
-	case resp := <-w.Chan():
-		if resp.WatchID != wt {
-			t.Errorf("resp.WatchID = %x, want %x", resp.WatchID, wt)
-		}
-		if resp.CompactRevision == 0 {
-			t.Errorf("resp.Compacted = %v, want %v", resp.CompactRevision, compactRev)
-		}
-	case <-time.After(1 * time.Second):
-		t.Fatalf("failed to receive response (timeout)")
-	}
-}
-
-func TestWatchFutureRev(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-
-	testKey := []byte("foo")
-	testValue := []byte("bar")
-
-	w := s.NewWatchStream()
-	wrev := int64(10)
-	w.Watch(0, testKey, nil, wrev)
-
-	for i := 0; i < 10; i++ {
-		rev := s.Put(testKey, testValue, lease.NoLease)
-		if rev >= wrev {
-			break
-		}
-	}
-
-	select {
-	case resp := <-w.Chan():
-		if resp.Revision != wrev {
-			t.Fatalf("rev = %d, want %d", resp.Revision, wrev)
-		}
-		if len(resp.Events) != 1 {
-			t.Fatalf("failed to get events from the response")
-		}
-		if resp.Events[0].Kv.ModRevision != wrev {
-			t.Fatalf("kv.rev = %d, want %d", resp.Events[0].Kv.ModRevision, wrev)
-		}
-	case <-time.After(time.Second):
-		t.Fatal("failed to receive event in 1 second.")
-	}
-}
-
-func TestWatchRestore(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
-	defer cleanup(s, b, tmpPath)
-
-	testKey := []byte("foo")
-	testValue := []byte("bar")
-	rev := s.Put(testKey, testValue, lease.NoLease)
-
-	newBackend, newPath := backend.NewDefaultTmpBackend()
-	newStore := newWatchableStore(newBackend, &lease.FakeLessor{}, nil)
-	defer cleanup(newStore, newBackend, newPath)
-
-	w := newStore.NewWatchStream()
-	w.Watch(0, testKey, nil, rev-1)
-
-	newStore.Restore(b)
-	select {
-	case resp := <-w.Chan():
-		if resp.Revision != rev {
-			t.Fatalf("rev = %d, want %d", resp.Revision, rev)
-		}
-		if len(resp.Events) != 1 {
-			t.Fatalf("failed to get events from the response")
-		}
-		if resp.Events[0].Kv.ModRevision != rev {
-			t.Fatalf("kv.rev = %d, want %d", resp.Events[0].Kv.ModRevision, rev)
-		}
-	case <-time.After(time.Second):
-		t.Fatal("failed to receive event in 1 second.")
-	}
-}
-
-// TestWatchBatchUnsynced tests batching on unsynced watchers
-func TestWatchBatchUnsynced(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
-
-	oldMaxRevs := watchBatchMaxRevs
-	defer func() {
-		watchBatchMaxRevs = oldMaxRevs
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-	batches := 3
-	watchBatchMaxRevs = 4
-
-	v := []byte("foo")
-	for i := 0; i < watchBatchMaxRevs*batches; i++ {
-		s.Put(v, v, lease.NoLease)
-	}
-
-	w := s.NewWatchStream()
-	w.Watch(0, v, nil, 1)
-	for i := 0; i < batches; i++ {
-		if resp := <-w.Chan(); len(resp.Events) != watchBatchMaxRevs {
-			t.Fatalf("len(events) = %d, want %d", len(resp.Events), watchBatchMaxRevs)
-		}
-	}
-
-	s.store.revMu.Lock()
-	defer s.store.revMu.Unlock()
-	if size := s.synced.size(); size != 1 {
-		t.Errorf("synced size = %d, want 1", size)
-	}
-}
-
-func TestNewMapwatcherToEventMap(t *testing.T) {
-	k0, k1, k2 := []byte("foo0"), []byte("foo1"), []byte("foo2")
-	v0, v1, v2 := []byte("bar0"), []byte("bar1"), []byte("bar2")
-
-	ws := []*watcher{{key: k0}, {key: k1}, {key: k2}}
-
-	evs := []mvccpb.Event{
-		{
-			Type: mvccpb.PUT,
-			Kv:   &mvccpb.KeyValue{Key: k0, Value: v0},
-		},
-		{
-			Type: mvccpb.PUT,
-			Kv:   &mvccpb.KeyValue{Key: k1, Value: v1},
-		},
-		{
-			Type: mvccpb.PUT,
-			Kv:   &mvccpb.KeyValue{Key: k2, Value: v2},
-		},
-	}
-
-	tests := []struct {
-		sync []*watcher
-		evs  []mvccpb.Event
-
-		wwe map[*watcher][]mvccpb.Event
-	}{
-		// no watcher in sync, some events should return empty wwe
-		{
-			nil,
-			evs,
-			map[*watcher][]mvccpb.Event{},
-		},
-
-		// one watcher in sync, one event that does not match the key of that
-		// watcher should return empty wwe
-		{
-			[]*watcher{ws[2]},
-			evs[:1],
-			map[*watcher][]mvccpb.Event{},
-		},
-
-		// one watcher in sync, one event that matches the key of that
-		// watcher should return wwe with that matching watcher
-		{
-			[]*watcher{ws[1]},
-			evs[1:2],
-			map[*watcher][]mvccpb.Event{
-				ws[1]: evs[1:2],
-			},
-		},
-
-		// two watchers in sync that watches two different keys, one event
-		// that matches the key of only one of the watcher should return wwe
-		// with the matching watcher
-		{
-			[]*watcher{ws[0], ws[2]},
-			evs[2:],
-			map[*watcher][]mvccpb.Event{
-				ws[2]: evs[2:],
-			},
-		},
-
-		// two watchers in sync that watches the same key, two events that
-		// match the keys should return wwe with those two watchers
-		{
-			[]*watcher{ws[0], ws[1]},
-			evs[:2],
-			map[*watcher][]mvccpb.Event{
-				ws[0]: evs[:1],
-				ws[1]: evs[1:2],
-			},
-		},
-	}
-
-	for i, tt := range tests {
-		wg := newWatcherGroup()
-		for _, w := range tt.sync {
-			wg.add(w)
-		}
-
-		gwe := newWatcherBatch(&wg, tt.evs)
-		if len(gwe) != len(tt.wwe) {
-			t.Errorf("#%d: len(gwe) got = %d, want = %d", i, len(gwe), len(tt.wwe))
-		}
-		// compare gwe and tt.wwe
-		for w, eb := range gwe {
-			if len(eb.evs) != len(tt.wwe[w]) {
-				t.Errorf("#%d: len(eb.evs) got = %d, want = %d", i, len(eb.evs), len(tt.wwe[w]))
-			}
-			if !reflect.DeepEqual(eb.evs, tt.wwe[w]) {
-				t.Errorf("#%d: reflect.DeepEqual events got = %v, want = true", i, false)
-			}
-		}
-	}
-}
-
-// TestWatchVictims tests that watchable store delivers watch events
-// when the watch channel is temporarily clogged with too many events.
-func TestWatchVictims(t *testing.T) {
-	oldChanBufLen, oldMaxWatchersPerSync := chanBufLen, maxWatchersPerSync
-
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-		chanBufLen, maxWatchersPerSync = oldChanBufLen, oldMaxWatchersPerSync
-	}()
-
-	chanBufLen, maxWatchersPerSync = 1, 2
-	numPuts := chanBufLen * 64
-	testKey, testValue := []byte("foo"), []byte("bar")
-
-	var wg sync.WaitGroup
-	numWatches := maxWatchersPerSync * 128
-	errc := make(chan error, numWatches)
-	wg.Add(numWatches)
-	for i := 0; i < numWatches; i++ {
-		go func() {
-			w := s.NewWatchStream()
-			w.Watch(0, testKey, nil, 1)
-			defer func() {
-				w.Close()
-				wg.Done()
-			}()
-			tc := time.After(10 * time.Second)
-			evs, nextRev := 0, int64(2)
-			for evs < numPuts {
-				select {
-				case <-tc:
-					errc <- fmt.Errorf("time out")
-					return
-				case wr := <-w.Chan():
-					evs += len(wr.Events)
-					for _, ev := range wr.Events {
-						if ev.Kv.ModRevision != nextRev {
-							errc <- fmt.Errorf("expected rev=%d, got %d", nextRev, ev.Kv.ModRevision)
-							return
-						}
-						nextRev++
-					}
-					time.Sleep(time.Millisecond)
-				}
-			}
-			if evs != numPuts {
-				errc <- fmt.Errorf("expected %d events, got %d", numPuts, evs)
-				return
-			}
-			select {
-			case <-w.Chan():
-				errc <- fmt.Errorf("unexpected response")
-			default:
-			}
-		}()
-		time.Sleep(time.Millisecond)
-	}
-
-	var wgPut sync.WaitGroup
-	wgPut.Add(numPuts)
-	for i := 0; i < numPuts; i++ {
-		go func() {
-			defer wgPut.Done()
-			s.Put(testKey, testValue, lease.NoLease)
-		}()
-	}
-	wgPut.Wait()
-
-	wg.Wait()
-	select {
-	case err := <-errc:
-		t.Fatal(err)
-	default:
-	}
-}
-
-// TestStressWatchCancelClose tests closing a watch stream while
-// canceling its watches.
-func TestStressWatchCancelClose(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-
-	testKey, testValue := []byte("foo"), []byte("bar")
-	var wg sync.WaitGroup
-	readyc := make(chan struct{})
-	wg.Add(100)
-	for i := 0; i < 100; i++ {
-		go func() {
-			defer wg.Done()
-			w := s.NewWatchStream()
-			ids := make([]WatchID, 10)
-			for i := range ids {
-				ids[i], _ = w.Watch(0, testKey, nil, 0)
-			}
-			<-readyc
-			wg.Add(1 + len(ids)/2)
-			for i := range ids[:len(ids)/2] {
-				go func(n int) {
-					defer wg.Done()
-					w.Cancel(ids[n])
-				}(i)
-			}
-			go func() {
-				defer wg.Done()
-				w.Close()
-			}()
-		}()
-	}
-
-	close(readyc)
-	for i := 0; i < 100; i++ {
-		s.Put(testKey, testValue, lease.NoLease)
-	}
-
-	wg.Wait()
-}
diff --git a/mvcc/watchable_store_txn.go b/mvcc/watchable_store_txn.go
deleted file mode 100644
index 5c5bfda..0000000
--- a/mvcc/watchable_store_txn.go
+++ /dev/null
@@ -1,53 +0,0 @@
-// Copyright 2017 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"github.com/coreos/etcd/mvcc/mvccpb"
-)
-
-func (tw *watchableStoreTxnWrite) End() {
-	changes := tw.Changes()
-	if len(changes) == 0 {
-		tw.TxnWrite.End()
-		return
-	}
-
-	rev := tw.Rev() + 1
-	evs := make([]mvccpb.Event, len(changes))
-	for i, change := range changes {
-		evs[i].Kv = &changes[i]
-		if change.CreateRevision == 0 {
-			evs[i].Type = mvccpb.DELETE
-			evs[i].Kv.ModRevision = rev
-		} else {
-			evs[i].Type = mvccpb.PUT
-		}
-	}
-
-	// end write txn under watchable store lock so the updates are visible
-	// when asynchronous event posting checks the current store revision
-	tw.s.mu.Lock()
-	tw.s.notify(rev, evs)
-	tw.TxnWrite.End()
-	tw.s.mu.Unlock()
-}
-
-type watchableStoreTxnWrite struct {
-	TxnWrite
-	s *watchableStore
-}
-
-func (s *watchableStore) Write() TxnWrite { return &watchableStoreTxnWrite{s.store.Write(), s} }
diff --git a/mvcc/watcher.go b/mvcc/watcher.go
deleted file mode 100644
index 886b87d..0000000
--- a/mvcc/watcher.go
+++ /dev/null
@@ -1,193 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"bytes"
-	"errors"
-	"sync"
-
-	"github.com/coreos/etcd/mvcc/mvccpb"
-)
-
-// AutoWatchID is the watcher ID passed in WatchStream.Watch when no
-// user-provided ID is available. If pass, an ID will automatically be assigned.
-const AutoWatchID WatchID = 0
-
-var (
-	ErrWatcherNotExist    = errors.New("mvcc: watcher does not exist")
-	ErrEmptyWatcherRange  = errors.New("mvcc: watcher range is empty")
-	ErrWatcherDuplicateID = errors.New("mvcc: duplicate watch ID provided on the WatchStream")
-)
-
-type WatchID int64
-
-// FilterFunc returns true if the given event should be filtered out.
-type FilterFunc func(e mvccpb.Event) bool
-
-type WatchStream interface {
-	// Watch creates a watcher. The watcher watches the events happening or
-	// happened on the given key or range [key, end) from the given startRev.
-	//
-	// The whole event history can be watched unless compacted.
-	// If "startRev" <=0, watch observes events after currentRev.
-	//
-	// The returned "id" is the ID of this watcher. It appears as WatchID
-	// in events that are sent to the created watcher through stream channel.
-	// The watch ID is used when it's not equal to AutoWatchID. Otherwise,
-	// an auto-generated watch ID is returned.
-	Watch(id WatchID, key, end []byte, startRev int64, fcs ...FilterFunc) (WatchID, error)
-
-	// Chan returns a chan. All watch response will be sent to the returned chan.
-	Chan() <-chan WatchResponse
-
-	// RequestProgress requests the progress of the watcher with given ID. The response
-	// will only be sent if the watcher is currently synced.
-	// The responses will be sent through the WatchRespone Chan attached
-	// with this stream to ensure correct ordering.
-	// The responses contains no events. The revision in the response is the progress
-	// of the watchers since the watcher is currently synced.
-	RequestProgress(id WatchID)
-
-	// Cancel cancels a watcher by giving its ID. If watcher does not exist, an error will be
-	// returned.
-	Cancel(id WatchID) error
-
-	// Close closes Chan and release all related resources.
-	Close()
-
-	// Rev returns the current revision of the KV the stream watches on.
-	Rev() int64
-}
-
-type WatchResponse struct {
-	// WatchID is the WatchID of the watcher this response sent to.
-	WatchID WatchID
-
-	// Events contains all the events that needs to send.
-	Events []mvccpb.Event
-
-	// Revision is the revision of the KV when the watchResponse is created.
-	// For a normal response, the revision should be the same as the last
-	// modified revision inside Events. For a delayed response to a unsynced
-	// watcher, the revision is greater than the last modified revision
-	// inside Events.
-	Revision int64
-
-	// CompactRevision is set when the watcher is cancelled due to compaction.
-	CompactRevision int64
-}
-
-// watchStream contains a collection of watchers that share
-// one streaming chan to send out watched events and other control events.
-type watchStream struct {
-	watchable watchable
-	ch        chan WatchResponse
-
-	mu sync.Mutex // guards fields below it
-	// nextID is the ID pre-allocated for next new watcher in this stream
-	nextID   WatchID
-	closed   bool
-	cancels  map[WatchID]cancelFunc
-	watchers map[WatchID]*watcher
-}
-
-// Watch creates a new watcher in the stream and returns its WatchID.
-func (ws *watchStream) Watch(id WatchID, key, end []byte, startRev int64, fcs ...FilterFunc) (WatchID, error) {
-	// prevent wrong range where key >= end lexicographically
-	// watch request with 'WithFromKey' has empty-byte range end
-	if len(end) != 0 && bytes.Compare(key, end) != -1 {
-		return -1, ErrEmptyWatcherRange
-	}
-
-	ws.mu.Lock()
-	defer ws.mu.Unlock()
-	if ws.closed {
-		return -1, ErrEmptyWatcherRange
-	}
-
-	if id == AutoWatchID {
-		for ws.watchers[ws.nextID] != nil {
-			ws.nextID++
-		}
-		id = ws.nextID
-		ws.nextID++
-	} else if _, ok := ws.watchers[id]; ok {
-		return -1, ErrWatcherDuplicateID
-	}
-
-	w, c := ws.watchable.watch(key, end, startRev, id, ws.ch, fcs...)
-
-	ws.cancels[id] = c
-	ws.watchers[id] = w
-	return id, nil
-}
-
-func (ws *watchStream) Chan() <-chan WatchResponse {
-	return ws.ch
-}
-
-func (ws *watchStream) Cancel(id WatchID) error {
-	ws.mu.Lock()
-	cancel, ok := ws.cancels[id]
-	w := ws.watchers[id]
-	ok = ok && !ws.closed
-	ws.mu.Unlock()
-
-	if !ok {
-		return ErrWatcherNotExist
-	}
-	cancel()
-
-	ws.mu.Lock()
-	// The watch isn't removed until cancel so that if Close() is called,
-	// it will wait for the cancel. Otherwise, Close() could close the
-	// watch channel while the store is still posting events.
-	if ww := ws.watchers[id]; ww == w {
-		delete(ws.cancels, id)
-		delete(ws.watchers, id)
-	}
-	ws.mu.Unlock()
-
-	return nil
-}
-
-func (ws *watchStream) Close() {
-	ws.mu.Lock()
-	defer ws.mu.Unlock()
-
-	for _, cancel := range ws.cancels {
-		cancel()
-	}
-	ws.closed = true
-	close(ws.ch)
-	watchStreamGauge.Dec()
-}
-
-func (ws *watchStream) Rev() int64 {
-	ws.mu.Lock()
-	defer ws.mu.Unlock()
-	return ws.watchable.rev()
-}
-
-func (ws *watchStream) RequestProgress(id WatchID) {
-	ws.mu.Lock()
-	w, ok := ws.watchers[id]
-	ws.mu.Unlock()
-	if !ok {
-		return
-	}
-	ws.watchable.progress(w)
-}
diff --git a/mvcc/watcher_bench_test.go b/mvcc/watcher_bench_test.go
deleted file mode 100644
index a417817..0000000
--- a/mvcc/watcher_bench_test.go
+++ /dev/null
@@ -1,38 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"fmt"
-	"testing"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-)
-
-func BenchmarkKVWatcherMemoryUsage(b *testing.B) {
-	be, tmpPath := backend.NewDefaultTmpBackend()
-	watchable := newWatchableStore(be, &lease.FakeLessor{}, nil)
-
-	defer cleanup(watchable, be, tmpPath)
-
-	w := watchable.NewWatchStream()
-
-	b.ReportAllocs()
-	b.StartTimer()
-	for i := 0; i < b.N; i++ {
-		w.Watch(0, []byte(fmt.Sprint("foo", i)), nil, 0)
-	}
-}
diff --git a/mvcc/watcher_group.go b/mvcc/watcher_group.go
deleted file mode 100644
index 6ef1d0c..0000000
--- a/mvcc/watcher_group.go
+++ /dev/null
@@ -1,283 +0,0 @@
-// Copyright 2016 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"math"
-
-	"github.com/coreos/etcd/mvcc/mvccpb"
-	"github.com/coreos/etcd/pkg/adt"
-)
-
-var (
-	// watchBatchMaxRevs is the maximum distinct revisions that
-	// may be sent to an unsynced watcher at a time. Declared as
-	// var instead of const for testing purposes.
-	watchBatchMaxRevs = 1000
-)
-
-type eventBatch struct {
-	// evs is a batch of revision-ordered events
-	evs []mvccpb.Event
-	// revs is the minimum unique revisions observed for this batch
-	revs int
-	// moreRev is first revision with more events following this batch
-	moreRev int64
-}
-
-func (eb *eventBatch) add(ev mvccpb.Event) {
-	if eb.revs > watchBatchMaxRevs {
-		// maxed out batch size
-		return
-	}
-
-	if len(eb.evs) == 0 {
-		// base case
-		eb.revs = 1
-		eb.evs = append(eb.evs, ev)
-		return
-	}
-
-	// revision accounting
-	ebRev := eb.evs[len(eb.evs)-1].Kv.ModRevision
-	evRev := ev.Kv.ModRevision
-	if evRev > ebRev {
-		eb.revs++
-		if eb.revs > watchBatchMaxRevs {
-			eb.moreRev = evRev
-			return
-		}
-	}
-
-	eb.evs = append(eb.evs, ev)
-}
-
-type watcherBatch map[*watcher]*eventBatch
-
-func (wb watcherBatch) add(w *watcher, ev mvccpb.Event) {
-	eb := wb[w]
-	if eb == nil {
-		eb = &eventBatch{}
-		wb[w] = eb
-	}
-	eb.add(ev)
-}
-
-// newWatcherBatch maps watchers to their matched events. It enables quick
-// events look up by watcher.
-func newWatcherBatch(wg *watcherGroup, evs []mvccpb.Event) watcherBatch {
-	if len(wg.watchers) == 0 {
-		return nil
-	}
-
-	wb := make(watcherBatch)
-	for _, ev := range evs {
-		for w := range wg.watcherSetByKey(string(ev.Kv.Key)) {
-			if ev.Kv.ModRevision >= w.minRev {
-				// don't double notify
-				wb.add(w, ev)
-			}
-		}
-	}
-	return wb
-}
-
-type watcherSet map[*watcher]struct{}
-
-func (w watcherSet) add(wa *watcher) {
-	if _, ok := w[wa]; ok {
-		panic("add watcher twice!")
-	}
-	w[wa] = struct{}{}
-}
-
-func (w watcherSet) union(ws watcherSet) {
-	for wa := range ws {
-		w.add(wa)
-	}
-}
-
-func (w watcherSet) delete(wa *watcher) {
-	if _, ok := w[wa]; !ok {
-		panic("removing missing watcher!")
-	}
-	delete(w, wa)
-}
-
-type watcherSetByKey map[string]watcherSet
-
-func (w watcherSetByKey) add(wa *watcher) {
-	set := w[string(wa.key)]
-	if set == nil {
-		set = make(watcherSet)
-		w[string(wa.key)] = set
-	}
-	set.add(wa)
-}
-
-func (w watcherSetByKey) delete(wa *watcher) bool {
-	k := string(wa.key)
-	if v, ok := w[k]; ok {
-		if _, ok := v[wa]; ok {
-			delete(v, wa)
-			if len(v) == 0 {
-				// remove the set; nothing left
-				delete(w, k)
-			}
-			return true
-		}
-	}
-	return false
-}
-
-// watcherGroup is a collection of watchers organized by their ranges
-type watcherGroup struct {
-	// keyWatchers has the watchers that watch on a single key
-	keyWatchers watcherSetByKey
-	// ranges has the watchers that watch a range; it is sorted by interval
-	ranges adt.IntervalTree
-	// watchers is the set of all watchers
-	watchers watcherSet
-}
-
-func newWatcherGroup() watcherGroup {
-	return watcherGroup{
-		keyWatchers: make(watcherSetByKey),
-		watchers:    make(watcherSet),
-	}
-}
-
-// add puts a watcher in the group.
-func (wg *watcherGroup) add(wa *watcher) {
-	wg.watchers.add(wa)
-	if wa.end == nil {
-		wg.keyWatchers.add(wa)
-		return
-	}
-
-	// interval already registered?
-	ivl := adt.NewStringAffineInterval(string(wa.key), string(wa.end))
-	if iv := wg.ranges.Find(ivl); iv != nil {
-		iv.Val.(watcherSet).add(wa)
-		return
-	}
-
-	// not registered, put in interval tree
-	ws := make(watcherSet)
-	ws.add(wa)
-	wg.ranges.Insert(ivl, ws)
-}
-
-// contains is whether the given key has a watcher in the group.
-func (wg *watcherGroup) contains(key string) bool {
-	_, ok := wg.keyWatchers[key]
-	return ok || wg.ranges.Intersects(adt.NewStringAffinePoint(key))
-}
-
-// size gives the number of unique watchers in the group.
-func (wg *watcherGroup) size() int { return len(wg.watchers) }
-
-// delete removes a watcher from the group.
-func (wg *watcherGroup) delete(wa *watcher) bool {
-	if _, ok := wg.watchers[wa]; !ok {
-		return false
-	}
-	wg.watchers.delete(wa)
-	if wa.end == nil {
-		wg.keyWatchers.delete(wa)
-		return true
-	}
-
-	ivl := adt.NewStringAffineInterval(string(wa.key), string(wa.end))
-	iv := wg.ranges.Find(ivl)
-	if iv == nil {
-		return false
-	}
-
-	ws := iv.Val.(watcherSet)
-	delete(ws, wa)
-	if len(ws) == 0 {
-		// remove interval missing watchers
-		if ok := wg.ranges.Delete(ivl); !ok {
-			panic("could not remove watcher from interval tree")
-		}
-	}
-
-	return true
-}
-
-// choose selects watchers from the watcher group to update
-func (wg *watcherGroup) choose(maxWatchers int, curRev, compactRev int64) (*watcherGroup, int64) {
-	if len(wg.watchers) < maxWatchers {
-		return wg, wg.chooseAll(curRev, compactRev)
-	}
-	ret := newWatcherGroup()
-	for w := range wg.watchers {
-		if maxWatchers <= 0 {
-			break
-		}
-		maxWatchers--
-		ret.add(w)
-	}
-	return &ret, ret.chooseAll(curRev, compactRev)
-}
-
-func (wg *watcherGroup) chooseAll(curRev, compactRev int64) int64 {
-	minRev := int64(math.MaxInt64)
-	for w := range wg.watchers {
-		if w.minRev > curRev {
-			panic("watcher current revision should not exceed current revision")
-		}
-		if w.minRev < compactRev {
-			select {
-			case w.ch <- WatchResponse{WatchID: w.id, CompactRevision: compactRev}:
-				w.compacted = true
-				wg.delete(w)
-			default:
-				// retry next time
-			}
-			continue
-		}
-		if minRev > w.minRev {
-			minRev = w.minRev
-		}
-	}
-	return minRev
-}
-
-// watcherSetByKey gets the set of watchers that receive events on the given key.
-func (wg *watcherGroup) watcherSetByKey(key string) watcherSet {
-	wkeys := wg.keyWatchers[key]
-	wranges := wg.ranges.Stab(adt.NewStringAffinePoint(key))
-
-	// zero-copy cases
-	switch {
-	case len(wranges) == 0:
-		// no need to merge ranges or copy; reuse single-key set
-		return wkeys
-	case len(wranges) == 0 && len(wkeys) == 0:
-		return nil
-	case len(wranges) == 1 && len(wkeys) == 0:
-		return wranges[0].Val.(watcherSet)
-	}
-
-	// copy case
-	ret := make(watcherSet)
-	ret.union(wg.keyWatchers[key])
-	for _, item := range wranges {
-		ret.union(item.Val.(watcherSet))
-	}
-	return ret
-}
diff --git a/mvcc/watcher_test.go b/mvcc/watcher_test.go
deleted file mode 100644
index d9a11cb..0000000
--- a/mvcc/watcher_test.go
+++ /dev/null
@@ -1,379 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package mvcc
-
-import (
-	"bytes"
-	"fmt"
-	"os"
-	"reflect"
-	"testing"
-	"time"
-
-	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
-)
-
-// TestWatcherWatchID tests that each watcher provides unique watchID,
-// and the watched event attaches the correct watchID.
-func TestWatcherWatchID(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
-	defer cleanup(s, b, tmpPath)
-
-	w := s.NewWatchStream()
-	defer w.Close()
-
-	idm := make(map[WatchID]struct{})
-
-	for i := 0; i < 10; i++ {
-		id, _ := w.Watch(0, []byte("foo"), nil, 0)
-		if _, ok := idm[id]; ok {
-			t.Errorf("#%d: id %d exists", i, id)
-		}
-		idm[id] = struct{}{}
-
-		s.Put([]byte("foo"), []byte("bar"), lease.NoLease)
-
-		resp := <-w.Chan()
-		if resp.WatchID != id {
-			t.Errorf("#%d: watch id in event = %d, want %d", i, resp.WatchID, id)
-		}
-
-		if err := w.Cancel(id); err != nil {
-			t.Error(err)
-		}
-	}
-
-	s.Put([]byte("foo2"), []byte("bar"), lease.NoLease)
-
-	// unsynced watchers
-	for i := 10; i < 20; i++ {
-		id, _ := w.Watch(0, []byte("foo2"), nil, 1)
-		if _, ok := idm[id]; ok {
-			t.Errorf("#%d: id %d exists", i, id)
-		}
-		idm[id] = struct{}{}
-
-		resp := <-w.Chan()
-		if resp.WatchID != id {
-			t.Errorf("#%d: watch id in event = %d, want %d", i, resp.WatchID, id)
-		}
-
-		if err := w.Cancel(id); err != nil {
-			t.Error(err)
-		}
-	}
-}
-
-func TestWatcherRequestsCustomID(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
-	defer cleanup(s, b, tmpPath)
-
-	w := s.NewWatchStream()
-	defer w.Close()
-
-	// - Request specifically ID #1
-	// - Try to duplicate it, get an error
-	// - Make sure the auto-assignment skips over things we manually assigned
-
-	tt := []struct {
-		givenID     WatchID
-		expectedID  WatchID
-		expectedErr error
-	}{
-		{1, 1, nil},
-		{1, 0, ErrWatcherDuplicateID},
-		{0, 0, nil},
-		{0, 2, nil},
-	}
-
-	for i, tcase := range tt {
-		id, err := w.Watch(tcase.givenID, []byte("foo"), nil, 0)
-		if tcase.expectedErr != nil || err != nil {
-			if err != tcase.expectedErr {
-				t.Errorf("expected get error %q in test case %q, got %q", tcase.expectedErr, i, err)
-			}
-		} else if tcase.expectedID != id {
-			t.Errorf("expected to create ID %d, got %d in test case %d", tcase.expectedID, id, i)
-		}
-	}
-}
-
-// TestWatcherWatchPrefix tests if Watch operation correctly watches
-// and returns events with matching prefixes.
-func TestWatcherWatchPrefix(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
-	defer cleanup(s, b, tmpPath)
-
-	w := s.NewWatchStream()
-	defer w.Close()
-
-	idm := make(map[WatchID]struct{})
-
-	val := []byte("bar")
-	keyWatch, keyEnd, keyPut := []byte("foo"), []byte("fop"), []byte("foobar")
-
-	for i := 0; i < 10; i++ {
-		id, _ := w.Watch(0, keyWatch, keyEnd, 0)
-		if _, ok := idm[id]; ok {
-			t.Errorf("#%d: unexpected duplicated id %x", i, id)
-		}
-		idm[id] = struct{}{}
-
-		s.Put(keyPut, val, lease.NoLease)
-
-		resp := <-w.Chan()
-		if resp.WatchID != id {
-			t.Errorf("#%d: watch id in event = %d, want %d", i, resp.WatchID, id)
-		}
-
-		if err := w.Cancel(id); err != nil {
-			t.Errorf("#%d: unexpected cancel error %v", i, err)
-		}
-
-		if len(resp.Events) != 1 {
-			t.Errorf("#%d: len(resp.Events) got = %d, want = 1", i, len(resp.Events))
-		}
-		if len(resp.Events) == 1 {
-			if !bytes.Equal(resp.Events[0].Kv.Key, keyPut) {
-				t.Errorf("#%d: resp.Events got = %s, want = %s", i, resp.Events[0].Kv.Key, keyPut)
-			}
-		}
-	}
-
-	keyWatch1, keyEnd1, keyPut1 := []byte("foo1"), []byte("foo2"), []byte("foo1bar")
-	s.Put(keyPut1, val, lease.NoLease)
-
-	// unsynced watchers
-	for i := 10; i < 15; i++ {
-		id, _ := w.Watch(0, keyWatch1, keyEnd1, 1)
-		if _, ok := idm[id]; ok {
-			t.Errorf("#%d: id %d exists", i, id)
-		}
-		idm[id] = struct{}{}
-
-		resp := <-w.Chan()
-		if resp.WatchID != id {
-			t.Errorf("#%d: watch id in event = %d, want %d", i, resp.WatchID, id)
-		}
-
-		if err := w.Cancel(id); err != nil {
-			t.Error(err)
-		}
-
-		if len(resp.Events) != 1 {
-			t.Errorf("#%d: len(resp.Events) got = %d, want = 1", i, len(resp.Events))
-		}
-		if len(resp.Events) == 1 {
-			if !bytes.Equal(resp.Events[0].Kv.Key, keyPut1) {
-				t.Errorf("#%d: resp.Events got = %s, want = %s", i, resp.Events[0].Kv.Key, keyPut1)
-			}
-		}
-	}
-}
-
-// TestWatcherWatchWrongRange ensures that watcher with wrong 'end' range
-// does not create watcher, which panics when canceling in range tree.
-func TestWatcherWatchWrongRange(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
-	defer cleanup(s, b, tmpPath)
-
-	w := s.NewWatchStream()
-	defer w.Close()
-
-	if _, err := w.Watch(0, []byte("foa"), []byte("foa"), 1); err != ErrEmptyWatcherRange {
-		t.Fatalf("key == end range given; expected ErrEmptyWatcherRange, got %+v", err)
-	}
-	if _, err := w.Watch(0, []byte("fob"), []byte("foa"), 1); err != ErrEmptyWatcherRange {
-		t.Fatalf("key > end range given; expected ErrEmptyWatcherRange, got %+v", err)
-	}
-	// watch request with 'WithFromKey' has empty-byte range end
-	if id, _ := w.Watch(0, []byte("foo"), []byte{}, 1); id != 0 {
-		t.Fatalf("\x00 is range given; id expected 0, got %d", id)
-	}
-}
-
-func TestWatchDeleteRange(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := newWatchableStore(b, &lease.FakeLessor{}, nil)
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-
-	testKeyPrefix := []byte("foo")
-
-	for i := 0; i < 3; i++ {
-		s.Put([]byte(fmt.Sprintf("%s_%d", testKeyPrefix, i)), []byte("bar"), lease.NoLease)
-	}
-
-	w := s.NewWatchStream()
-	from, to := []byte(testKeyPrefix), []byte(fmt.Sprintf("%s_%d", testKeyPrefix, 99))
-	w.Watch(0, from, to, 0)
-
-	s.DeleteRange(from, to)
-
-	we := []mvccpb.Event{
-		{Type: mvccpb.DELETE, Kv: &mvccpb.KeyValue{Key: []byte("foo_0"), ModRevision: 5}},
-		{Type: mvccpb.DELETE, Kv: &mvccpb.KeyValue{Key: []byte("foo_1"), ModRevision: 5}},
-		{Type: mvccpb.DELETE, Kv: &mvccpb.KeyValue{Key: []byte("foo_2"), ModRevision: 5}},
-	}
-
-	select {
-	case r := <-w.Chan():
-		if !reflect.DeepEqual(r.Events, we) {
-			t.Errorf("event = %v, want %v", r.Events, we)
-		}
-	case <-time.After(10 * time.Second):
-		t.Fatal("failed to receive event after 10 seconds!")
-	}
-}
-
-// TestWatchStreamCancelWatcherByID ensures cancel calls the cancel func of the watcher
-// with given id inside watchStream.
-func TestWatchStreamCancelWatcherByID(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
-	defer cleanup(s, b, tmpPath)
-
-	w := s.NewWatchStream()
-	defer w.Close()
-
-	id, _ := w.Watch(0, []byte("foo"), nil, 0)
-
-	tests := []struct {
-		cancelID WatchID
-		werr     error
-	}{
-		// no error should be returned when cancel the created watcher.
-		{id, nil},
-		// not exist error should be returned when cancel again.
-		{id, ErrWatcherNotExist},
-		// not exist error should be returned when cancel a bad id.
-		{id + 1, ErrWatcherNotExist},
-	}
-
-	for i, tt := range tests {
-		gerr := w.Cancel(tt.cancelID)
-
-		if gerr != tt.werr {
-			t.Errorf("#%d: err = %v, want %v", i, gerr, tt.werr)
-		}
-	}
-
-	if l := len(w.(*watchStream).cancels); l != 0 {
-		t.Errorf("cancels = %d, want 0", l)
-	}
-}
-
-// TestWatcherRequestProgress ensures synced watcher can correctly
-// report its correct progress.
-func TestWatcherRequestProgress(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-
-	// manually create watchableStore instead of newWatchableStore
-	// because newWatchableStore automatically calls syncWatchers
-	// method to sync watchers in unsynced map. We want to keep watchers
-	// in unsynced to test if syncWatchers works as expected.
-	s := &watchableStore{
-		store:    NewStore(b, &lease.FakeLessor{}, nil),
-		unsynced: newWatcherGroup(),
-		synced:   newWatcherGroup(),
-	}
-
-	defer func() {
-		s.store.Close()
-		os.Remove(tmpPath)
-	}()
-
-	testKey := []byte("foo")
-	notTestKey := []byte("bad")
-	testValue := []byte("bar")
-	s.Put(testKey, testValue, lease.NoLease)
-
-	w := s.NewWatchStream()
-
-	badID := WatchID(1000)
-	w.RequestProgress(badID)
-	select {
-	case resp := <-w.Chan():
-		t.Fatalf("unexpected %+v", resp)
-	default:
-	}
-
-	id, _ := w.Watch(0, notTestKey, nil, 1)
-	w.RequestProgress(id)
-	select {
-	case resp := <-w.Chan():
-		t.Fatalf("unexpected %+v", resp)
-	default:
-	}
-
-	s.syncWatchers()
-
-	w.RequestProgress(id)
-	wrs := WatchResponse{WatchID: id, Revision: 2}
-	select {
-	case resp := <-w.Chan():
-		if !reflect.DeepEqual(resp, wrs) {
-			t.Fatalf("got %+v, expect %+v", resp, wrs)
-		}
-	case <-time.After(time.Second):
-		t.Fatal("failed to receive progress")
-	}
-}
-
-func TestWatcherWatchWithFilter(t *testing.T) {
-	b, tmpPath := backend.NewDefaultTmpBackend()
-	s := WatchableKV(newWatchableStore(b, &lease.FakeLessor{}, nil))
-	defer cleanup(s, b, tmpPath)
-
-	w := s.NewWatchStream()
-	defer w.Close()
-
-	filterPut := func(e mvccpb.Event) bool {
-		return e.Type == mvccpb.PUT
-	}
-
-	w.Watch(0, []byte("foo"), nil, 0, filterPut)
-	done := make(chan struct{})
-
-	go func() {
-		<-w.Chan()
-		done <- struct{}{}
-	}()
-
-	s.Put([]byte("foo"), []byte("bar"), 0)
-
-	select {
-	case <-done:
-		t.Fatal("failed to filter put request")
-	case <-time.After(100 * time.Millisecond):
-	}
-
-	s.DeleteRange([]byte("foo"), nil)
-
-	select {
-	case <-done:
-	case <-time.After(100 * time.Millisecond):
-		t.Fatal("failed to receive delete request")
-	}
-}
diff --git a/proxy/grpcproxy/watcher.go b/proxy/grpcproxy/watcher.go
index 1a49746..0c56e56 100644
--- a/proxy/grpcproxy/watcher.go
+++ b/proxy/grpcproxy/watcher.go
@@ -19,8 +19,8 @@ import (
 
 	"github.com/coreos/etcd/clientv3"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 type watchRange struct {
diff --git a/snapshot/v3_snapshot.go b/snapshot/v3_snapshot.go
index 26cb83a..7988989 100644
--- a/snapshot/v3_snapshot.go
+++ b/snapshot/v3_snapshot.go
@@ -31,10 +31,10 @@ import (
 	"github.com/coreos/etcd/etcdserver/etcdserverpb"
 	"github.com/coreos/etcd/etcdserver/membership"
 	"github.com/coreos/etcd/internal/lease"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/coreos/etcd/internal/raftsnap"
 	"github.com/coreos/etcd/internal/store"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
 	"github.com/coreos/etcd/pkg/fileutil"
 	"github.com/coreos/etcd/pkg/logger"
 	"github.com/coreos/etcd/pkg/types"
diff --git a/tools/benchmark/cmd/mvcc.go b/tools/benchmark/cmd/mvcc.go
index dac23a2..72b3f37 100644
--- a/tools/benchmark/cmd/mvcc.go
+++ b/tools/benchmark/cmd/mvcc.go
@@ -19,8 +19,8 @@ import (
 	"time"
 
 	"github.com/coreos/etcd/internal/lease"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
 	"github.com/spf13/cobra"
 )
 
diff --git a/tools/etcd-dump-db/backend.go b/tools/etcd-dump-db/backend.go
index d40ce09..986adf0 100644
--- a/tools/etcd-dump-db/backend.go
+++ b/tools/etcd-dump-db/backend.go
@@ -21,9 +21,9 @@ import (
 
 	bolt "github.com/coreos/bbolt"
 	"github.com/coreos/etcd/internal/lease/leasepb"
-	"github.com/coreos/etcd/mvcc"
-	"github.com/coreos/etcd/mvcc/backend"
-	"github.com/coreos/etcd/mvcc/mvccpb"
+	"github.com/coreos/etcd/internal/mvcc"
+	"github.com/coreos/etcd/internal/mvcc/backend"
+	"github.com/coreos/etcd/internal/mvcc/mvccpb"
 )
 
 func snapDir(dataDir string) string {
