commit 432581c7d08ee76ccef7a0eead64792909ad711f
Author: Gyuho Lee <gyuhox@gmail.com>
Date:   Thu Jan 25 14:32:13 2018 -0800

    *: move "discovery" to "internal/discovery"
    
    Signed-off-by: Gyuho Lee <gyuhox@gmail.com>

diff --git a/discovery/discovery.go b/discovery/discovery.go
deleted file mode 100644
index 7d1fa0d..0000000
--- a/discovery/discovery.go
+++ /dev/null
@@ -1,363 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-// Package discovery provides an implementation of the cluster discovery that
-// is used by etcd.
-package discovery
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"math"
-	"net/http"
-	"net/url"
-	"path"
-	"sort"
-	"strconv"
-	"strings"
-	"time"
-
-	"github.com/coreos/etcd/client"
-	"github.com/coreos/etcd/pkg/transport"
-	"github.com/coreos/etcd/pkg/types"
-
-	"github.com/coreos/pkg/capnslog"
-	"github.com/jonboulle/clockwork"
-)
-
-var (
-	plog = capnslog.NewPackageLogger("github.com/coreos/etcd", "discovery")
-
-	ErrInvalidURL           = errors.New("discovery: invalid URL")
-	ErrBadSizeKey           = errors.New("discovery: size key is bad")
-	ErrSizeNotFound         = errors.New("discovery: size key not found")
-	ErrTokenNotFound        = errors.New("discovery: token not found")
-	ErrDuplicateID          = errors.New("discovery: found duplicate id")
-	ErrDuplicateName        = errors.New("discovery: found duplicate name")
-	ErrFullCluster          = errors.New("discovery: cluster is full")
-	ErrTooManyRetries       = errors.New("discovery: too many retries")
-	ErrBadDiscoveryEndpoint = errors.New("discovery: bad discovery endpoint")
-)
-
-var (
-	// Number of retries discovery will attempt before giving up and erroring out.
-	nRetries             = uint(math.MaxUint32)
-	maxExpoentialRetries = uint(8)
-)
-
-// JoinCluster will connect to the discovery service at the given url, and
-// register the server represented by the given id and config to the cluster
-func JoinCluster(durl, dproxyurl string, id types.ID, config string) (string, error) {
-	d, err := newDiscovery(durl, dproxyurl, id)
-	if err != nil {
-		return "", err
-	}
-	return d.joinCluster(config)
-}
-
-// GetCluster will connect to the discovery service at the given url and
-// retrieve a string describing the cluster
-func GetCluster(durl, dproxyurl string) (string, error) {
-	d, err := newDiscovery(durl, dproxyurl, 0)
-	if err != nil {
-		return "", err
-	}
-	return d.getCluster()
-}
-
-type discovery struct {
-	cluster string
-	id      types.ID
-	c       client.KeysAPI
-	retries uint
-	url     *url.URL
-
-	clock clockwork.Clock
-}
-
-// newProxyFunc builds a proxy function from the given string, which should
-// represent a URL that can be used as a proxy. It performs basic
-// sanitization of the URL and returns any error encountered.
-func newProxyFunc(proxy string) (func(*http.Request) (*url.URL, error), error) {
-	if proxy == "" {
-		return nil, nil
-	}
-	// Do a small amount of URL sanitization to help the user
-	// Derived from net/http.ProxyFromEnvironment
-	proxyURL, err := url.Parse(proxy)
-	if err != nil || !strings.HasPrefix(proxyURL.Scheme, "http") {
-		// proxy was bogus. Try prepending "http://" to it and
-		// see if that parses correctly. If not, we ignore the
-		// error and complain about the original one
-		var err2 error
-		proxyURL, err2 = url.Parse("http://" + proxy)
-		if err2 == nil {
-			err = nil
-		}
-	}
-	if err != nil {
-		return nil, fmt.Errorf("invalid proxy address %q: %v", proxy, err)
-	}
-
-	plog.Infof("using proxy %q", proxyURL.String())
-	return http.ProxyURL(proxyURL), nil
-}
-
-func newDiscovery(durl, dproxyurl string, id types.ID) (*discovery, error) {
-	u, err := url.Parse(durl)
-	if err != nil {
-		return nil, err
-	}
-	token := u.Path
-	u.Path = ""
-	pf, err := newProxyFunc(dproxyurl)
-	if err != nil {
-		return nil, err
-	}
-
-	// TODO: add ResponseHeaderTimeout back when watch on discovery service writes header early
-	tr, err := transport.NewTransport(transport.TLSInfo{}, 30*time.Second)
-	if err != nil {
-		return nil, err
-	}
-	tr.Proxy = pf
-	cfg := client.Config{
-		Transport: tr,
-		Endpoints: []string{u.String()},
-	}
-	c, err := client.New(cfg)
-	if err != nil {
-		return nil, err
-	}
-	dc := client.NewKeysAPIWithPrefix(c, "")
-	return &discovery{
-		cluster: token,
-		c:       dc,
-		id:      id,
-		url:     u,
-		clock:   clockwork.NewRealClock(),
-	}, nil
-}
-
-func (d *discovery) joinCluster(config string) (string, error) {
-	// fast path: if the cluster is full, return the error
-	// do not need to register to the cluster in this case.
-	if _, _, _, err := d.checkCluster(); err != nil {
-		return "", err
-	}
-
-	if err := d.createSelf(config); err != nil {
-		// Fails, even on a timeout, if createSelf times out.
-		// TODO(barakmich): Retrying the same node might want to succeed here
-		// (ie, createSelf should be idempotent for discovery).
-		return "", err
-	}
-
-	nodes, size, index, err := d.checkCluster()
-	if err != nil {
-		return "", err
-	}
-
-	all, err := d.waitNodes(nodes, size, index)
-	if err != nil {
-		return "", err
-	}
-
-	return nodesToCluster(all, size)
-}
-
-func (d *discovery) getCluster() (string, error) {
-	nodes, size, index, err := d.checkCluster()
-	if err != nil {
-		if err == ErrFullCluster {
-			return nodesToCluster(nodes, size)
-		}
-		return "", err
-	}
-
-	all, err := d.waitNodes(nodes, size, index)
-	if err != nil {
-		return "", err
-	}
-	return nodesToCluster(all, size)
-}
-
-func (d *discovery) createSelf(contents string) error {
-	ctx, cancel := context.WithTimeout(context.Background(), client.DefaultRequestTimeout)
-	resp, err := d.c.Create(ctx, d.selfKey(), contents)
-	cancel()
-	if err != nil {
-		if eerr, ok := err.(client.Error); ok && eerr.Code == client.ErrorCodeNodeExist {
-			return ErrDuplicateID
-		}
-		return err
-	}
-
-	// ensure self appears on the server we connected to
-	w := d.c.Watcher(d.selfKey(), &client.WatcherOptions{AfterIndex: resp.Node.CreatedIndex - 1})
-	_, err = w.Next(context.Background())
-	return err
-}
-
-func (d *discovery) checkCluster() ([]*client.Node, int, uint64, error) {
-	configKey := path.Join("/", d.cluster, "_config")
-	ctx, cancel := context.WithTimeout(context.Background(), client.DefaultRequestTimeout)
-	// find cluster size
-	resp, err := d.c.Get(ctx, path.Join(configKey, "size"), nil)
-	cancel()
-	if err != nil {
-		if eerr, ok := err.(*client.Error); ok && eerr.Code == client.ErrorCodeKeyNotFound {
-			return nil, 0, 0, ErrSizeNotFound
-		}
-		if err == client.ErrInvalidJSON {
-			return nil, 0, 0, ErrBadDiscoveryEndpoint
-		}
-		if ce, ok := err.(*client.ClusterError); ok {
-			plog.Error(ce.Detail())
-			return d.checkClusterRetry()
-		}
-		return nil, 0, 0, err
-	}
-	size, err := strconv.Atoi(resp.Node.Value)
-	if err != nil {
-		return nil, 0, 0, ErrBadSizeKey
-	}
-
-	ctx, cancel = context.WithTimeout(context.Background(), client.DefaultRequestTimeout)
-	resp, err = d.c.Get(ctx, d.cluster, nil)
-	cancel()
-	if err != nil {
-		if ce, ok := err.(*client.ClusterError); ok {
-			plog.Error(ce.Detail())
-			return d.checkClusterRetry()
-		}
-		return nil, 0, 0, err
-	}
-	var nodes []*client.Node
-	// append non-config keys to nodes
-	for _, n := range resp.Node.Nodes {
-		if !(path.Base(n.Key) == path.Base(configKey)) {
-			nodes = append(nodes, n)
-		}
-	}
-
-	snodes := sortableNodes{nodes}
-	sort.Sort(snodes)
-
-	// find self position
-	for i := range nodes {
-		if path.Base(nodes[i].Key) == path.Base(d.selfKey()) {
-			break
-		}
-		if i >= size-1 {
-			return nodes[:size], size, resp.Index, ErrFullCluster
-		}
-	}
-	return nodes, size, resp.Index, nil
-}
-
-func (d *discovery) logAndBackoffForRetry(step string) {
-	d.retries++
-	// logAndBackoffForRetry stops exponential backoff when the retries are more than maxExpoentialRetries and is set to a constant backoff afterward.
-	retries := d.retries
-	if retries > maxExpoentialRetries {
-		retries = maxExpoentialRetries
-	}
-	retryTimeInSecond := time.Duration(0x1<<retries) * time.Second
-	plog.Infof("%s: error connecting to %s, retrying in %s", step, d.url, retryTimeInSecond)
-	d.clock.Sleep(retryTimeInSecond)
-}
-
-func (d *discovery) checkClusterRetry() ([]*client.Node, int, uint64, error) {
-	if d.retries < nRetries {
-		d.logAndBackoffForRetry("cluster status check")
-		return d.checkCluster()
-	}
-	return nil, 0, 0, ErrTooManyRetries
-}
-
-func (d *discovery) waitNodesRetry() ([]*client.Node, error) {
-	if d.retries < nRetries {
-		d.logAndBackoffForRetry("waiting for other nodes")
-		nodes, n, index, err := d.checkCluster()
-		if err != nil {
-			return nil, err
-		}
-		return d.waitNodes(nodes, n, index)
-	}
-	return nil, ErrTooManyRetries
-}
-
-func (d *discovery) waitNodes(nodes []*client.Node, size int, index uint64) ([]*client.Node, error) {
-	if len(nodes) > size {
-		nodes = nodes[:size]
-	}
-	// watch from the next index
-	w := d.c.Watcher(d.cluster, &client.WatcherOptions{AfterIndex: index, Recursive: true})
-	all := make([]*client.Node, len(nodes))
-	copy(all, nodes)
-	for _, n := range all {
-		if path.Base(n.Key) == path.Base(d.selfKey()) {
-			plog.Noticef("found self %s in the cluster", path.Base(d.selfKey()))
-		} else {
-			plog.Noticef("found peer %s in the cluster", path.Base(n.Key))
-		}
-	}
-
-	// wait for others
-	for len(all) < size {
-		plog.Noticef("found %d peer(s), waiting for %d more", len(all), size-len(all))
-		resp, err := w.Next(context.Background())
-		if err != nil {
-			if ce, ok := err.(*client.ClusterError); ok {
-				plog.Error(ce.Detail())
-				return d.waitNodesRetry()
-			}
-			return nil, err
-		}
-		plog.Noticef("found peer %s in the cluster", path.Base(resp.Node.Key))
-		all = append(all, resp.Node)
-	}
-	plog.Noticef("found %d needed peer(s)", len(all))
-	return all, nil
-}
-
-func (d *discovery) selfKey() string {
-	return path.Join("/", d.cluster, d.id.String())
-}
-
-func nodesToCluster(ns []*client.Node, size int) (string, error) {
-	s := make([]string, len(ns))
-	for i, n := range ns {
-		s[i] = n.Value
-	}
-	us := strings.Join(s, ",")
-	m, err := types.NewURLsMap(us)
-	if err != nil {
-		return us, ErrInvalidURL
-	}
-	if m.Len() != size {
-		return us, ErrDuplicateName
-	}
-	return us, nil
-}
-
-type sortableNodes struct{ Nodes []*client.Node }
-
-func (ns sortableNodes) Len() int { return len(ns.Nodes) }
-func (ns sortableNodes) Less(i, j int) bool {
-	return ns.Nodes[i].CreatedIndex < ns.Nodes[j].CreatedIndex
-}
-func (ns sortableNodes) Swap(i, j int) { ns.Nodes[i], ns.Nodes[j] = ns.Nodes[j], ns.Nodes[i] }
diff --git a/discovery/discovery_test.go b/discovery/discovery_test.go
deleted file mode 100644
index 8989726..0000000
--- a/discovery/discovery_test.go
+++ /dev/null
@@ -1,558 +0,0 @@
-// Copyright 2015 The etcd Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package discovery
-
-import (
-	"context"
-	"errors"
-	"math"
-	"math/rand"
-	"net/http"
-	"reflect"
-	"sort"
-	"strconv"
-	"testing"
-	"time"
-
-	"github.com/coreos/etcd/client"
-
-	"github.com/jonboulle/clockwork"
-)
-
-const (
-	maxRetryInTest = 3
-)
-
-func TestNewProxyFuncUnset(t *testing.T) {
-	pf, err := newProxyFunc("")
-	if pf != nil {
-		t.Fatal("unexpected non-nil proxyFunc")
-	}
-	if err != nil {
-		t.Fatalf("unexpected non-nil err: %v", err)
-	}
-}
-
-func TestNewProxyFuncBad(t *testing.T) {
-	tests := []string{
-		"%%",
-		"http://foo.com/%1",
-	}
-	for i, in := range tests {
-		pf, err := newProxyFunc(in)
-		if pf != nil {
-			t.Errorf("#%d: unexpected non-nil proxyFunc", i)
-		}
-		if err == nil {
-			t.Errorf("#%d: unexpected nil err", i)
-		}
-	}
-}
-
-func TestNewProxyFunc(t *testing.T) {
-	tests := map[string]string{
-		"bar.com":              "http://bar.com",
-		"http://disco.foo.bar": "http://disco.foo.bar",
-	}
-	for in, w := range tests {
-		pf, err := newProxyFunc(in)
-		if pf == nil {
-			t.Errorf("%s: unexpected nil proxyFunc", in)
-			continue
-		}
-		if err != nil {
-			t.Errorf("%s: unexpected non-nil err: %v", in, err)
-			continue
-		}
-		g, err := pf(&http.Request{})
-		if err != nil {
-			t.Errorf("%s: unexpected non-nil err: %v", in, err)
-		}
-		if g.String() != w {
-			t.Errorf("%s: proxyURL=%q, want %q", in, g, w)
-		}
-
-	}
-}
-
-func TestCheckCluster(t *testing.T) {
-	cluster := "/prefix/1000"
-	self := "/1000/1"
-
-	tests := []struct {
-		nodes []*client.Node
-		index uint64
-		werr  error
-		wsize int
-	}{
-		{
-			// self is in the size range
-			[]*client.Node{
-				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
-				{Key: "/1000/_config/"},
-				{Key: self, CreatedIndex: 2},
-				{Key: "/1000/2", CreatedIndex: 3},
-				{Key: "/1000/3", CreatedIndex: 4},
-				{Key: "/1000/4", CreatedIndex: 5},
-			},
-			5,
-			nil,
-			3,
-		},
-		{
-			// self is in the size range
-			[]*client.Node{
-				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
-				{Key: "/1000/_config/"},
-				{Key: "/1000/2", CreatedIndex: 2},
-				{Key: "/1000/3", CreatedIndex: 3},
-				{Key: self, CreatedIndex: 4},
-				{Key: "/1000/4", CreatedIndex: 5},
-			},
-			5,
-			nil,
-			3,
-		},
-		{
-			// self is out of the size range
-			[]*client.Node{
-				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
-				{Key: "/1000/_config/"},
-				{Key: "/1000/2", CreatedIndex: 2},
-				{Key: "/1000/3", CreatedIndex: 3},
-				{Key: "/1000/4", CreatedIndex: 4},
-				{Key: self, CreatedIndex: 5},
-			},
-			5,
-			ErrFullCluster,
-			3,
-		},
-		{
-			// self is not in the cluster
-			[]*client.Node{
-				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
-				{Key: "/1000/_config/"},
-				{Key: "/1000/2", CreatedIndex: 2},
-				{Key: "/1000/3", CreatedIndex: 3},
-			},
-			3,
-			nil,
-			3,
-		},
-		{
-			[]*client.Node{
-				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
-				{Key: "/1000/_config/"},
-				{Key: "/1000/2", CreatedIndex: 2},
-				{Key: "/1000/3", CreatedIndex: 3},
-				{Key: "/1000/4", CreatedIndex: 4},
-			},
-			3,
-			ErrFullCluster,
-			3,
-		},
-		{
-			// bad size key
-			[]*client.Node{
-				{Key: "/1000/_config/size", Value: "bad", CreatedIndex: 1},
-			},
-			0,
-			ErrBadSizeKey,
-			0,
-		},
-		{
-			// no size key
-			[]*client.Node{},
-			0,
-			ErrSizeNotFound,
-			0,
-		},
-	}
-
-	for i, tt := range tests {
-		var rs []*client.Response
-		if len(tt.nodes) > 0 {
-			rs = append(rs, &client.Response{Node: tt.nodes[0], Index: tt.index})
-			rs = append(rs, &client.Response{
-				Node: &client.Node{
-					Key:   cluster,
-					Nodes: tt.nodes[1:],
-				},
-				Index: tt.index,
-			})
-		}
-		c := &clientWithResp{rs: rs}
-		dBase := discovery{cluster: cluster, id: 1, c: c}
-
-		cRetry := &clientWithRetry{failTimes: 3}
-		cRetry.rs = rs
-		fc := clockwork.NewFakeClock()
-		dRetry := discovery{cluster: cluster, id: 1, c: cRetry, clock: fc}
-
-		for _, d := range []discovery{dBase, dRetry} {
-			go func() {
-				for i := uint(1); i <= maxRetryInTest; i++ {
-					fc.BlockUntil(1)
-					fc.Advance(time.Second * (0x1 << i))
-				}
-			}()
-			ns, size, index, err := d.checkCluster()
-			if err != tt.werr {
-				t.Errorf("#%d: err = %v, want %v", i, err, tt.werr)
-			}
-			if reflect.DeepEqual(ns, tt.nodes) {
-				t.Errorf("#%d: nodes = %v, want %v", i, ns, tt.nodes)
-			}
-			if size != tt.wsize {
-				t.Errorf("#%d: size = %v, want %d", i, size, tt.wsize)
-			}
-			if index != tt.index {
-				t.Errorf("#%d: index = %v, want %d", i, index, tt.index)
-			}
-		}
-	}
-}
-
-func TestWaitNodes(t *testing.T) {
-	all := []*client.Node{
-		0: {Key: "/1000/1", CreatedIndex: 2},
-		1: {Key: "/1000/2", CreatedIndex: 3},
-		2: {Key: "/1000/3", CreatedIndex: 4},
-	}
-
-	tests := []struct {
-		nodes []*client.Node
-		rs    []*client.Response
-	}{
-		{
-			all,
-			[]*client.Response{},
-		},
-		{
-			all[:1],
-			[]*client.Response{
-				{Node: &client.Node{Key: "/1000/2", CreatedIndex: 3}},
-				{Node: &client.Node{Key: "/1000/3", CreatedIndex: 4}},
-			},
-		},
-		{
-			all[:2],
-			[]*client.Response{
-				{Node: &client.Node{Key: "/1000/3", CreatedIndex: 4}},
-			},
-		},
-		{
-			append(all, &client.Node{Key: "/1000/4", CreatedIndex: 5}),
-			[]*client.Response{
-				{Node: &client.Node{Key: "/1000/3", CreatedIndex: 4}},
-			},
-		},
-	}
-
-	for i, tt := range tests {
-		// Basic case
-		c := &clientWithResp{rs: nil, w: &watcherWithResp{rs: tt.rs}}
-		dBase := &discovery{cluster: "1000", c: c}
-
-		// Retry case
-		var retryScanResp []*client.Response
-		if len(tt.nodes) > 0 {
-			retryScanResp = append(retryScanResp, &client.Response{
-				Node: &client.Node{
-					Key:   "1000",
-					Value: strconv.Itoa(3),
-				},
-			})
-			retryScanResp = append(retryScanResp, &client.Response{
-				Node: &client.Node{
-					Nodes: tt.nodes,
-				},
-			})
-		}
-		cRetry := &clientWithResp{
-			rs: retryScanResp,
-			w:  &watcherWithRetry{rs: tt.rs, failTimes: 2},
-		}
-		fc := clockwork.NewFakeClock()
-		dRetry := &discovery{
-			cluster: "1000",
-			c:       cRetry,
-			clock:   fc,
-		}
-
-		for _, d := range []*discovery{dBase, dRetry} {
-			go func() {
-				for i := uint(1); i <= maxRetryInTest; i++ {
-					fc.BlockUntil(1)
-					fc.Advance(time.Second * (0x1 << i))
-				}
-			}()
-			g, err := d.waitNodes(tt.nodes, 3, 0) // we do not care about index in this test
-			if err != nil {
-				t.Errorf("#%d: err = %v, want %v", i, err, nil)
-			}
-			if !reflect.DeepEqual(g, all) {
-				t.Errorf("#%d: all = %v, want %v", i, g, all)
-			}
-		}
-	}
-}
-
-func TestCreateSelf(t *testing.T) {
-	rs := []*client.Response{{Node: &client.Node{Key: "1000/1", CreatedIndex: 2}}}
-
-	w := &watcherWithResp{rs: rs}
-	errw := &watcherWithErr{err: errors.New("watch err")}
-
-	c := &clientWithResp{rs: rs, w: w}
-	errc := &clientWithErr{err: errors.New("create err"), w: w}
-	errdupc := &clientWithErr{err: client.Error{Code: client.ErrorCodeNodeExist}}
-	errwc := &clientWithResp{rs: rs, w: errw}
-
-	tests := []struct {
-		c    client.KeysAPI
-		werr error
-	}{
-		// no error
-		{c, nil},
-		// client.create returns an error
-		{errc, errc.err},
-		// watcher.next returns an error
-		{errwc, errw.err},
-		// parse key exist error to duplicate ID error
-		{errdupc, ErrDuplicateID},
-	}
-
-	for i, tt := range tests {
-		d := discovery{cluster: "1000", c: tt.c}
-		if err := d.createSelf(""); err != tt.werr {
-			t.Errorf("#%d: err = %v, want %v", i, err, nil)
-		}
-	}
-}
-
-func TestNodesToCluster(t *testing.T) {
-	tests := []struct {
-		nodes    []*client.Node
-		size     int
-		wcluster string
-		werr     error
-	}{
-		{
-			[]*client.Node{
-				0: {Key: "/1000/1", Value: "1=http://1.1.1.1:2380", CreatedIndex: 1},
-				1: {Key: "/1000/2", Value: "2=http://2.2.2.2:2380", CreatedIndex: 2},
-				2: {Key: "/1000/3", Value: "3=http://3.3.3.3:2380", CreatedIndex: 3},
-			},
-			3,
-			"1=http://1.1.1.1:2380,2=http://2.2.2.2:2380,3=http://3.3.3.3:2380",
-			nil,
-		},
-		{
-			[]*client.Node{
-				0: {Key: "/1000/1", Value: "1=http://1.1.1.1:2380", CreatedIndex: 1},
-				1: {Key: "/1000/2", Value: "2=http://2.2.2.2:2380", CreatedIndex: 2},
-				2: {Key: "/1000/3", Value: "2=http://3.3.3.3:2380", CreatedIndex: 3},
-			},
-			3,
-			"1=http://1.1.1.1:2380,2=http://2.2.2.2:2380,2=http://3.3.3.3:2380",
-			ErrDuplicateName,
-		},
-		{
-			[]*client.Node{
-				0: {Key: "/1000/1", Value: "1=1.1.1.1:2380", CreatedIndex: 1},
-				1: {Key: "/1000/2", Value: "2=http://2.2.2.2:2380", CreatedIndex: 2},
-				2: {Key: "/1000/3", Value: "2=http://3.3.3.3:2380", CreatedIndex: 3},
-			},
-			3,
-			"1=1.1.1.1:2380,2=http://2.2.2.2:2380,2=http://3.3.3.3:2380",
-			ErrInvalidURL,
-		},
-	}
-
-	for i, tt := range tests {
-		cluster, err := nodesToCluster(tt.nodes, tt.size)
-		if err != tt.werr {
-			t.Errorf("#%d: err = %v, want %v", i, err, tt.werr)
-		}
-		if !reflect.DeepEqual(cluster, tt.wcluster) {
-			t.Errorf("#%d: cluster = %v, want %v", i, cluster, tt.wcluster)
-		}
-	}
-}
-
-func TestSortableNodes(t *testing.T) {
-	ns := []*client.Node{
-		0: {CreatedIndex: 5},
-		1: {CreatedIndex: 1},
-		2: {CreatedIndex: 3},
-		3: {CreatedIndex: 4},
-	}
-	// add some randomness
-	for i := 0; i < 10000; i++ {
-		ns = append(ns, &client.Node{CreatedIndex: uint64(rand.Int31())})
-	}
-	sns := sortableNodes{ns}
-	sort.Sort(sns)
-	var cis []int
-	for _, n := range sns.Nodes {
-		cis = append(cis, int(n.CreatedIndex))
-	}
-	if !sort.IntsAreSorted(cis) {
-		t.Errorf("isSorted = %v, want %v", sort.IntsAreSorted(cis), true)
-	}
-	cis = make([]int, 0)
-	for _, n := range ns {
-		cis = append(cis, int(n.CreatedIndex))
-	}
-	if !sort.IntsAreSorted(cis) {
-		t.Errorf("isSorted = %v, want %v", sort.IntsAreSorted(cis), true)
-	}
-}
-
-func TestRetryFailure(t *testing.T) {
-	nRetries = maxRetryInTest
-	defer func() { nRetries = math.MaxUint32 }()
-
-	cluster := "1000"
-	c := &clientWithRetry{failTimes: 4}
-	fc := clockwork.NewFakeClock()
-	d := discovery{
-		cluster: cluster,
-		id:      1,
-		c:       c,
-		clock:   fc,
-	}
-	go func() {
-		for i := uint(1); i <= maxRetryInTest; i++ {
-			fc.BlockUntil(1)
-			fc.Advance(time.Second * (0x1 << i))
-		}
-	}()
-	if _, _, _, err := d.checkCluster(); err != ErrTooManyRetries {
-		t.Errorf("err = %v, want %v", err, ErrTooManyRetries)
-	}
-}
-
-type clientWithResp struct {
-	rs []*client.Response
-	w  client.Watcher
-	client.KeysAPI
-}
-
-func (c *clientWithResp) Create(ctx context.Context, key string, value string) (*client.Response, error) {
-	if len(c.rs) == 0 {
-		return &client.Response{}, nil
-	}
-	r := c.rs[0]
-	c.rs = c.rs[1:]
-	return r, nil
-}
-
-func (c *clientWithResp) Get(ctx context.Context, key string, opts *client.GetOptions) (*client.Response, error) {
-	if len(c.rs) == 0 {
-		return &client.Response{}, &client.Error{Code: client.ErrorCodeKeyNotFound}
-	}
-	r := c.rs[0]
-	c.rs = append(c.rs[1:], r)
-	return r, nil
-}
-
-func (c *clientWithResp) Watcher(key string, opts *client.WatcherOptions) client.Watcher {
-	return c.w
-}
-
-type clientWithErr struct {
-	err error
-	w   client.Watcher
-	client.KeysAPI
-}
-
-func (c *clientWithErr) Create(ctx context.Context, key string, value string) (*client.Response, error) {
-	return &client.Response{}, c.err
-}
-
-func (c *clientWithErr) Get(ctx context.Context, key string, opts *client.GetOptions) (*client.Response, error) {
-	return &client.Response{}, c.err
-}
-
-func (c *clientWithErr) Watcher(key string, opts *client.WatcherOptions) client.Watcher {
-	return c.w
-}
-
-type watcherWithResp struct {
-	client.KeysAPI
-	rs []*client.Response
-}
-
-func (w *watcherWithResp) Next(context.Context) (*client.Response, error) {
-	if len(w.rs) == 0 {
-		return &client.Response{}, nil
-	}
-	r := w.rs[0]
-	w.rs = w.rs[1:]
-	return r, nil
-}
-
-type watcherWithErr struct {
-	err error
-}
-
-func (w *watcherWithErr) Next(context.Context) (*client.Response, error) {
-	return &client.Response{}, w.err
-}
-
-// clientWithRetry will timeout all requests up to failTimes
-type clientWithRetry struct {
-	clientWithResp
-	failCount int
-	failTimes int
-}
-
-func (c *clientWithRetry) Create(ctx context.Context, key string, value string) (*client.Response, error) {
-	if c.failCount < c.failTimes {
-		c.failCount++
-		return nil, &client.ClusterError{Errors: []error{context.DeadlineExceeded}}
-	}
-	return c.clientWithResp.Create(ctx, key, value)
-}
-
-func (c *clientWithRetry) Get(ctx context.Context, key string, opts *client.GetOptions) (*client.Response, error) {
-	if c.failCount < c.failTimes {
-		c.failCount++
-		return nil, &client.ClusterError{Errors: []error{context.DeadlineExceeded}}
-	}
-	return c.clientWithResp.Get(ctx, key, opts)
-}
-
-// watcherWithRetry will timeout all requests up to failTimes
-type watcherWithRetry struct {
-	rs        []*client.Response
-	failCount int
-	failTimes int
-}
-
-func (w *watcherWithRetry) Next(context.Context) (*client.Response, error) {
-	if w.failCount < w.failTimes {
-		w.failCount++
-		return nil, &client.ClusterError{Errors: []error{context.DeadlineExceeded}}
-	}
-	if len(w.rs) == 0 {
-		return &client.Response{}, nil
-	}
-	r := w.rs[0]
-	w.rs = w.rs[1:]
-	return r, nil
-}
diff --git a/etcdmain/etcd.go b/etcdmain/etcd.go
index 87e9b25..49ef725 100644
--- a/etcdmain/etcd.go
+++ b/etcdmain/etcd.go
@@ -26,10 +26,10 @@ import (
 	"strings"
 	"time"
 
-	"github.com/coreos/etcd/discovery"
 	"github.com/coreos/etcd/embed"
 	"github.com/coreos/etcd/etcdserver"
 	"github.com/coreos/etcd/etcdserver/api/etcdhttp"
+	"github.com/coreos/etcd/internal/discovery"
 	"github.com/coreos/etcd/pkg/cors"
 	"github.com/coreos/etcd/pkg/fileutil"
 	pkgioutil "github.com/coreos/etcd/pkg/ioutil"
diff --git a/etcdserver/server.go b/etcdserver/server.go
index 981e688..b1f49eb 100644
--- a/etcdserver/server.go
+++ b/etcdserver/server.go
@@ -30,7 +30,6 @@ import (
 	"time"
 
 	"github.com/coreos/etcd/auth"
-	"github.com/coreos/etcd/discovery"
 	"github.com/coreos/etcd/etcdserver/api"
 	"github.com/coreos/etcd/etcdserver/api/v2http/httptypes"
 	pb "github.com/coreos/etcd/etcdserver/etcdserverpb"
@@ -38,6 +37,7 @@ import (
 	"github.com/coreos/etcd/etcdserver/stats"
 	"github.com/coreos/etcd/internal/alarm"
 	"github.com/coreos/etcd/internal/compactor"
+	"github.com/coreos/etcd/internal/discovery"
 	"github.com/coreos/etcd/internal/raftsnap"
 	"github.com/coreos/etcd/lease"
 	"github.com/coreos/etcd/lease/leasehttp"
diff --git a/internal/discovery/discovery.go b/internal/discovery/discovery.go
new file mode 100644
index 0000000..7d1fa0d
--- /dev/null
+++ b/internal/discovery/discovery.go
@@ -0,0 +1,363 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+// Package discovery provides an implementation of the cluster discovery that
+// is used by etcd.
+package discovery
+
+import (
+	"context"
+	"errors"
+	"fmt"
+	"math"
+	"net/http"
+	"net/url"
+	"path"
+	"sort"
+	"strconv"
+	"strings"
+	"time"
+
+	"github.com/coreos/etcd/client"
+	"github.com/coreos/etcd/pkg/transport"
+	"github.com/coreos/etcd/pkg/types"
+
+	"github.com/coreos/pkg/capnslog"
+	"github.com/jonboulle/clockwork"
+)
+
+var (
+	plog = capnslog.NewPackageLogger("github.com/coreos/etcd", "discovery")
+
+	ErrInvalidURL           = errors.New("discovery: invalid URL")
+	ErrBadSizeKey           = errors.New("discovery: size key is bad")
+	ErrSizeNotFound         = errors.New("discovery: size key not found")
+	ErrTokenNotFound        = errors.New("discovery: token not found")
+	ErrDuplicateID          = errors.New("discovery: found duplicate id")
+	ErrDuplicateName        = errors.New("discovery: found duplicate name")
+	ErrFullCluster          = errors.New("discovery: cluster is full")
+	ErrTooManyRetries       = errors.New("discovery: too many retries")
+	ErrBadDiscoveryEndpoint = errors.New("discovery: bad discovery endpoint")
+)
+
+var (
+	// Number of retries discovery will attempt before giving up and erroring out.
+	nRetries             = uint(math.MaxUint32)
+	maxExpoentialRetries = uint(8)
+)
+
+// JoinCluster will connect to the discovery service at the given url, and
+// register the server represented by the given id and config to the cluster
+func JoinCluster(durl, dproxyurl string, id types.ID, config string) (string, error) {
+	d, err := newDiscovery(durl, dproxyurl, id)
+	if err != nil {
+		return "", err
+	}
+	return d.joinCluster(config)
+}
+
+// GetCluster will connect to the discovery service at the given url and
+// retrieve a string describing the cluster
+func GetCluster(durl, dproxyurl string) (string, error) {
+	d, err := newDiscovery(durl, dproxyurl, 0)
+	if err != nil {
+		return "", err
+	}
+	return d.getCluster()
+}
+
+type discovery struct {
+	cluster string
+	id      types.ID
+	c       client.KeysAPI
+	retries uint
+	url     *url.URL
+
+	clock clockwork.Clock
+}
+
+// newProxyFunc builds a proxy function from the given string, which should
+// represent a URL that can be used as a proxy. It performs basic
+// sanitization of the URL and returns any error encountered.
+func newProxyFunc(proxy string) (func(*http.Request) (*url.URL, error), error) {
+	if proxy == "" {
+		return nil, nil
+	}
+	// Do a small amount of URL sanitization to help the user
+	// Derived from net/http.ProxyFromEnvironment
+	proxyURL, err := url.Parse(proxy)
+	if err != nil || !strings.HasPrefix(proxyURL.Scheme, "http") {
+		// proxy was bogus. Try prepending "http://" to it and
+		// see if that parses correctly. If not, we ignore the
+		// error and complain about the original one
+		var err2 error
+		proxyURL, err2 = url.Parse("http://" + proxy)
+		if err2 == nil {
+			err = nil
+		}
+	}
+	if err != nil {
+		return nil, fmt.Errorf("invalid proxy address %q: %v", proxy, err)
+	}
+
+	plog.Infof("using proxy %q", proxyURL.String())
+	return http.ProxyURL(proxyURL), nil
+}
+
+func newDiscovery(durl, dproxyurl string, id types.ID) (*discovery, error) {
+	u, err := url.Parse(durl)
+	if err != nil {
+		return nil, err
+	}
+	token := u.Path
+	u.Path = ""
+	pf, err := newProxyFunc(dproxyurl)
+	if err != nil {
+		return nil, err
+	}
+
+	// TODO: add ResponseHeaderTimeout back when watch on discovery service writes header early
+	tr, err := transport.NewTransport(transport.TLSInfo{}, 30*time.Second)
+	if err != nil {
+		return nil, err
+	}
+	tr.Proxy = pf
+	cfg := client.Config{
+		Transport: tr,
+		Endpoints: []string{u.String()},
+	}
+	c, err := client.New(cfg)
+	if err != nil {
+		return nil, err
+	}
+	dc := client.NewKeysAPIWithPrefix(c, "")
+	return &discovery{
+		cluster: token,
+		c:       dc,
+		id:      id,
+		url:     u,
+		clock:   clockwork.NewRealClock(),
+	}, nil
+}
+
+func (d *discovery) joinCluster(config string) (string, error) {
+	// fast path: if the cluster is full, return the error
+	// do not need to register to the cluster in this case.
+	if _, _, _, err := d.checkCluster(); err != nil {
+		return "", err
+	}
+
+	if err := d.createSelf(config); err != nil {
+		// Fails, even on a timeout, if createSelf times out.
+		// TODO(barakmich): Retrying the same node might want to succeed here
+		// (ie, createSelf should be idempotent for discovery).
+		return "", err
+	}
+
+	nodes, size, index, err := d.checkCluster()
+	if err != nil {
+		return "", err
+	}
+
+	all, err := d.waitNodes(nodes, size, index)
+	if err != nil {
+		return "", err
+	}
+
+	return nodesToCluster(all, size)
+}
+
+func (d *discovery) getCluster() (string, error) {
+	nodes, size, index, err := d.checkCluster()
+	if err != nil {
+		if err == ErrFullCluster {
+			return nodesToCluster(nodes, size)
+		}
+		return "", err
+	}
+
+	all, err := d.waitNodes(nodes, size, index)
+	if err != nil {
+		return "", err
+	}
+	return nodesToCluster(all, size)
+}
+
+func (d *discovery) createSelf(contents string) error {
+	ctx, cancel := context.WithTimeout(context.Background(), client.DefaultRequestTimeout)
+	resp, err := d.c.Create(ctx, d.selfKey(), contents)
+	cancel()
+	if err != nil {
+		if eerr, ok := err.(client.Error); ok && eerr.Code == client.ErrorCodeNodeExist {
+			return ErrDuplicateID
+		}
+		return err
+	}
+
+	// ensure self appears on the server we connected to
+	w := d.c.Watcher(d.selfKey(), &client.WatcherOptions{AfterIndex: resp.Node.CreatedIndex - 1})
+	_, err = w.Next(context.Background())
+	return err
+}
+
+func (d *discovery) checkCluster() ([]*client.Node, int, uint64, error) {
+	configKey := path.Join("/", d.cluster, "_config")
+	ctx, cancel := context.WithTimeout(context.Background(), client.DefaultRequestTimeout)
+	// find cluster size
+	resp, err := d.c.Get(ctx, path.Join(configKey, "size"), nil)
+	cancel()
+	if err != nil {
+		if eerr, ok := err.(*client.Error); ok && eerr.Code == client.ErrorCodeKeyNotFound {
+			return nil, 0, 0, ErrSizeNotFound
+		}
+		if err == client.ErrInvalidJSON {
+			return nil, 0, 0, ErrBadDiscoveryEndpoint
+		}
+		if ce, ok := err.(*client.ClusterError); ok {
+			plog.Error(ce.Detail())
+			return d.checkClusterRetry()
+		}
+		return nil, 0, 0, err
+	}
+	size, err := strconv.Atoi(resp.Node.Value)
+	if err != nil {
+		return nil, 0, 0, ErrBadSizeKey
+	}
+
+	ctx, cancel = context.WithTimeout(context.Background(), client.DefaultRequestTimeout)
+	resp, err = d.c.Get(ctx, d.cluster, nil)
+	cancel()
+	if err != nil {
+		if ce, ok := err.(*client.ClusterError); ok {
+			plog.Error(ce.Detail())
+			return d.checkClusterRetry()
+		}
+		return nil, 0, 0, err
+	}
+	var nodes []*client.Node
+	// append non-config keys to nodes
+	for _, n := range resp.Node.Nodes {
+		if !(path.Base(n.Key) == path.Base(configKey)) {
+			nodes = append(nodes, n)
+		}
+	}
+
+	snodes := sortableNodes{nodes}
+	sort.Sort(snodes)
+
+	// find self position
+	for i := range nodes {
+		if path.Base(nodes[i].Key) == path.Base(d.selfKey()) {
+			break
+		}
+		if i >= size-1 {
+			return nodes[:size], size, resp.Index, ErrFullCluster
+		}
+	}
+	return nodes, size, resp.Index, nil
+}
+
+func (d *discovery) logAndBackoffForRetry(step string) {
+	d.retries++
+	// logAndBackoffForRetry stops exponential backoff when the retries are more than maxExpoentialRetries and is set to a constant backoff afterward.
+	retries := d.retries
+	if retries > maxExpoentialRetries {
+		retries = maxExpoentialRetries
+	}
+	retryTimeInSecond := time.Duration(0x1<<retries) * time.Second
+	plog.Infof("%s: error connecting to %s, retrying in %s", step, d.url, retryTimeInSecond)
+	d.clock.Sleep(retryTimeInSecond)
+}
+
+func (d *discovery) checkClusterRetry() ([]*client.Node, int, uint64, error) {
+	if d.retries < nRetries {
+		d.logAndBackoffForRetry("cluster status check")
+		return d.checkCluster()
+	}
+	return nil, 0, 0, ErrTooManyRetries
+}
+
+func (d *discovery) waitNodesRetry() ([]*client.Node, error) {
+	if d.retries < nRetries {
+		d.logAndBackoffForRetry("waiting for other nodes")
+		nodes, n, index, err := d.checkCluster()
+		if err != nil {
+			return nil, err
+		}
+		return d.waitNodes(nodes, n, index)
+	}
+	return nil, ErrTooManyRetries
+}
+
+func (d *discovery) waitNodes(nodes []*client.Node, size int, index uint64) ([]*client.Node, error) {
+	if len(nodes) > size {
+		nodes = nodes[:size]
+	}
+	// watch from the next index
+	w := d.c.Watcher(d.cluster, &client.WatcherOptions{AfterIndex: index, Recursive: true})
+	all := make([]*client.Node, len(nodes))
+	copy(all, nodes)
+	for _, n := range all {
+		if path.Base(n.Key) == path.Base(d.selfKey()) {
+			plog.Noticef("found self %s in the cluster", path.Base(d.selfKey()))
+		} else {
+			plog.Noticef("found peer %s in the cluster", path.Base(n.Key))
+		}
+	}
+
+	// wait for others
+	for len(all) < size {
+		plog.Noticef("found %d peer(s), waiting for %d more", len(all), size-len(all))
+		resp, err := w.Next(context.Background())
+		if err != nil {
+			if ce, ok := err.(*client.ClusterError); ok {
+				plog.Error(ce.Detail())
+				return d.waitNodesRetry()
+			}
+			return nil, err
+		}
+		plog.Noticef("found peer %s in the cluster", path.Base(resp.Node.Key))
+		all = append(all, resp.Node)
+	}
+	plog.Noticef("found %d needed peer(s)", len(all))
+	return all, nil
+}
+
+func (d *discovery) selfKey() string {
+	return path.Join("/", d.cluster, d.id.String())
+}
+
+func nodesToCluster(ns []*client.Node, size int) (string, error) {
+	s := make([]string, len(ns))
+	for i, n := range ns {
+		s[i] = n.Value
+	}
+	us := strings.Join(s, ",")
+	m, err := types.NewURLsMap(us)
+	if err != nil {
+		return us, ErrInvalidURL
+	}
+	if m.Len() != size {
+		return us, ErrDuplicateName
+	}
+	return us, nil
+}
+
+type sortableNodes struct{ Nodes []*client.Node }
+
+func (ns sortableNodes) Len() int { return len(ns.Nodes) }
+func (ns sortableNodes) Less(i, j int) bool {
+	return ns.Nodes[i].CreatedIndex < ns.Nodes[j].CreatedIndex
+}
+func (ns sortableNodes) Swap(i, j int) { ns.Nodes[i], ns.Nodes[j] = ns.Nodes[j], ns.Nodes[i] }
diff --git a/internal/discovery/discovery_test.go b/internal/discovery/discovery_test.go
new file mode 100644
index 0000000..8989726
--- /dev/null
+++ b/internal/discovery/discovery_test.go
@@ -0,0 +1,558 @@
+// Copyright 2015 The etcd Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package discovery
+
+import (
+	"context"
+	"errors"
+	"math"
+	"math/rand"
+	"net/http"
+	"reflect"
+	"sort"
+	"strconv"
+	"testing"
+	"time"
+
+	"github.com/coreos/etcd/client"
+
+	"github.com/jonboulle/clockwork"
+)
+
+const (
+	maxRetryInTest = 3
+)
+
+func TestNewProxyFuncUnset(t *testing.T) {
+	pf, err := newProxyFunc("")
+	if pf != nil {
+		t.Fatal("unexpected non-nil proxyFunc")
+	}
+	if err != nil {
+		t.Fatalf("unexpected non-nil err: %v", err)
+	}
+}
+
+func TestNewProxyFuncBad(t *testing.T) {
+	tests := []string{
+		"%%",
+		"http://foo.com/%1",
+	}
+	for i, in := range tests {
+		pf, err := newProxyFunc(in)
+		if pf != nil {
+			t.Errorf("#%d: unexpected non-nil proxyFunc", i)
+		}
+		if err == nil {
+			t.Errorf("#%d: unexpected nil err", i)
+		}
+	}
+}
+
+func TestNewProxyFunc(t *testing.T) {
+	tests := map[string]string{
+		"bar.com":              "http://bar.com",
+		"http://disco.foo.bar": "http://disco.foo.bar",
+	}
+	for in, w := range tests {
+		pf, err := newProxyFunc(in)
+		if pf == nil {
+			t.Errorf("%s: unexpected nil proxyFunc", in)
+			continue
+		}
+		if err != nil {
+			t.Errorf("%s: unexpected non-nil err: %v", in, err)
+			continue
+		}
+		g, err := pf(&http.Request{})
+		if err != nil {
+			t.Errorf("%s: unexpected non-nil err: %v", in, err)
+		}
+		if g.String() != w {
+			t.Errorf("%s: proxyURL=%q, want %q", in, g, w)
+		}
+
+	}
+}
+
+func TestCheckCluster(t *testing.T) {
+	cluster := "/prefix/1000"
+	self := "/1000/1"
+
+	tests := []struct {
+		nodes []*client.Node
+		index uint64
+		werr  error
+		wsize int
+	}{
+		{
+			// self is in the size range
+			[]*client.Node{
+				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
+				{Key: "/1000/_config/"},
+				{Key: self, CreatedIndex: 2},
+				{Key: "/1000/2", CreatedIndex: 3},
+				{Key: "/1000/3", CreatedIndex: 4},
+				{Key: "/1000/4", CreatedIndex: 5},
+			},
+			5,
+			nil,
+			3,
+		},
+		{
+			// self is in the size range
+			[]*client.Node{
+				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
+				{Key: "/1000/_config/"},
+				{Key: "/1000/2", CreatedIndex: 2},
+				{Key: "/1000/3", CreatedIndex: 3},
+				{Key: self, CreatedIndex: 4},
+				{Key: "/1000/4", CreatedIndex: 5},
+			},
+			5,
+			nil,
+			3,
+		},
+		{
+			// self is out of the size range
+			[]*client.Node{
+				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
+				{Key: "/1000/_config/"},
+				{Key: "/1000/2", CreatedIndex: 2},
+				{Key: "/1000/3", CreatedIndex: 3},
+				{Key: "/1000/4", CreatedIndex: 4},
+				{Key: self, CreatedIndex: 5},
+			},
+			5,
+			ErrFullCluster,
+			3,
+		},
+		{
+			// self is not in the cluster
+			[]*client.Node{
+				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
+				{Key: "/1000/_config/"},
+				{Key: "/1000/2", CreatedIndex: 2},
+				{Key: "/1000/3", CreatedIndex: 3},
+			},
+			3,
+			nil,
+			3,
+		},
+		{
+			[]*client.Node{
+				{Key: "/1000/_config/size", Value: "3", CreatedIndex: 1},
+				{Key: "/1000/_config/"},
+				{Key: "/1000/2", CreatedIndex: 2},
+				{Key: "/1000/3", CreatedIndex: 3},
+				{Key: "/1000/4", CreatedIndex: 4},
+			},
+			3,
+			ErrFullCluster,
+			3,
+		},
+		{
+			// bad size key
+			[]*client.Node{
+				{Key: "/1000/_config/size", Value: "bad", CreatedIndex: 1},
+			},
+			0,
+			ErrBadSizeKey,
+			0,
+		},
+		{
+			// no size key
+			[]*client.Node{},
+			0,
+			ErrSizeNotFound,
+			0,
+		},
+	}
+
+	for i, tt := range tests {
+		var rs []*client.Response
+		if len(tt.nodes) > 0 {
+			rs = append(rs, &client.Response{Node: tt.nodes[0], Index: tt.index})
+			rs = append(rs, &client.Response{
+				Node: &client.Node{
+					Key:   cluster,
+					Nodes: tt.nodes[1:],
+				},
+				Index: tt.index,
+			})
+		}
+		c := &clientWithResp{rs: rs}
+		dBase := discovery{cluster: cluster, id: 1, c: c}
+
+		cRetry := &clientWithRetry{failTimes: 3}
+		cRetry.rs = rs
+		fc := clockwork.NewFakeClock()
+		dRetry := discovery{cluster: cluster, id: 1, c: cRetry, clock: fc}
+
+		for _, d := range []discovery{dBase, dRetry} {
+			go func() {
+				for i := uint(1); i <= maxRetryInTest; i++ {
+					fc.BlockUntil(1)
+					fc.Advance(time.Second * (0x1 << i))
+				}
+			}()
+			ns, size, index, err := d.checkCluster()
+			if err != tt.werr {
+				t.Errorf("#%d: err = %v, want %v", i, err, tt.werr)
+			}
+			if reflect.DeepEqual(ns, tt.nodes) {
+				t.Errorf("#%d: nodes = %v, want %v", i, ns, tt.nodes)
+			}
+			if size != tt.wsize {
+				t.Errorf("#%d: size = %v, want %d", i, size, tt.wsize)
+			}
+			if index != tt.index {
+				t.Errorf("#%d: index = %v, want %d", i, index, tt.index)
+			}
+		}
+	}
+}
+
+func TestWaitNodes(t *testing.T) {
+	all := []*client.Node{
+		0: {Key: "/1000/1", CreatedIndex: 2},
+		1: {Key: "/1000/2", CreatedIndex: 3},
+		2: {Key: "/1000/3", CreatedIndex: 4},
+	}
+
+	tests := []struct {
+		nodes []*client.Node
+		rs    []*client.Response
+	}{
+		{
+			all,
+			[]*client.Response{},
+		},
+		{
+			all[:1],
+			[]*client.Response{
+				{Node: &client.Node{Key: "/1000/2", CreatedIndex: 3}},
+				{Node: &client.Node{Key: "/1000/3", CreatedIndex: 4}},
+			},
+		},
+		{
+			all[:2],
+			[]*client.Response{
+				{Node: &client.Node{Key: "/1000/3", CreatedIndex: 4}},
+			},
+		},
+		{
+			append(all, &client.Node{Key: "/1000/4", CreatedIndex: 5}),
+			[]*client.Response{
+				{Node: &client.Node{Key: "/1000/3", CreatedIndex: 4}},
+			},
+		},
+	}
+
+	for i, tt := range tests {
+		// Basic case
+		c := &clientWithResp{rs: nil, w: &watcherWithResp{rs: tt.rs}}
+		dBase := &discovery{cluster: "1000", c: c}
+
+		// Retry case
+		var retryScanResp []*client.Response
+		if len(tt.nodes) > 0 {
+			retryScanResp = append(retryScanResp, &client.Response{
+				Node: &client.Node{
+					Key:   "1000",
+					Value: strconv.Itoa(3),
+				},
+			})
+			retryScanResp = append(retryScanResp, &client.Response{
+				Node: &client.Node{
+					Nodes: tt.nodes,
+				},
+			})
+		}
+		cRetry := &clientWithResp{
+			rs: retryScanResp,
+			w:  &watcherWithRetry{rs: tt.rs, failTimes: 2},
+		}
+		fc := clockwork.NewFakeClock()
+		dRetry := &discovery{
+			cluster: "1000",
+			c:       cRetry,
+			clock:   fc,
+		}
+
+		for _, d := range []*discovery{dBase, dRetry} {
+			go func() {
+				for i := uint(1); i <= maxRetryInTest; i++ {
+					fc.BlockUntil(1)
+					fc.Advance(time.Second * (0x1 << i))
+				}
+			}()
+			g, err := d.waitNodes(tt.nodes, 3, 0) // we do not care about index in this test
+			if err != nil {
+				t.Errorf("#%d: err = %v, want %v", i, err, nil)
+			}
+			if !reflect.DeepEqual(g, all) {
+				t.Errorf("#%d: all = %v, want %v", i, g, all)
+			}
+		}
+	}
+}
+
+func TestCreateSelf(t *testing.T) {
+	rs := []*client.Response{{Node: &client.Node{Key: "1000/1", CreatedIndex: 2}}}
+
+	w := &watcherWithResp{rs: rs}
+	errw := &watcherWithErr{err: errors.New("watch err")}
+
+	c := &clientWithResp{rs: rs, w: w}
+	errc := &clientWithErr{err: errors.New("create err"), w: w}
+	errdupc := &clientWithErr{err: client.Error{Code: client.ErrorCodeNodeExist}}
+	errwc := &clientWithResp{rs: rs, w: errw}
+
+	tests := []struct {
+		c    client.KeysAPI
+		werr error
+	}{
+		// no error
+		{c, nil},
+		// client.create returns an error
+		{errc, errc.err},
+		// watcher.next returns an error
+		{errwc, errw.err},
+		// parse key exist error to duplicate ID error
+		{errdupc, ErrDuplicateID},
+	}
+
+	for i, tt := range tests {
+		d := discovery{cluster: "1000", c: tt.c}
+		if err := d.createSelf(""); err != tt.werr {
+			t.Errorf("#%d: err = %v, want %v", i, err, nil)
+		}
+	}
+}
+
+func TestNodesToCluster(t *testing.T) {
+	tests := []struct {
+		nodes    []*client.Node
+		size     int
+		wcluster string
+		werr     error
+	}{
+		{
+			[]*client.Node{
+				0: {Key: "/1000/1", Value: "1=http://1.1.1.1:2380", CreatedIndex: 1},
+				1: {Key: "/1000/2", Value: "2=http://2.2.2.2:2380", CreatedIndex: 2},
+				2: {Key: "/1000/3", Value: "3=http://3.3.3.3:2380", CreatedIndex: 3},
+			},
+			3,
+			"1=http://1.1.1.1:2380,2=http://2.2.2.2:2380,3=http://3.3.3.3:2380",
+			nil,
+		},
+		{
+			[]*client.Node{
+				0: {Key: "/1000/1", Value: "1=http://1.1.1.1:2380", CreatedIndex: 1},
+				1: {Key: "/1000/2", Value: "2=http://2.2.2.2:2380", CreatedIndex: 2},
+				2: {Key: "/1000/3", Value: "2=http://3.3.3.3:2380", CreatedIndex: 3},
+			},
+			3,
+			"1=http://1.1.1.1:2380,2=http://2.2.2.2:2380,2=http://3.3.3.3:2380",
+			ErrDuplicateName,
+		},
+		{
+			[]*client.Node{
+				0: {Key: "/1000/1", Value: "1=1.1.1.1:2380", CreatedIndex: 1},
+				1: {Key: "/1000/2", Value: "2=http://2.2.2.2:2380", CreatedIndex: 2},
+				2: {Key: "/1000/3", Value: "2=http://3.3.3.3:2380", CreatedIndex: 3},
+			},
+			3,
+			"1=1.1.1.1:2380,2=http://2.2.2.2:2380,2=http://3.3.3.3:2380",
+			ErrInvalidURL,
+		},
+	}
+
+	for i, tt := range tests {
+		cluster, err := nodesToCluster(tt.nodes, tt.size)
+		if err != tt.werr {
+			t.Errorf("#%d: err = %v, want %v", i, err, tt.werr)
+		}
+		if !reflect.DeepEqual(cluster, tt.wcluster) {
+			t.Errorf("#%d: cluster = %v, want %v", i, cluster, tt.wcluster)
+		}
+	}
+}
+
+func TestSortableNodes(t *testing.T) {
+	ns := []*client.Node{
+		0: {CreatedIndex: 5},
+		1: {CreatedIndex: 1},
+		2: {CreatedIndex: 3},
+		3: {CreatedIndex: 4},
+	}
+	// add some randomness
+	for i := 0; i < 10000; i++ {
+		ns = append(ns, &client.Node{CreatedIndex: uint64(rand.Int31())})
+	}
+	sns := sortableNodes{ns}
+	sort.Sort(sns)
+	var cis []int
+	for _, n := range sns.Nodes {
+		cis = append(cis, int(n.CreatedIndex))
+	}
+	if !sort.IntsAreSorted(cis) {
+		t.Errorf("isSorted = %v, want %v", sort.IntsAreSorted(cis), true)
+	}
+	cis = make([]int, 0)
+	for _, n := range ns {
+		cis = append(cis, int(n.CreatedIndex))
+	}
+	if !sort.IntsAreSorted(cis) {
+		t.Errorf("isSorted = %v, want %v", sort.IntsAreSorted(cis), true)
+	}
+}
+
+func TestRetryFailure(t *testing.T) {
+	nRetries = maxRetryInTest
+	defer func() { nRetries = math.MaxUint32 }()
+
+	cluster := "1000"
+	c := &clientWithRetry{failTimes: 4}
+	fc := clockwork.NewFakeClock()
+	d := discovery{
+		cluster: cluster,
+		id:      1,
+		c:       c,
+		clock:   fc,
+	}
+	go func() {
+		for i := uint(1); i <= maxRetryInTest; i++ {
+			fc.BlockUntil(1)
+			fc.Advance(time.Second * (0x1 << i))
+		}
+	}()
+	if _, _, _, err := d.checkCluster(); err != ErrTooManyRetries {
+		t.Errorf("err = %v, want %v", err, ErrTooManyRetries)
+	}
+}
+
+type clientWithResp struct {
+	rs []*client.Response
+	w  client.Watcher
+	client.KeysAPI
+}
+
+func (c *clientWithResp) Create(ctx context.Context, key string, value string) (*client.Response, error) {
+	if len(c.rs) == 0 {
+		return &client.Response{}, nil
+	}
+	r := c.rs[0]
+	c.rs = c.rs[1:]
+	return r, nil
+}
+
+func (c *clientWithResp) Get(ctx context.Context, key string, opts *client.GetOptions) (*client.Response, error) {
+	if len(c.rs) == 0 {
+		return &client.Response{}, &client.Error{Code: client.ErrorCodeKeyNotFound}
+	}
+	r := c.rs[0]
+	c.rs = append(c.rs[1:], r)
+	return r, nil
+}
+
+func (c *clientWithResp) Watcher(key string, opts *client.WatcherOptions) client.Watcher {
+	return c.w
+}
+
+type clientWithErr struct {
+	err error
+	w   client.Watcher
+	client.KeysAPI
+}
+
+func (c *clientWithErr) Create(ctx context.Context, key string, value string) (*client.Response, error) {
+	return &client.Response{}, c.err
+}
+
+func (c *clientWithErr) Get(ctx context.Context, key string, opts *client.GetOptions) (*client.Response, error) {
+	return &client.Response{}, c.err
+}
+
+func (c *clientWithErr) Watcher(key string, opts *client.WatcherOptions) client.Watcher {
+	return c.w
+}
+
+type watcherWithResp struct {
+	client.KeysAPI
+	rs []*client.Response
+}
+
+func (w *watcherWithResp) Next(context.Context) (*client.Response, error) {
+	if len(w.rs) == 0 {
+		return &client.Response{}, nil
+	}
+	r := w.rs[0]
+	w.rs = w.rs[1:]
+	return r, nil
+}
+
+type watcherWithErr struct {
+	err error
+}
+
+func (w *watcherWithErr) Next(context.Context) (*client.Response, error) {
+	return &client.Response{}, w.err
+}
+
+// clientWithRetry will timeout all requests up to failTimes
+type clientWithRetry struct {
+	clientWithResp
+	failCount int
+	failTimes int
+}
+
+func (c *clientWithRetry) Create(ctx context.Context, key string, value string) (*client.Response, error) {
+	if c.failCount < c.failTimes {
+		c.failCount++
+		return nil, &client.ClusterError{Errors: []error{context.DeadlineExceeded}}
+	}
+	return c.clientWithResp.Create(ctx, key, value)
+}
+
+func (c *clientWithRetry) Get(ctx context.Context, key string, opts *client.GetOptions) (*client.Response, error) {
+	if c.failCount < c.failTimes {
+		c.failCount++
+		return nil, &client.ClusterError{Errors: []error{context.DeadlineExceeded}}
+	}
+	return c.clientWithResp.Get(ctx, key, opts)
+}
+
+// watcherWithRetry will timeout all requests up to failTimes
+type watcherWithRetry struct {
+	rs        []*client.Response
+	failCount int
+	failTimes int
+}
+
+func (w *watcherWithRetry) Next(context.Context) (*client.Response, error) {
+	if w.failCount < w.failTimes {
+		w.failCount++
+		return nil, &client.ClusterError{Errors: []error{context.DeadlineExceeded}}
+	}
+	if len(w.rs) == 0 {
+		return &client.Response{}, nil
+	}
+	r := w.rs[0]
+	w.rs = w.rs[1:]
+	return r, nil
+}
